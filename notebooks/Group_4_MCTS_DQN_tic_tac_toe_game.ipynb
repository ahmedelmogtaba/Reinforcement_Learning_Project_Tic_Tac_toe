{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Group_4_MCTS_DQN_tic_tac_toe_game.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bVqh8vrkH7wg"
      },
      "source": [
        "# Model Based Algorithms (Monti-Carlo Tree Search):"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wm_5i9V7KnLM"
      },
      "source": [
        "**The Board of the game:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pOtX6371HvWI"
      },
      "source": [
        "from copy import deepcopy\n",
        "\n",
        "class XO_Board() :\n",
        "\n",
        "  def __init__(self,board = None):\n",
        "    # define players\n",
        "    self.first_player =     'x'\n",
        "    self.second_player =     'o'\n",
        "    self.empty_place = '-'\n",
        "    self.user_input = None\n",
        "\n",
        "    #define the board position\n",
        "    self.position = {}\n",
        "\n",
        "    # init the board\n",
        "    self.init_board()\n",
        "\n",
        "    # create a copy of previous board state \n",
        "    if board :\n",
        "      self.__dict__ = deepcopy(board.__dict__)\n",
        "\n",
        "  # initialize the board\n",
        "  def init_board(self):\n",
        "    # loop over board rows\n",
        "    for row in range(3):\n",
        "      # loop over board columns\n",
        "      for col in range(3):\n",
        "        # set every square to empty square\n",
        "        self.position[row,col] = self.empty_place\n",
        "\n",
        "  # implement make move\n",
        "  def make_move(self,row,col):\n",
        "    # create new board instance that inherits from the current state\n",
        "    board = XO_Board(self)\n",
        "\n",
        "    # make move \n",
        "    board.position[row,col] = self.first_player\n",
        "\n",
        "    #swap players\n",
        "    (board.first_player , board.second_player) = (board.second_player , board.first_player)\n",
        "\n",
        "    # return new board state\n",
        "    return board\n",
        "  \n",
        "\n",
        "  # get whether the game is draw\n",
        "  def is_draw(self):\n",
        "    # loop over board\n",
        "    for row , col in self.position:\n",
        "      # empty square is available\n",
        "      if self.position[row,col] == self.empty_place:\n",
        "        return False\n",
        "\n",
        "    # by default return True\n",
        "    return True\n",
        "\n",
        "  # get whether the game is win\n",
        "  def is_win(self):\n",
        "    # vertical sequence detection\n",
        "    # loop over board columns\n",
        "    for col in range(3):\n",
        "      # define the winning sequence list\n",
        "      winning_sequence = []\n",
        "\n",
        "      # loop over board rows\n",
        "      for row in range(3):\n",
        "        if self.position[row , col] == self.second_player:\n",
        "          # update winning sequence\n",
        "          winning_sequence.append((row,col)) \n",
        "        # if we have 3 elements in the row \n",
        "        if len(winning_sequence) == 3 :\n",
        "          return True\n",
        "\n",
        "    # horizontal sequence detection\n",
        "    # loop over board rows\n",
        "    for row in range(3):\n",
        "      # define the winning sequence list\n",
        "      winning_sequence = []\n",
        "\n",
        "      # loop over board columns\n",
        "      for col in range(3):\n",
        "        # if found the same next element in the row\n",
        "        if self.position[row , col] == self.second_player :\n",
        "          # update winning sequence\n",
        "          winning_sequence.append((row,col)) \n",
        "        # if we have 3 elements in the row \n",
        "        if len(winning_sequence) == 3 :\n",
        "          return True\n",
        "\n",
        "   \n",
        "    # 1st diagonal sequence detection\n",
        "    \n",
        "    # define the winning sequence list\n",
        "    winning_sequence = []\n",
        "    # loop over board rows\n",
        "    for row in range(3):\n",
        "      # init column\n",
        "      col = row\n",
        "      if self.position[row , col] == self.second_player :\n",
        "        # update winning sequence\n",
        "        winning_sequence.append((row,col)) \n",
        "      # if we have 3 elements in the row \n",
        "      if len(winning_sequence) == 3 :\n",
        "        return True\n",
        "\n",
        "    # 2nd diagonal sequence detection  \n",
        "    # define the winning sequence list\n",
        "    winning_sequence = []\n",
        "    # loop over board rows\n",
        "    for row in range(3):\n",
        "      # init column\n",
        "      col = 3-row-1\n",
        "      if self.position[row , col] == self.second_player :\n",
        "        # update winning sequence\n",
        "        winning_sequence.append((row,col)) \n",
        "      # if we have 3 elements in the row \n",
        "      if len(winning_sequence) == 3 :\n",
        "        return True\n",
        "\n",
        "\n",
        "    return False\n",
        "\n",
        "  # generate legal moves\n",
        "  def generate_moves(self):\n",
        "    actions = []\n",
        "    # loop over board rows\n",
        "    for row in range(3):\n",
        "      # loop over board columns\n",
        "      for col in range(3):\n",
        "        # make sure the current position is empty\n",
        "        if self.position[row,col] == self.empty_place :\n",
        "          # append available actions/board state to action list\n",
        "          actions.append(self.make_move(row,col))\n",
        "\n",
        "    # return the list of available actions (board class instances)\n",
        "    return actions\n",
        "\n",
        "  # main game loop \n",
        "  def game(self,num_iter):\n",
        "    print('   \\nWelcome to X O Game:')\n",
        "    print('===================================')\n",
        "    user_input_1 = ''\n",
        "    while True:\n",
        "        print(' \\nPlease Choose if you want to play with x or o  ? \\n')\n",
        "        user_input_1 = input()\n",
        "        if user_input_1 == 'x':\n",
        "          self.first_player = 'x'\n",
        "          self.second_player = 'o'\n",
        "          break\n",
        "        elif user_input_1 == 'o':\n",
        "          self.first_player = 'o'\n",
        "          self.second_player = 'x' \n",
        "          break\n",
        "        elif user_input_1 == 'exit':\n",
        "          return\n",
        "        else:\n",
        "            continue\n",
        "    if  user_input_1 == 'x' :       \n",
        "         print('\\nYou will play with x , and the Agent will play with o\\n')\n",
        "    else:\n",
        "         print('\\nYou will play with o , and the Agent will play with x\\n')   \n",
        "\n",
        "    print('enter your move for example : [x,y] = 1,2 where 1 is row and 2 is col,  or type \"exit\" to quit the game')\n",
        "\n",
        "    self.user_input = user_input_1\n",
        "    print(self)\n",
        "\n",
        "    # create monti carlo tree search instance\n",
        "    mcts = MCTS()\n",
        "\n",
        "    # game loop\n",
        "    while True :\n",
        "      # user input\n",
        "      user_input = input('> ')\n",
        "\n",
        "      if user_input == 'exit':\n",
        "        break\n",
        "\n",
        "      # skipp empty input\n",
        "      if user_input == '':\n",
        "        continue\n",
        "      try:\n",
        "        # parse user input ===> ex : format for move [col,row] = (1,3)\n",
        "        row = int(user_input.split(',')[0]) - 1\n",
        "        col = int(user_input.split(',')[1]) - 1\n",
        "\n",
        "        # check if the move is legal or not\n",
        "        if self.position[row,col] != self.empty_place:\n",
        "          print('Illegal move !!!')\n",
        "          continue\n",
        "\n",
        "        # make move on board\n",
        "        self = self.make_move(row,col)\n",
        "        # print board\n",
        "        print('-------------------------You Played------------------------ :)\\n')\n",
        "        print(self) \n",
        "\n",
        "\n",
        "        # search for the best move\n",
        "        best_move = mcts.search(self,num_iter)\n",
        "\n",
        "\n",
        "        # make AI Agent move ....\n",
        "        # legal moves available\n",
        "        try:\n",
        "           self = best_move.board\n",
        "        except:\n",
        "           pass   \n",
        "\n",
        "\n",
        "        # print board\n",
        "        print('------------------------Agent Played----------------------- :)\\n')\n",
        "        print(self) \n",
        "\n",
        "        # check the game state\n",
        "        if self.is_win():\n",
        "          print(' Player \"%s\" has won the game \\n' % self.second_player )\n",
        "          break\n",
        "\n",
        "        elif self.is_draw():\n",
        "          print('Oooh We have a draw \\n')\n",
        "          break   \n",
        "\n",
        "\n",
        "      except Exception as e:\n",
        "        print('Error: ' , e)\n",
        "        print('Illegal command !!!')\n",
        "        print('enter your move for example : [x,y] = 1,2 where 1 is row and 2 is column,  or type \"exit\" to quit the game')\n",
        "\n",
        "\n",
        "  # print the board state\n",
        "  def __str__(self):\n",
        "    # define board string representation\n",
        "    board_str = ''\n",
        "    # loop over board rows\n",
        "    for row in range(3):\n",
        "      # loop over board columns\n",
        "      for col in range(3):\n",
        "        board_str += ' %s' % self.position[row,col]\n",
        "\n",
        "      # print new line \n",
        "      board_str += '\\n'\n",
        "\n",
        "    # side to move \n",
        "    if self.first_player == self.user_input:\n",
        "      board_str = '\\n---------------------------\\n \"Your Turn ==>  \"%s\" to go\"   \\n---------------------------\\n\\n' %self.user_input + board_str\n",
        "    \n",
        "    else:\n",
        "      board_str = '\\n---------------------------\\n \"Agent Turn\"    \\n---------------------------\\n\\n' + board_str\n",
        "\n",
        "    return board_str\n",
        "   \n"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NHGZ_zoyKhA0"
      },
      "source": [
        "**Tree Node Class:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oavFMx1xKV6i"
      },
      "source": [
        "import math\n",
        "import random\n",
        "# Tree node class \n",
        "class TreeNode():\n",
        "  def __init__(self,board,parent):\n",
        "    self.board = board\n",
        "\n",
        "    # check if the node is terminal\n",
        "    if self.board.is_win() or self.board.is_draw():\n",
        "      # that means the game is over\n",
        "      self.is_terminal = True \n",
        "    else :\n",
        "      # we have a non terminal node\n",
        "      self.is_terminal = False  \n",
        "\n",
        "    # initialise is fully expanded flag\n",
        "    self.is_fully_expanded = self.is_terminal\n",
        "    # initialise parent node if available \n",
        "    self.parent = parent  \n",
        "    # initialize the number of node visits\n",
        "    self.visits = 0\n",
        "\n",
        "    # initialize the total score of the node\n",
        "    self.score =  0\n",
        "\n",
        "    # initialize the current node children\n",
        "    self.children = {}  \n"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3u2eDe_1LHSc"
      },
      "source": [
        "**MCTS class:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UEIf1XNwLAg2"
      },
      "source": [
        "class MCTS():\n",
        "  # search for the best move in the current position\n",
        "  def search(self,initial_state,num_iter):\n",
        "    # create root node\n",
        "    self.root = TreeNode(initial_state,None)\n",
        "\n",
        "    # Do iterations\n",
        "    for iteration in range(num_iter):\n",
        "      # select a node (selection phase)\n",
        "      node = self.select(self.root)\n",
        "\n",
        "      # score current node (simulation phase)\n",
        "      score = self.simulate_game(node.board)\n",
        "      # backpropagate the number of visits and the score\n",
        "      self.backpropagate(node,score)\n",
        "\n",
        "    # pick up the best move in the current position\n",
        "    try:\n",
        "      return self.get_best_move(self.root,0)\n",
        "    except:\n",
        "      pass  \n",
        "\n",
        "  # select most promising node\n",
        "  def select(self,node):\n",
        "    # make sure that it is not a terminal node\n",
        "    while not node.is_terminal:\n",
        "      # case where the node is fully expanded\n",
        "      if node.is_fully_expanded:\n",
        "        node = self.get_best_move(node,2)\n",
        "      # case where the node is not fully expanded\n",
        "      else:\n",
        "        # expand the nodes\n",
        "        return self.expand(node)\n",
        "    return node\n",
        "\n",
        "\n",
        "  # expand node\n",
        "  def expand(self,node):\n",
        "    # generate legal moves for the given node\n",
        "    states = node.board.generate_moves()\n",
        "    # loop over generated \n",
        "    for state in states:\n",
        "      # make sure that the current node is not present in child nodes \n",
        "      if str(state.position) not in node.children:\n",
        "        # create new node\n",
        "        new_node = TreeNode(state,node)\n",
        "        # add child node to parent's node children\n",
        "        node.children[str(state.position)] = new_node\n",
        "\n",
        "        # check if node is fully expanded\n",
        "        if len(states) == len(node.children):\n",
        "          node.is_fully_expanded = True\n",
        "        # return newly created node\n",
        "        return new_node  \n",
        "\n",
        "\n",
        "  # simulate the game by making random moves until reach the end of the game\n",
        "  def simulate_game(self,board):\n",
        "    # make random moves for both sides until terminal state is reached\n",
        "    while not board.is_win():\n",
        "      # try to make a move\n",
        "      try:\n",
        "        # make the move on board\n",
        "        board = random.choice(board.generate_moves())\n",
        "        \n",
        "      except:\n",
        "        # return a draw score    \n",
        "        return 0\n",
        "        \n",
        "    # return the score from player x perspective\n",
        "    if board.second_player == board.user_input:\n",
        "      return 1\n",
        "    else:\n",
        "      return -1    \n",
        "\n",
        "\n",
        "  #  backpropagate   \n",
        "  def backpropagate(self,node,score):\n",
        "    # update node visit count and score up to root node\n",
        "    while node is not None:\n",
        "      # update node's visits\n",
        "      node.visits += 1\n",
        "      # update node's score\n",
        "      node.score += score\n",
        "      # set node to parent\n",
        "      node = node.parent\n",
        "\n",
        "  # select the best node based on UCB1 formula\n",
        "  def get_best_move(self,node,exploration_factor):\n",
        "    # define best score and best moves\n",
        "    best_score = float('-inf')\n",
        "    best_moves = []\n",
        "    # loop over node's children\n",
        "    for child in node.children.values():\n",
        "      # define current player\n",
        "      if child.board.second_player == child.board.user_input: \n",
        "        current_player = 1\n",
        "      else:   \n",
        "        current_player = -1\n",
        "\n",
        "      # use UCB1 formula to get the move score\n",
        "      move_score = current_player * child.score / child.visits + exploration_factor * math.sqrt(math.log(node.visits/child.visits))\n",
        "\n",
        "      #better move has been found \n",
        "      if move_score > best_score:\n",
        "        best_score = move_score\n",
        "        best_moves = [child]\n",
        "\n",
        "      # move score is equal to the best score  \n",
        "      elif move_score == best_score :\n",
        "        best_moves.append(child)\n",
        "\n",
        "    # return one of the best moves randomly\n",
        "    return random.choice(best_moves)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85LMtelhLTAq"
      },
      "source": [
        "# Now Try to play the game (Human vs Agent) =========> :) :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Aq_P7o0LOw4"
      },
      "source": [
        "if __name__ == '__main__':\n",
        "  # create board instance \n",
        "  board = XO_Board()\n",
        "  # create mcts\n",
        "  mcts = MCTS()\n",
        "  # start game loop \n",
        "  board.game(2000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K_grcyqXLuka"
      },
      "source": [
        "# Model Free Algorithm (DQN) :"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tTi-9dq-MQ9M"
      },
      "source": [
        "# ENV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uwpXfHbfLf5A"
      },
      "source": [
        "from copy import deepcopy\n",
        "\n",
        "class XO_Board() :\n",
        "\n",
        "  def __init__(self,board = None):\n",
        "    self.first_player = 'x'\n",
        "    self.second_player = 'o'\n",
        "    self.empty_place = '-'\n",
        "    self.user_input = None\n",
        "    self.WIN_REWARD = 1\n",
        "    self.DRAW_REWARD = 0\n",
        "    self.LOSS_REWARD = -1\n",
        "    self.STUPID_ACTION_REWARD = -0.5\n",
        "    self.SMART_ACTION_REWARD = 0\n",
        "    self.EPS_START = 1.0\n",
        "    self.eps_threshold=2\n",
        "    self.EPS_END = 0.01\n",
        "    self.EPS_DECAY = 800000\n",
        "    self.agent_winner=0\n",
        "    self.mcts_winner=0\n",
        "    self.draw=0\n",
        "    # self.agent_player = 'x'\n",
        "    # self.mcts_player = 'o'\n",
        "    self.position = {}\n",
        "    mcts = MCTS()\n",
        "\n",
        "\n",
        "    # init the board\n",
        "    self.init_board()\n",
        "\n",
        "    # create a copy of previous board state \n",
        "    if board:\n",
        "      self.__dict__ = deepcopy(board.__dict__)\n",
        "    else:\n",
        "      self.init_board()\n",
        "\n",
        "  # initialize the board\n",
        "  def init_board(self, empty=True):\n",
        "    for row in range(3):\n",
        "      for col in range(3):\n",
        "        # set every square to empty square\n",
        "        self.position[row,col] = self.empty_place  \n",
        "    if not empty and  random.random()>0.5:\n",
        "      r_action = random.randrange(9)\n",
        "      row, col = self.action_to_ids(r_action+1)\n",
        "      self.position[row,col] = 'o'\n",
        "\n",
        "\n",
        "\n",
        "  # get whether the game is draw\n",
        "  def is_draw(self):\n",
        "    for row , col in self.position:\n",
        "      # empty square is available\n",
        "      if self.position[row,col] == self.empty_place:\n",
        "        return False\n",
        "    return True\n",
        "\n",
        "  # get whether the game is win\n",
        "  def is_win(self):\n",
        "    # vertical sequence detection\n",
        "    for col in range(3):\n",
        "      # define the winning sequence list\n",
        "      winning_sequence = []\n",
        "      for row in range(3):\n",
        "        if self.position[row , col] == self.second_player:\n",
        "          # update winning sequence\n",
        "          winning_sequence.append((row,col)) \n",
        "        # if we have 3 elements in the row \n",
        "        if len(winning_sequence) == 3 :\n",
        "          return True\n",
        "\n",
        "    # horizontal sequence detection\n",
        "    for row in range(3):\n",
        "      # define the winning sequence list\n",
        "      winning_sequence = []\n",
        "      for col in range(3):\n",
        "        # if found the same next element in the row\n",
        "        if self.position[row , col] == self.second_player :\n",
        "          # update winning sequence\n",
        "          winning_sequence.append((row,col)) \n",
        "        # if we have 3 elements in the row \n",
        "        if len(winning_sequence) == 3 :\n",
        "          return True\n",
        "\n",
        "    # 1st diagonal sequence detection\n",
        "    # define the winning sequence list\n",
        "    winning_sequence = []\n",
        "    for row in range(3):\n",
        "      # init column\n",
        "      col = row\n",
        "      if self.position[row , col] == self.second_player :\n",
        "        # update winning sequence\n",
        "        winning_sequence.append((row,col)) \n",
        "      # if we have 3 elements in the row \n",
        "      if len(winning_sequence) == 3 :\n",
        "        return True\n",
        "\n",
        "    # 2nd diagonal sequence detection  \n",
        "    # define the winning sequence list\n",
        "    winning_sequence = []\n",
        "    # loop over board rows\n",
        "    for row in range(3):\n",
        "      # init column\n",
        "      col = 3-row-1\n",
        "      if self.position[row , col] == self.second_player :\n",
        "        # update winning sequence\n",
        "        winning_sequence.append((row,col)) \n",
        "      # if we have 3 elements in the row \n",
        "      if len(winning_sequence) == 3 :\n",
        "        return True\n",
        "    return False\n",
        "\n",
        "\n",
        "  # generate legal moves\n",
        "  def generate_moves(self):\n",
        "    boards = [] #list of objects\n",
        "    for row in range(3):\n",
        "      for col in range(3):\n",
        "        # make sure the current position is empty\n",
        "        if self.position[row,col] == self.empty_place :\n",
        "          # append available actions/board state to action list\n",
        "          boards.append(self.make_move(row,col))\n",
        "    # return the list of available actions (board class instances)\n",
        "    return boards\n",
        "\n",
        "  # implement make move\n",
        "  def make_move(self,row,col):\n",
        "    #create new board instance that inherits from the current state\n",
        "    board = XO_Board(self)\n",
        "    #make move \n",
        "    board.position[row,col] = self.first_player\n",
        "    #swap players\n",
        "    (board.first_player , board.second_player) = (board.second_player , board.first_player)\n",
        "    return board\n",
        "\n",
        "  # print the board state\n",
        "  def __str__(self):\n",
        "    # define board string representation\n",
        "    board_str = ''\n",
        "    for row in range(3):\n",
        "      for col in range(3):\n",
        "        board_str += ' %s' % self.position[row,col]\n",
        "      # print new line \n",
        "      board_str += '\\n'\n",
        "\n",
        "    # side to move \n",
        "    if self.first_player == self.user_input:\n",
        "      board_str = '\\n---------------------------\\n \"Your Turn ==>  \"%s\" to go\"   \\n---------------------------\\n\\n' %self.user_input + board_str\n",
        "    else:\n",
        "      board_str = '\\n---------------------------\\n \"Agent Turn\"    \\n---------------------------\\n\\n' + board_str\n",
        "    return board_str\n",
        "\n",
        "  def get_state(self):\n",
        "    board_str = ''\n",
        "    for row in range(3):\n",
        "      for col in range(3):\n",
        "        board_str += ' %s' % self.position[row,col]\n",
        "      board_str += '\\n'\n",
        "      \n",
        "    print(board_str)\n",
        "\n",
        "  # implement make move\n",
        "  # def make_agent_move(self,row,col):\n",
        "  #   self.position[row,col] = self.agent_player\n",
        "  #   (board.mcts_player , board.agent_player) = (board.agent_player , board.mcts_player)\n",
        "    \n",
        "  def step(self, action, mask): #action 1-9\n",
        "    '''\n",
        "    action : 1->9\n",
        "    '''\n",
        "    reward = 0\n",
        "    if (is_smart_action(self.position_list(), action-1)):\n",
        "      reward+= self.SMART_ACTION_REWARD\n",
        "\n",
        "    state = self.position_list()\n",
        "    if state[action-1]==1 or state[action-1]==-1: #action is not available\n",
        "      print(f'action not avaliable action<0,8> {action-1} , satae {state}, mask {mask}')###\n",
        "      # env.get_state()###\n",
        "      return state, self.STUPID_ACTION_REWARD, False, state\n",
        "\n",
        "    ######### agent  #########\n",
        "    ######### agent  #########\n",
        "\n",
        "    row, col = self.action_to_ids(action)\n",
        "    # print('before agent',self.first_player)\n",
        "    self.__dict__ = deepcopy(self.make_move(row, col).__dict__)\n",
        "\n",
        "    agent_win = self.is_win()\n",
        "    if agent_win:\n",
        "      self.agent_winner+=1\n",
        "      print('agent won ',self.agent_winner, ' eps ',self. eps_threshold)###\n",
        "      # self.get_state()###\n",
        "      reward+=self.WIN_REWARD\n",
        "      return state, reward, True, None \n",
        "    elif self.is_draw():\n",
        "      self.draw+=1\n",
        "      print('draw ', self.draw, ' eps ',self. eps_threshold)###\n",
        "      # self.get_state()###\n",
        "      reward+=self.DRAW_REWARD\n",
        "      return state, reward, True, None \n",
        "    # print('agent [x]')###\n",
        "    # self.get_state()###\n",
        "\n",
        "    ######### mcts  #########\n",
        "    ######### mcts  #########\n",
        "    #self.EPS_START = 1.0 self.EPS_END = 0.9\n",
        "    # self.eps_threshold = self.EPS_END + (self.EPS_START - self.EPS_END) * \\\n",
        "    #     math.exp(-1. * steps_done / self.EPS_DECAY)\n",
        "\n",
        "    self.eps_threshold = 0.9     # the oponnent will play 90% of the time random and 10% MCTS \n",
        "    sample = random.random()\n",
        "    if sample >self.eps_threshold: #use mcts 1.0->0.9\n",
        "      best_mcts_move = mcts.search(self,800)\n",
        "      # make AI Agent move ....\n",
        "      try:\n",
        "          self.__dict__ = deepcopy(best_mcts_move.board.__dict__)\n",
        "          \n",
        "      except:\n",
        "          raise Exception \n",
        "\n",
        "    else:  #choose random action\n",
        "        mask[action-1] = False #action played by the agent\n",
        "        while True:\n",
        "          r_action=random.randrange(n_actions)\n",
        "          if mask[r_action]: #available action\n",
        "            row, col = self.action_to_ids(r_action+1)\n",
        "            # print('random')\n",
        "            self.__dict__ = deepcopy(self.make_move(row, col).__dict__)\n",
        "            break\n",
        "\n",
        "    mcts_win = self.is_win()\n",
        "    if mcts_win:\n",
        "      self.mcts_winner+=1\n",
        "      print('mcts won ',self.mcts_winner,' eps ',self. eps_threshold)###\n",
        "      # self.get_state()###\n",
        "      reward+=self.LOSS_REWARD\n",
        "      return state, reward, True, None \n",
        "    elif self.is_draw():\n",
        "      self.draw+=1\n",
        "      print('draw ',self.draw, ' eps ', self. eps_threshold)\n",
        "      # self.get_state()###\n",
        "      reward+=self.DRAW_REWARD\n",
        "      return state, reward, True, None \n",
        "    # print('mcts [o]')###\n",
        "    # self.get_state()###\n",
        "    \n",
        "\n",
        "    return state, reward, False, self.position_list()   #s, reward, done, new_s\n",
        "\n",
        "\n",
        "  def action_to_ids(self, action):\n",
        "    if action==1:\n",
        "      row=0;col=0\n",
        "    elif action==2:\n",
        "      row=0;col=1\n",
        "    elif action==3:\n",
        "      row=0;col=2\n",
        "    elif action==4:\n",
        "      row=1;col=0\n",
        "    elif action==5:\n",
        "      row=1;col=1  \n",
        "    elif action==6:\n",
        "      row=1;col=2    \n",
        "    elif action==7:\n",
        "      row=2;col=0\n",
        "    elif action==8:\n",
        "      row=2;col=1\n",
        "    elif action==9:\n",
        "      row=2;col=2\n",
        "    else:\n",
        "      raise Exception()\n",
        "    \n",
        "    \n",
        "    return row, col\n",
        "  \n",
        "\n",
        "  def action_sapce(self):\n",
        "    return [1,2,3,4,5,6,7,8,9]\n",
        "\n",
        "  def position_list(self):\n",
        "    state = []\n",
        "    for i in list(self.position.values()):\n",
        "      if i=='-':\n",
        "        state.append(0)\n",
        "      elif i=='x':\n",
        "        state.append(1)\n",
        "      elif i=='o':\n",
        "        state.append(-1)\n",
        "\n",
        "    return state"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jWREXM0vMflX"
      },
      "source": [
        "**Try to initialize the board using the environment:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y7zU3BGjMYC8",
        "outputId": "2150d597-b6f2-487c-fa7e-ad97f00e8ff8"
      },
      "source": [
        "env = XO_Board()\n",
        "mcts = MCTS()\n",
        "env.init_board()\n",
        "env.get_state()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " - - -\n",
            " - - -\n",
            " - - -\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ddGo5bSCMz-q"
      },
      "source": [
        "**check if the action is smart action (in order to give the agent a reward):**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aiqe5u7TMm3g"
      },
      "source": [
        "def is_smart_action(position_list, a): #<0,8>\n",
        "  o=2\n",
        "  if a<3: #0,1,2\n",
        "    if position_list[:3].count(o)==2:\n",
        "      return True\n",
        "  if a>=3 and a<6: #3,4,5\n",
        "    if position_list[3:6].count(o)==2:\n",
        "      return True\n",
        "  if position_list[6:].count(o)==2:\n",
        "    return True\n",
        "\n",
        "  if position_list[4]==o:#center\n",
        "    if a==0 and position_list[8]==o:\n",
        "      return True\n",
        "    elif a==2 and position_list[6]==o:\n",
        "      return True\n",
        "    elif a==6 and position_list[2]==o:\n",
        "      return True\n",
        "    elif a==8 and position_list[2]==o:\n",
        "      return True\n",
        "  if a==0 or a==3 or a==6:\n",
        "    if [position_list[0], position_list[3], position_list[6]].count(o)==2:\n",
        "      return True\n",
        "  if a==1 or a==4 or a==7:\n",
        "    if [position_list[1], position_list[4], position_list[7]].count(o)==2:\n",
        "      return True\n",
        "  if a==2 or a==5 or a==8:\n",
        "    if [position_list[2], position_list[5], position_list[8]].count(o)==2:\n",
        "      return True\n",
        "  if a==4:\n",
        "    if position_list[0]==o and position_list[8]==o:\n",
        "      return True\n",
        "    elif position_list[2]==o and position_list[6]==o:\n",
        "      return True\n",
        "\n",
        "  return False"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ReE2rp4HNR5i"
      },
      "source": [
        "#DQN:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v0sggQZWX55E"
      },
      "source": [
        "**Setting up the training environment :**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T6vDjggFYFwY"
      },
      "source": [
        "**Fix the Seed**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13KPD0yQX_zj"
      },
      "source": [
        "import random\n",
        "import torch\n",
        "import numpy as np\n",
        "seed= 0\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kR0_XN2_NIKJ"
      },
      "source": [
        "import math\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import namedtuple, deque\n",
        "from itertools import count\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as T\n",
        "\n",
        "\n",
        "# env = gym.make('CartPole-v0').unwrapped\n",
        "\n",
        "# set up matplotlib\n",
        "is_ipython = 'inline' in matplotlib.get_backend()\n",
        "if is_ipython:\n",
        "    from IPython import display\n",
        "\n",
        "plt.ion()\n",
        "\n",
        "# if gpu is to be used\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "%matplotlib inline"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eg5i2XEwNYtb"
      },
      "source": [
        "Transition = namedtuple('Transition',\n",
        "                        ('state', 'action', 'next_state', 'reward'))\n",
        "\n",
        "\n",
        "class ReplayMemory(object):\n",
        "\n",
        "    def __init__(self, capacity):\n",
        "        self.memory = deque([],maxlen=capacity)\n",
        "\n",
        "    def push(self, *args):\n",
        "        \"\"\"Save a transition\"\"\"\n",
        "        self.memory.append(Transition(*args))\n",
        "\n",
        "    def sample(self, batch_size): #sample random batch\n",
        "        return random.sample(self.memory, batch_size)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.memory)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ItepuHZNepn"
      },
      "source": [
        "class DQN(nn.Module):\n",
        "\n",
        "    def __init__(self, outputs=9, num_embeddings=3, embedding_dim=1):\n",
        "        super(DQN, self).__init__()\n",
        "        self.num_embeddings = num_embeddings\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.outputs = outputs\n",
        "        # self.emb = nn.Embedding(num_embeddings=self.num_embeddings, embedding_dim=self.embedding_dim)\n",
        "        #[0, 2, 0, 1, 0, 0, 0, 0, 0] ==> 9x16\n",
        "        \n",
        "        self.linear1 = nn.Linear( 9,  64) #16*9 x 16*9\n",
        "        # self.linear2 = nn.Linear( 64, 128)\n",
        "        self.linear2 = nn.Linear( 64, 64)\n",
        "        self.output = nn.Linear(64, self.outputs)\n",
        "\n",
        "    # Called with either one element to determine next action, or a batch\n",
        "    # during optimization. Returns tensor([[left0exp,right0exp]...]).\n",
        "    def forward(self, x):\n",
        "        # print(x.shape,x)\n",
        "        # x = self.emb(x)\n",
        "        # print('shape ',x.shape)\n",
        "        # x = x.view(-1,9*self.embedding_dim)\n",
        "        # print('f shape ',x.shape)\n",
        "        x=x.float()\n",
        "        # print('xxxxx ',x)\n",
        "        x = F.relu(self.linear1(x))\n",
        "        x = F.relu(self.linear2(x))\n",
        "        # x = F.relu(self.linear3(x))\n",
        "        return self.output(x)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmUpZYLhNoa5"
      },
      "source": [
        "#Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D59qHXa0hPge"
      },
      "source": [
        "# Training parameters:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qdmL6l6khN_h"
      },
      "source": [
        "BATCH_SIZE = 256\n",
        "GAMMA = 0.999\n",
        "EPS_START = 0.9\n",
        "EPS_END = 0.05\n",
        "EPS_DECAY = 5000000\n",
        "TARGET_UPDATE = 250\n",
        "MEMORY_SIZE = 800000\n",
        "steps_done = 0\n",
        "n_actions = 9"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tlZHAdvpy5TU"
      },
      "source": [
        "policy_net = DQN(outputs=n_actions, num_embeddings=3, embedding_dim=16).to(device)\n",
        "target_net = DQN(outputs=n_actions, num_embeddings=3, embedding_dim=16).to(device)\n",
        "target_net.load_state_dict(policy_net.state_dict())\n",
        "target_net.eval()\n",
        "\n",
        "optimizer = optim.Adam(policy_net.parameters(),lr=0.0001)\n",
        "                       \n",
        "\n",
        "def select_action(state, policy_net,mask=None):  \n",
        "      global steps_done\n",
        "      global eps_threshold\n",
        "      sample = random.random()\n",
        "      eps_threshold = EPS_END + (EPS_START - EPS_END) * \\\n",
        "          math.exp(-1. * steps_done / EPS_DECAY)\n",
        "      steps_done += 1\n",
        "      if sample > eps_threshold:\n",
        "          # print('select action, agent',eps_threshold)\n",
        "          with torch.no_grad():\n",
        "              # t.max(1) will return largest column value of each row.\n",
        "              # second column on max result is index of where max element was\n",
        "              # found, so we pick action with the larger expected reward.\n",
        "              if mask is not None:\n",
        "                # mask = np.array([1,1,1,0,0,0,1,1,1]) #mask =1 where empty\n",
        "                ids = torch.tensor(np.where(mask)).squeeze()\n",
        "                p = policy_net(state).squeeze().cpu()\n",
        "                max_value = p[ids].max(0)[0].view(1)\n",
        "                # print(f'select action agent ids: {ids} p[ids].max(0)[1] {p[ids].max(0)[1]}')\n",
        "                # return p[ids].max(0)[1].view(1)\n",
        "                max_index = (p == max_value).nonzero(as_tuple=True)[0][0].view(1)\n",
        "                # print('action =  ' , max_index)\n",
        "                return max_index\n",
        "              else:\n",
        "                return policy_net(state).max(1)[1].view(1)\n",
        "\n",
        "      else:\n",
        "          # print('select action, random',eps_threshold)\n",
        "          while True:\n",
        "            action=random.randrange(n_actions)\n",
        "            if mask[action]:\n",
        "              break\n",
        "          return torch.tensor([action], device=device, dtype=torch.long)\n",
        "\n",
        "\n",
        "episode_durations = []\n",
        "\n",
        "def plot_durations(episode_durations):\n",
        "    plt.figure(2)\n",
        "    plt.clf()\n",
        "    durations_t = torch.tensor(episode_durations, dtype=torch.float)\n",
        "    plt.title('Training...')\n",
        "    plt.xlabel('Episode')\n",
        "    plt.ylabel('Duration')\n",
        "    plt.plot(durations_t.numpy())\n",
        "    # Take 100 episode averages and plot them too\n",
        "    if len(durations_t) >= 100:\n",
        "        means = durations_t.unfold(0, 100, 1).mean(1).view(-1)\n",
        "        means = torch.cat((torch.zeros(99), means))\n",
        "        plt.plot(means.numpy())\n",
        "\n",
        "\n",
        "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
        "    if is_ipython:\n",
        "        display.clear_output(wait=True)\n",
        "        display.display(plt.gcf())"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kgae0YPVNwd3"
      },
      "source": [
        "criterion = nn.SmoothL1Loss() #nn.MSELoss() \n",
        "\n",
        "def optimize_model(criterion=criterion):\n",
        "\n",
        "    transitions = memory.sample(BATCH_SIZE)\n",
        "    # Transpose the batch (see https://stackoverflow.com/a/19343/3343043 for\n",
        "    # detailed explanation). This converts batch-array of Transitions to Transition of batch-arrays.\n",
        "    batch = Transition(*zip(*transitions)) #[(state, action, next_state, reward)]\n",
        "\n",
        "\n",
        "    non_final_mask = torch.tensor(tuple(map(lambda s: s is not None,\n",
        "                                          batch.next_state)), device=device, dtype=torch.bool) # s=[2,3,None,4] ==> tensor([ True,  True, False,  True])\n",
        "    non_final_next_states = torch.stack([s for s in batch.next_state\n",
        "                                                if s is not None]).to(device)\n",
        "\n",
        "    state_batch = torch.stack(batch.state)\n",
        "    # state_batch = [[0,2,1,1,0,2,1,2,1],\n",
        "    #                [0,1,2,0,0,0,0,1,0]]\n",
        "    \n",
        "    action_batch = torch.stack(batch.action)\n",
        "    # action_batch = [1,3]\n",
        "    reward_batch = torch.stack(batch.reward)\n",
        "    #reward_batch = [-1,0]\n",
        "    # print('batch non_final_next_states',non_final_next_states))###\n",
        "    # print('batch state_batch',state_batch))###\n",
        "    # print('batch action_batch',action_batch))###\n",
        "    # print('batch reward_batch',reward_batch))###\n",
        "\n",
        "    # Compute Q(s_t, a) - the model computes Q(s_t), then we select the\n",
        "    # columns of actions taken. These are the actions which would've been taken\n",
        "    # for each batch state according to policy_net\n",
        "    state_action_values = policy_net(state_batch.to(device)).gather(1, action_batch.to(device))  #Qo(s,a) == state_action_values = [22,14] for action_batch= [1,3]\n",
        "\n",
        "    # Compute V(s_{t+1}) for all next states.\n",
        "    # Expected values of actions for non_final_next_states are computed based\n",
        "    # on the \"older\" target_net; selecting their best reward with max(1)[0].\n",
        "    # This is merged based on the mask, such that we'll have either the expected\n",
        "    # state value or 0 in case the state was final.\n",
        "    next_state_values = torch.zeros(BATCH_SIZE, device=device)\n",
        "    #next_state_values[final_state]=0 (the next value for the final state is 0)\n",
        "    next_state_values[non_final_mask] = target_net(non_final_next_states.to(device)).max(1)[0].detach() #max[Qt(s,a)] \n",
        "    # Compute the expected Q values\n",
        "    expected_state_action_values = reward_batch + (GAMMA * next_state_values.view(256,1))\n",
        "\n",
        "    # Compute Huber loss\n",
        "    criterion = nn.SmoothL1Loss()\n",
        "    # print('state_action_values, expected_state_action_values.unsqueeze(1)'))###\n",
        "    # print(state_action_values, expected_state_action_values.unsqueeze(1)))###\n",
        "    loss = criterion(state_action_values, expected_state_action_values.unsqueeze(1))\n",
        "    # print('shape ',state_action_values.shape, expected_state_action_values.shape)\n",
        "    # Optimize the model\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    # for param in policy_net.parameters():\n",
        "    #     param.grad.data.clamp_(-1, 1)\n",
        "    optimizer.step()\n",
        "\n",
        "    return loss.item(), state_action_values.mean().item()\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g39QV5D_TRPz"
      },
      "source": [
        "**Training Loop :**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JYnlrNcYZmNV"
      },
      "source": [
        "# Trainig without Mask (No Negative reward for non-available action):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "VUT5wwqlN2uI",
        "outputId": "f251b41b-6d29-4616-8f63-c7efedc78810"
      },
      "source": [
        "#env.step(action) -> s, reward, done, s'\n",
        "#optimize_model\n",
        "env = XO_Board()\n",
        "mcts = MCTS()\n",
        "env.init_board()\n",
        "memory = ReplayMemory(MEMORY_SIZE)\n",
        "\n",
        "losses_list = []\n",
        "num_episodes = 15000\n",
        "reward_list=[]\n",
        "q_list=[]\n",
        "tr_eps=[]\n",
        "for i_episode in range(num_episodes):\n",
        "    episode_loss=[]\n",
        "    episode_q = []\n",
        "    episode_reward=[]\n",
        "    print('game #num: ',i_episode+1)\n",
        "    # Initialize the environment and state\n",
        "    env.init_board(empty=False)\n",
        "    # last_screen = get_screen()\n",
        "    # current_screen = get_screen()\n",
        "    state = env.position_list()#current_screen - last_screen\n",
        "    for t in count():\n",
        "        # Select and perform an action\n",
        "        mask=[]\n",
        "        for i in env.position_list():\n",
        "          mask.append(not (i==-1 or i==1))\n",
        "        action = select_action(torch.tensor(state).to(device), policy_net, mask=np.array([1,1,1,1,1,1,1,1,1])) #0->8np.array(mask)\n",
        "        action = action.cpu()\n",
        "        _, reward, done, new_s = env.step(action.item()+1,mask) #<1,9>\n",
        "        # print('new s', new_s)\n",
        "        episode_reward.append(reward)\n",
        "        \n",
        "        reward = torch.tensor([reward], device=device)\n",
        "        # Observe new state\n",
        "        # last_screen = current_screen\n",
        "        # current_screen = get_screen()\n",
        "        # if not done:\n",
        "        #     next_state = new_s #current_screen - last_screen\n",
        "        # else:\n",
        "        #     next_state = None\n",
        "\n",
        "        # Store the transition in memory\n",
        "        # print('push')###\n",
        "        if new_s:\n",
        "          new_s = torch.tensor(new_s)\n",
        "          # print(torch.tensor(state), action, reward, new_s))###\n",
        "        # else: ###\n",
        "          # print('new state is None')###\n",
        "          # print(torch.tensor(state), action, reward)###\n",
        "        \n",
        "        if not np.all(np.array(torch.tensor(state))== np.array(new_s)):\n",
        "          memory.push(torch.tensor(state), action, new_s, reward)\n",
        "        # else:\n",
        "        #   print('eorrrrrrrrrr in adding the data sample')\n",
        "\n",
        "        # Move to the next state\n",
        "        state = new_s\n",
        "\n",
        "        # Perform one step of the optimization (on the policy network)\n",
        "        # print('memoooory ',len(memory))\n",
        "        if len(memory) > BATCH_SIZE:\n",
        "          loss, q = optimize_model() #BSGD\n",
        "          episode_q.append(q)\n",
        "          episode_loss.append(loss)\n",
        "          \n",
        "          # print('lossssssss ',loss)\n",
        "\n",
        "        if done:\n",
        "            episode_durations.append(t + 1)\n",
        "            # episode_reward = reward\n",
        "            break\n",
        "\n",
        "        tr_eps.append(eps_threshold)\n",
        "    print('################################################################################################')\n",
        "    print('episode_reward : ' , episode_reward)\n",
        "    print('################################################################################################')\n",
        "          \n",
        "\n",
        "    reward_list.append(np.sum(episode_reward))\n",
        "    q_list.append(np.mean(episode_q))\n",
        "    losses_list.append(np.mean(episode_loss))\n",
        "    # Update the target network, copying all weights and biases in DQN\n",
        "    if i_episode % TARGET_UPDATE == 0:\n",
        "        target_net.load_state_dict(policy_net.state_dict())\n",
        "    print('game loss: ',np.mean(episode_loss), 'q value',np.mean(episode_q), ' reward :',np.sum(episode_reward))\n",
        "\n",
        "print('Complete')\n",
        "# env.render()\n",
        "# env.close()\n",
        "plt.ioff()\n",
        "plt.plot(losses_list)\n",
        "plt.show()\n",
        "# plot_durations(episode_durations)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "game #num:  1\n",
            "action not avaliable action<0,8> 4 , satae [0, 0, 0, -1, -1, 1, -1, 0, 1], mask [True, True, True, False, False, False, False, True, False]\n",
            "mcts won  1  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  nan q value nan  reward : -1\n",
            "game #num:  2\n",
            "action not avaliable action<0,8> 5 , satae [0, -1, 0, 0, 0, 1, 0, 0, 0], mask [True, False, True, True, True, False, True, True, True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:28: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.\n",
            "  out=out, **kwargs)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "action not avaliable action<0,8> 0 , satae [-1, -1, 0, 1, 0, 1, 0, 0, 0], mask [False, False, True, False, True, False, True, True, True]\n",
            "action not avaliable action<0,8> 2 , satae [-1, -1, 1, 1, 0, 1, 0, -1, 0], mask [False, False, False, False, True, False, True, False, True]\n",
            "action not avaliable action<0,8> 0 , satae [-1, -1, 1, 1, 0, 1, 0, -1, 0], mask [False, False, False, False, True, False, True, False, True]\n",
            "action not avaliable action<0,8> 0 , satae [-1, -1, 1, 1, 0, 1, 0, -1, 0], mask [False, False, False, False, True, False, True, False, True]\n",
            "action not avaliable action<0,8> 0 , satae [-1, -1, 1, 1, 0, 1, 0, -1, 0], mask [False, False, False, False, True, False, True, False, True]\n",
            "action not avaliable action<0,8> 1 , satae [-1, -1, 1, 1, 0, 1, 0, -1, 0], mask [False, False, False, False, True, False, True, False, True]\n",
            "action not avaliable action<0,8> 5 , satae [-1, -1, 1, 1, 0, 1, 1, -1, -1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 0 , satae [-1, -1, 1, 1, 0, 1, 1, -1, -1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 3 , satae [-1, -1, 1, 1, 0, 1, 1, -1, -1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [-1, -1, 1, 1, 0, 1, 1, -1, -1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [-1, -1, 1, 1, 0, 1, 1, -1, -1], mask [False, False, False, False, True, False, False, False, False]\n",
            "agent won  1  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  nan q value nan  reward : 1\n",
            "game #num:  3\n",
            "action not avaliable action<0,8> 0 , satae [-1, 0, -1, 0, 1, 0, 0, 1, 0], mask [False, True, False, True, False, True, True, False, True]\n",
            "action not avaliable action<0,8> 0 , satae [-1, 0, -1, 0, 1, 0, 0, 1, 0], mask [False, True, False, True, False, True, True, False, True]\n",
            "agent won  2  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  nan q value nan  reward : 1\n",
            "game #num:  4\n",
            "action not avaliable action<0,8> 3 , satae [-1, 0, -1, 1, 0, -1, -1, 1, 1], mask [False, True, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 0 , satae [-1, 0, -1, 1, 0, -1, -1, 1, 1], mask [False, True, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 5 , satae [-1, 0, -1, 1, 0, -1, -1, 1, 1], mask [False, True, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 0 , satae [-1, 0, -1, 1, 0, -1, -1, 1, 1], mask [False, True, False, False, True, False, False, False, False]\n",
            "mcts won  2  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  nan q value nan  reward : -1\n",
            "game #num:  5\n",
            "action not avaliable action<0,8> 6 , satae [0, -1, 0, -1, 0, 0, 1, 0, 0], mask [True, False, True, False, True, True, False, True, True]\n",
            "action not avaliable action<0,8> 6 , satae [0, -1, 0, -1, 0, 0, 1, 0, 0], mask [True, False, True, False, True, True, False, True, True]\n",
            "action not avaliable action<0,8> 6 , satae [0, -1, -1, -1, -1, 1, 1, 1, 0], mask [True, False, False, False, False, False, False, False, True]\n",
            "action not avaliable action<0,8> 7 , satae [0, -1, -1, -1, -1, 1, 1, 1, 0], mask [True, False, False, False, False, False, False, False, True]\n",
            "action not avaliable action<0,8> 3 , satae [0, -1, -1, -1, -1, 1, 1, 1, 0], mask [True, False, False, False, False, False, False, False, True]\n",
            "action not avaliable action<0,8> 5 , satae [0, -1, -1, -1, -1, 1, 1, 1, 0], mask [True, False, False, False, False, False, False, False, True]\n",
            "draw  1  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "################################################################################################\n",
            "game loss:  nan q value nan  reward : 0\n",
            "game #num:  6\n",
            "action not avaliable action<0,8> 7 , satae [0, -1, 1, 0, 0, 0, -1, -1, 1], mask [True, False, False, True, True, True, False, False, False]\n",
            "action not avaliable action<0,8> 4 , satae [-1, -1, 1, 0, 1, 0, -1, -1, 1], mask [False, False, False, True, False, True, False, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [-1, -1, 1, 0, 1, 0, -1, -1, 1], mask [False, False, False, True, False, True, False, False, False]\n",
            "action not avaliable action<0,8> 4 , satae [-1, -1, 1, 0, 1, 0, -1, -1, 1], mask [False, False, False, True, False, True, False, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [-1, -1, 1, 0, 1, 0, -1, -1, 1], mask [False, False, False, True, False, True, False, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [-1, -1, 1, 0, 1, 0, -1, -1, 1], mask [False, False, False, True, False, True, False, False, False]\n",
            "agent won  3  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  nan q value nan  reward : 1\n",
            "game #num:  7\n",
            "action not avaliable action<0,8> 2 , satae [-1, 1, 1, 0, -1, 0, 0, 0, 0], mask [False, False, False, True, False, True, True, True, True]\n",
            "action not avaliable action<0,8> 1 , satae [-1, 1, 1, 0, -1, 0, 0, 0, 0], mask [False, False, False, True, False, True, True, True, True]\n",
            "action not avaliable action<0,8> 0 , satae [-1, 1, 1, 0, -1, 0, 0, 0, 0], mask [False, False, False, True, False, True, True, True, True]\n",
            "action not avaliable action<0,8> 7 , satae [-1, 1, 1, 1, -1, 0, 0, -1, 0], mask [False, False, False, False, False, True, True, False, True]\n",
            "action not avaliable action<0,8> 1 , satae [-1, 1, 1, 1, -1, 0, 0, -1, 0], mask [False, False, False, False, False, True, True, False, True]\n",
            "action not avaliable action<0,8> 7 , satae [-1, 1, 1, 1, -1, 0, 0, -1, 0], mask [False, False, False, False, False, True, True, False, True]\n",
            "action not avaliable action<0,8> 7 , satae [-1, 1, 1, 1, -1, 0, 0, -1, 0], mask [False, False, False, False, False, True, True, False, True]\n",
            "action not avaliable action<0,8> 2 , satae [-1, 1, 1, 1, -1, 0, 0, -1, 0], mask [False, False, False, False, False, True, True, False, True]\n",
            "action not avaliable action<0,8> 2 , satae [-1, 1, 1, 1, -1, 0, 0, -1, 0], mask [False, False, False, False, False, True, True, False, True]\n",
            "action not avaliable action<0,8> 7 , satae [-1, 1, 1, 1, -1, 0, -1, -1, 1], mask [False, False, False, False, False, True, False, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [-1, 1, 1, 1, -1, 0, -1, -1, 1], mask [False, False, False, False, False, True, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [-1, 1, 1, 1, -1, 0, -1, -1, 1], mask [False, False, False, False, False, True, False, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [-1, 1, 1, 1, -1, 0, -1, -1, 1], mask [False, False, False, False, False, True, False, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [-1, 1, 1, 1, -1, 0, -1, -1, 1], mask [False, False, False, False, False, True, False, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [-1, 1, 1, 1, -1, 0, -1, -1, 1], mask [False, False, False, False, False, True, False, False, False]\n",
            "action not avaliable action<0,8> 4 , satae [-1, 1, 1, 1, -1, 0, -1, -1, 1], mask [False, False, False, False, False, True, False, False, False]\n",
            "action not avaliable action<0,8> 1 , satae [-1, 1, 1, 1, -1, 0, -1, -1, 1], mask [False, False, False, False, False, True, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [-1, 1, 1, 1, -1, 0, -1, -1, 1], mask [False, False, False, False, False, True, False, False, False]\n",
            "draw  2  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "################################################################################################\n",
            "game loss:  nan q value nan  reward : 0\n",
            "game #num:  8\n",
            "action not avaliable action<0,8> 5 , satae [1, -1, -1, 1, -1, -1, 0, 1, 0], mask [False, False, False, False, False, False, True, False, True]\n",
            "action not avaliable action<0,8> 0 , satae [1, -1, -1, 1, -1, -1, 0, 1, 0], mask [False, False, False, False, False, False, True, False, True]\n",
            "action not avaliable action<0,8> 5 , satae [1, -1, -1, 1, -1, -1, 0, 1, 0], mask [False, False, False, False, False, False, True, False, True]\n",
            "action not avaliable action<0,8> 5 , satae [1, -1, -1, 1, -1, -1, 0, 1, 0], mask [False, False, False, False, False, False, True, False, True]\n",
            "action not avaliable action<0,8> 1 , satae [1, -1, -1, 1, -1, -1, 0, 1, 0], mask [False, False, False, False, False, False, True, False, True]\n",
            "action not avaliable action<0,8> 7 , satae [1, -1, -1, 1, -1, -1, 0, 1, 0], mask [False, False, False, False, False, False, True, False, True]\n",
            "action not avaliable action<0,8> 4 , satae [1, -1, -1, 1, -1, -1, 0, 1, 0], mask [False, False, False, False, False, False, True, False, True]\n",
            "action not avaliable action<0,8> 1 , satae [1, -1, -1, 1, -1, -1, 0, 1, 0], mask [False, False, False, False, False, False, True, False, True]\n",
            "action not avaliable action<0,8> 3 , satae [1, -1, -1, 1, -1, -1, 0, 1, 0], mask [False, False, False, False, False, False, True, False, True]\n",
            "agent won  4  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  nan q value nan  reward : 1\n",
            "game #num:  9\n",
            "agent won  5  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  nan q value nan  reward : 1\n",
            "game #num:  10\n",
            "action not avaliable action<0,8> 0 , satae [-1, 0, 0, 0, 1, -1, 0, 0, 0], mask [False, True, True, True, False, False, True, True, True]\n",
            "action not avaliable action<0,8> 4 , satae [-1, 0, 0, 0, 1, -1, 0, 0, 0], mask [False, True, True, True, False, False, True, True, True]\n",
            "action not avaliable action<0,8> 2 , satae [-1, 0, 1, 0, 1, -1, 0, 0, -1], mask [False, True, False, True, False, False, True, True, False]\n",
            "action not avaliable action<0,8> 8 , satae [-1, 1, 1, 0, 1, -1, -1, 0, -1], mask [False, False, False, True, False, False, False, True, False]\n",
            "action not avaliable action<0,8> 0 , satae [-1, 1, 1, 0, 1, -1, -1, 0, -1], mask [False, False, False, True, False, False, False, True, False]\n",
            "mcts won  3  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  nan q value nan  reward : -1\n",
            "game #num:  11\n",
            "action not avaliable action<0,8> 0 , satae [1, -1, -1, 1, 0, -1, -1, 1, 0], mask [False, False, False, False, True, False, False, False, True]\n",
            "action not avaliable action<0,8> 3 , satae [1, -1, -1, 1, 0, -1, -1, 1, 0], mask [False, False, False, False, True, False, False, False, True]\n",
            "action not avaliable action<0,8> 7 , satae [1, -1, -1, 1, 0, -1, -1, 1, 0], mask [False, False, False, False, True, False, False, False, True]\n",
            "action not avaliable action<0,8> 6 , satae [1, -1, -1, 1, 0, -1, -1, 1, 0], mask [False, False, False, False, True, False, False, False, True]\n",
            "action not avaliable action<0,8> 6 , satae [1, -1, -1, 1, 0, -1, -1, 1, 0], mask [False, False, False, False, True, False, False, False, True]\n",
            "action not avaliable action<0,8> 7 , satae [1, -1, -1, 1, 0, -1, -1, 1, 0], mask [False, False, False, False, True, False, False, False, True]\n",
            "action not avaliable action<0,8> 3 , satae [1, -1, -1, 1, 0, -1, -1, 1, 0], mask [False, False, False, False, True, False, False, False, True]\n",
            "action not avaliable action<0,8> 2 , satae [1, -1, -1, 1, 0, -1, -1, 1, 0], mask [False, False, False, False, True, False, False, False, True]\n",
            "action not avaliable action<0,8> 5 , satae [1, -1, -1, 1, 0, -1, -1, 1, 0], mask [False, False, False, False, True, False, False, False, True]\n",
            "action not avaliable action<0,8> 2 , satae [1, -1, -1, 1, 0, -1, -1, 1, 0], mask [False, False, False, False, True, False, False, False, True]\n",
            "action not avaliable action<0,8> 2 , satae [1, -1, -1, 1, 0, -1, -1, 1, 0], mask [False, False, False, False, True, False, False, False, True]\n",
            "action not avaliable action<0,8> 6 , satae [1, -1, -1, 1, 0, -1, -1, 1, 0], mask [False, False, False, False, True, False, False, False, True]\n",
            "action not avaliable action<0,8> 6 , satae [1, -1, -1, 1, 0, -1, -1, 1, 0], mask [False, False, False, False, True, False, False, False, True]\n",
            "action not avaliable action<0,8> 6 , satae [1, -1, -1, 1, 0, -1, -1, 1, 0], mask [False, False, False, False, True, False, False, False, True]\n",
            "action not avaliable action<0,8> 1 , satae [1, -1, -1, 1, 0, -1, -1, 1, 0], mask [False, False, False, False, True, False, False, False, True]\n",
            "action not avaliable action<0,8> 5 , satae [1, -1, -1, 1, 0, -1, -1, 1, 0], mask [False, False, False, False, True, False, False, False, True]\n",
            "mcts won  4  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  nan q value nan  reward : -1\n",
            "game #num:  12\n",
            "action not avaliable action<0,8> 0 , satae [1, 0, 0, 0, 1, 0, -1, 0, -1], mask [False, True, True, True, False, True, False, True, False]\n",
            "agent won  6  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  nan q value nan  reward : 1\n",
            "game #num:  13\n",
            "action not avaliable action<0,8> 7 , satae [0, 0, 1, 0, 1, -1, -1, -1, 0], mask [True, True, False, True, False, False, False, False, True]\n",
            "agent won  7  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  nan q value nan  reward : 1\n",
            "game #num:  14\n",
            "action not avaliable action<0,8> 0 , satae [1, 0, 0, 0, 0, 0, 0, 0, -1], mask [False, True, True, True, True, True, True, True, False]\n",
            "action not avaliable action<0,8> 6 , satae [1, 0, 0, 0, 0, 0, -1, 1, -1], mask [False, True, True, True, True, True, False, False, False]\n",
            "action not avaliable action<0,8> 0 , satae [1, 0, 0, 0, 0, 0, -1, 1, -1], mask [False, True, True, True, True, True, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [1, 0, 0, 0, 0, 0, -1, 1, -1], mask [False, True, True, True, True, True, False, False, False]\n",
            "action not avaliable action<0,8> 0 , satae [1, 1, 0, -1, 0, 0, -1, 1, -1], mask [False, False, True, False, True, True, False, False, False]\n",
            "action not avaliable action<0,8> 0 , satae [1, 1, 0, -1, 0, 0, -1, 1, -1], mask [False, False, True, False, True, True, False, False, False]\n",
            "agent won  8  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  nan q value nan  reward : 1\n",
            "game #num:  15\n",
            "action not avaliable action<0,8> 3 , satae [0, 0, -1, 1, 0, 0, 0, -1, 0], mask [True, True, False, False, True, True, True, False, True]\n",
            "agent won  9  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  nan q value nan  reward : 1\n",
            "game #num:  16\n",
            "action not avaliable action<0,8> 1 , satae [1, -1, 0, -1, -1, 1, 0, 1, 0], mask [False, False, True, False, False, False, True, False, True]\n",
            "action not avaliable action<0,8> 5 , satae [1, -1, 0, -1, -1, 1, 0, 1, 0], mask [False, False, True, False, False, False, True, False, True]\n",
            "action not avaliable action<0,8> 3 , satae [1, -1, 0, -1, -1, 1, 0, 1, 0], mask [False, False, True, False, False, False, True, False, True]\n",
            "action not avaliable action<0,8> 3 , satae [1, -1, 0, -1, -1, 1, 0, 1, 0], mask [False, False, True, False, False, False, True, False, True]\n",
            "action not avaliable action<0,8> 4 , satae [1, -1, 0, -1, -1, 1, 0, 1, 0], mask [False, False, True, False, False, False, True, False, True]\n",
            "agent won  10  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  nan q value nan  reward : 1\n",
            "game #num:  17\n",
            "action not avaliable action<0,8> 7 , satae [1, 1, 0, 0, 0, -1, 0, -1, 0], mask [False, False, True, True, True, False, True, False, True]\n",
            "action not avaliable action<0,8> 0 , satae [1, 1, 0, 0, 0, -1, 0, -1, 0], mask [False, False, True, True, True, False, True, False, True]\n",
            "mcts won  5  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  nan q value nan  reward : -1\n",
            "game #num:  18\n",
            "action not avaliable action<0,8> 5 , satae [-1, 0, 0, 1, 0, -1, 0, 1, -1], mask [False, True, True, False, True, False, True, False, False]\n",
            "action not avaliable action<0,8> 0 , satae [-1, 0, 0, 1, 1, -1, -1, 1, -1], mask [False, True, True, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [-1, 0, 0, 1, 1, -1, -1, 1, -1], mask [False, True, True, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 5 , satae [-1, 0, 0, 1, 1, -1, -1, 1, -1], mask [False, True, True, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 4 , satae [-1, 0, 0, 1, 1, -1, -1, 1, -1], mask [False, True, True, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 3 , satae [-1, 0, 0, 1, 1, -1, -1, 1, -1], mask [False, True, True, False, False, False, False, False, False]\n",
            "draw  3  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "################################################################################################\n",
            "game loss:  nan q value nan  reward : 0\n",
            "game #num:  19\n",
            "action not avaliable action<0,8> 0 , satae [-1, 0, 0, 1, 0, 0, 0, 0, 0], mask [False, True, True, False, True, True, True, True, True]\n",
            "mcts won  6  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  nan q value nan  reward : -1\n",
            "game #num:  20\n",
            "agent won  11  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  nan q value nan  reward : 1\n",
            "game #num:  21\n",
            "action not avaliable action<0,8> 2 , satae [1, 0, -1, -1, 1, 0, 0, 0, -1], mask [False, True, False, False, False, True, True, True, False]\n",
            "action not avaliable action<0,8> 7 , satae [1, 1, -1, -1, 1, 0, 0, -1, -1], mask [False, False, False, False, False, True, True, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [1, 1, -1, -1, 1, 0, 0, -1, -1], mask [False, False, False, False, False, True, True, False, False]\n",
            "action not avaliable action<0,8> 1 , satae [1, 1, -1, -1, 1, 0, 0, -1, -1], mask [False, False, False, False, False, True, True, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [1, 1, -1, -1, 1, 0, 0, -1, -1], mask [False, False, False, False, False, True, True, False, False]\n",
            "action not avaliable action<0,8> 1 , satae [1, 1, -1, -1, 1, 0, 0, -1, -1], mask [False, False, False, False, False, True, True, False, False]\n",
            "action not avaliable action<0,8> 4 , satae [1, 1, -1, -1, 1, 0, 0, -1, -1], mask [False, False, False, False, False, True, True, False, False]\n",
            "action not avaliable action<0,8> 3 , satae [1, 1, -1, -1, 1, 0, 0, -1, -1], mask [False, False, False, False, False, True, True, False, False]\n",
            "mcts won  7  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  nan q value nan  reward : -1\n",
            "game #num:  22\n",
            "action not avaliable action<0,8> 4 , satae [0, 0, 0, 0, -1, 0, 0, 0, 0], mask [True, True, True, True, False, True, True, True, True]\n",
            "draw  4  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0]\n",
            "################################################################################################\n",
            "game loss:  nan q value nan  reward : 0\n",
            "game #num:  23\n",
            "action not avaliable action<0,8> 2 , satae [1, -1, -1, -1, 1, 1, 0, 1, -1], mask [False, False, False, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [1, -1, -1, -1, 1, 1, 0, 1, -1], mask [False, False, False, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 1 , satae [1, -1, -1, -1, 1, 1, 0, 1, -1], mask [False, False, False, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 5 , satae [1, -1, -1, -1, 1, 1, 0, 1, -1], mask [False, False, False, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [1, -1, -1, -1, 1, 1, 0, 1, -1], mask [False, False, False, False, False, False, True, False, False]\n",
            "draw  5  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "################################################################################################\n",
            "game loss:  nan q value nan  reward : 0\n",
            "game #num:  24\n",
            "agent won  12  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  nan q value nan  reward : 1\n",
            "game #num:  25\n",
            "action not avaliable action<0,8> 0 , satae [-1, 0, 1, 0, -1, 0, 0, 0, 1], mask [False, True, False, True, False, True, True, True, False]\n",
            "action not avaliable action<0,8> 8 , satae [-1, 0, 1, 1, -1, 0, 0, -1, 1], mask [False, True, False, False, False, True, True, False, False]\n",
            "agent won  13  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  nan q value nan  reward : 1\n",
            "game #num:  26\n",
            "agent won  14  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 1]\n",
            "################################################################################################\n",
            "game loss:  nan q value nan  reward : 1\n",
            "game #num:  27\n",
            "agent won  15  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  nan q value nan  reward : 1\n",
            "game #num:  28\n",
            "action not avaliable action<0,8> 6 , satae [-1, 0, 0, 0, 0, 0, 1, 0, -1], mask [False, True, True, True, True, True, False, True, False]\n",
            "action not avaliable action<0,8> 0 , satae [-1, 0, 0, 0, 0, 0, 1, 0, -1], mask [False, True, True, True, True, True, False, True, False]\n",
            "action not avaliable action<0,8> 0 , satae [-1, -1, 0, 0, 1, 0, 1, 0, -1], mask [False, False, True, True, False, True, False, True, False]\n",
            "action not avaliable action<0,8> 1 , satae [-1, -1, 0, 0, 1, 0, 1, 0, -1], mask [False, False, True, True, False, True, False, True, False]\n",
            "action not avaliable action<0,8> 0 , satae [-1, -1, 0, 0, 1, 0, 1, 0, -1], mask [False, False, True, True, False, True, False, True, False]\n",
            "action not avaliable action<0,8> 0 , satae [-1, -1, 0, 0, 1, 0, 1, 0, -1], mask [False, False, True, True, False, True, False, True, False]\n",
            "action not avaliable action<0,8> 8 , satae [-1, -1, 0, 0, 1, 0, 1, 0, -1], mask [False, False, True, True, False, True, False, True, False]\n",
            "action not avaliable action<0,8> 4 , satae [-1, -1, 0, 0, 1, 1, 1, -1, -1], mask [False, False, True, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [-1, -1, 0, 0, 1, 1, 1, -1, -1], mask [False, False, True, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [-1, -1, 0, 0, 1, 1, 1, -1, -1], mask [False, False, True, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [-1, -1, 0, 0, 1, 1, 1, -1, -1], mask [False, False, True, True, False, False, False, False, False]\n",
            "mcts won  8  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  nan q value nan  reward : -1\n",
            "game #num:  29\n",
            "action not avaliable action<0,8> 3 , satae [0, 0, 0, -1, -1, 1, 0, -1, 1], mask [True, True, True, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [0, 0, 0, -1, -1, 1, 0, -1, 1], mask [True, True, True, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 5 , satae [0, 0, 0, -1, -1, 1, 0, -1, 1], mask [True, True, True, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [1, 0, -1, -1, -1, 1, 0, -1, 1], mask [False, True, False, False, False, False, True, False, False]\n",
            "agent won  16  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  nan q value nan  reward : 1\n",
            "game #num:  30\n",
            "action not avaliable action<0,8> 4 , satae [-1, 0, 0, 0, -1, 1, 0, 1, 0], mask [False, True, True, True, False, False, True, False, True]\n",
            "action not avaliable action<0,8> 5 , satae [-1, 1, 0, 0, -1, 1, -1, 1, 0], mask [False, False, True, True, False, False, False, False, True]\n",
            "mcts won  9  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  nan q value nan  reward : -1\n",
            "game #num:  31\n",
            "action not avaliable action<0,8> 7 , satae [1, 0, 0, 0, 0, 0, 0, -1, 0], mask [False, True, True, True, True, True, True, False, True]\n",
            "action not avaliable action<0,8> 2 , satae [1, 0, -1, 0, 1, 1, -1, -1, 0], mask [False, True, False, True, False, False, False, False, True]\n",
            "agent won  17  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  nan q value nan  reward : 1\n",
            "game #num:  32\n",
            "action not avaliable action<0,8> 6 , satae [-1, -1, 0, 0, 0, 0, 1, 0, 0], mask [False, False, True, True, True, True, False, True, True]\n",
            "action not avaliable action<0,8> 1 , satae [-1, -1, 0, -1, 0, 0, 1, 1, 0], mask [False, False, True, False, True, True, False, False, True]\n",
            "action not avaliable action<0,8> 7 , satae [-1, -1, 0, -1, 0, 0, 1, 1, 0], mask [False, False, True, False, True, True, False, False, True]\n",
            "action not avaliable action<0,8> 6 , satae [-1, -1, 0, -1, 0, 0, 1, 1, 0], mask [False, False, True, False, True, True, False, False, True]\n",
            "agent won  18  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  nan q value nan  reward : 1\n",
            "game #num:  33\n",
            "action not avaliable action<0,8> 7 , satae [0, 0, 0, 0, 0, 0, 0, -1, 0], mask [True, True, True, True, True, True, True, False, True]\n",
            "action not avaliable action<0,8> 7 , satae [1, -1, 0, 0, 1, -1, 0, -1, 0], mask [False, False, True, True, False, False, True, False, True]\n",
            "agent won  19  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  nan q value nan  reward : 1\n",
            "game #num:  34\n",
            "action not avaliable action<0,8> 5 , satae [-1, 1, 1, 0, -1, -1, 1, 0, 0], mask [False, False, False, True, False, False, False, True, True]\n",
            "action not avaliable action<0,8> 0 , satae [-1, 1, 1, 0, -1, -1, 1, 0, 0], mask [False, False, False, True, False, False, False, True, True]\n",
            "agent won  20  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  nan q value nan  reward : 1\n",
            "game #num:  35\n",
            "action not avaliable action<0,8> 0 , satae [-1, -1, 0, 1, 1, 0, -1, 0, 0], mask [False, False, True, False, False, True, False, True, True]\n",
            "action not avaliable action<0,8> 3 , satae [-1, -1, 0, 1, 1, -1, -1, 0, 1], mask [False, False, True, False, False, False, False, True, False]\n",
            "action not avaliable action<0,8> 4 , satae [-1, -1, 0, 1, 1, -1, -1, 0, 1], mask [False, False, True, False, False, False, False, True, False]\n",
            "action not avaliable action<0,8> 5 , satae [-1, -1, 0, 1, 1, -1, -1, 0, 1], mask [False, False, True, False, False, False, False, True, False]\n",
            "action not avaliable action<0,8> 8 , satae [-1, -1, 0, 1, 1, -1, -1, 0, 1], mask [False, False, True, False, False, False, False, True, False]\n",
            "action not avaliable action<0,8> 4 , satae [-1, -1, 0, 1, 1, -1, -1, 0, 1], mask [False, False, True, False, False, False, False, True, False]\n",
            "action not avaliable action<0,8> 8 , satae [-1, -1, 0, 1, 1, -1, -1, 0, 1], mask [False, False, True, False, False, False, False, True, False]\n",
            "action not avaliable action<0,8> 8 , satae [-1, -1, 0, 1, 1, -1, -1, 0, 1], mask [False, False, True, False, False, False, False, True, False]\n",
            "action not avaliable action<0,8> 5 , satae [-1, -1, 0, 1, 1, -1, -1, 0, 1], mask [False, False, True, False, False, False, False, True, False]\n",
            "action not avaliable action<0,8> 6 , satae [-1, -1, 0, 1, 1, -1, -1, 0, 1], mask [False, False, True, False, False, False, False, True, False]\n",
            "action not avaliable action<0,8> 6 , satae [-1, -1, 0, 1, 1, -1, -1, 0, 1], mask [False, False, True, False, False, False, False, True, False]\n",
            "action not avaliable action<0,8> 6 , satae [-1, -1, 0, 1, 1, -1, -1, 0, 1], mask [False, False, True, False, False, False, False, True, False]\n",
            "action not avaliable action<0,8> 5 , satae [-1, -1, 0, 1, 1, -1, -1, 0, 1], mask [False, False, True, False, False, False, False, True, False]\n",
            "action not avaliable action<0,8> 4 , satae [-1, -1, 0, 1, 1, -1, -1, 0, 1], mask [False, False, True, False, False, False, False, True, False]\n",
            "action not avaliable action<0,8> 6 , satae [-1, -1, 0, 1, 1, -1, -1, 0, 1], mask [False, False, True, False, False, False, False, True, False]\n",
            "mcts won  10  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  nan q value nan  reward : -1\n",
            "game #num:  36\n",
            "action not avaliable action<0,8> 4 , satae [0, 1, 0, 0, -1, -1, 0, 0, 0], mask [True, False, True, True, False, False, True, True, True]\n",
            "action not avaliable action<0,8> 4 , satae [1, 1, 0, 0, -1, -1, -1, -1, 1], mask [False, False, True, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [1, 1, 0, 0, -1, -1, -1, -1, 1], mask [False, False, True, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [1, 1, 0, 0, -1, -1, -1, -1, 1], mask [False, False, True, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [1, 1, 0, 0, -1, -1, -1, -1, 1], mask [False, False, True, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 4 , satae [1, 1, 0, 0, -1, -1, -1, -1, 1], mask [False, False, True, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [1, 1, 0, 0, -1, -1, -1, -1, 1], mask [False, False, True, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [1, 1, 0, 0, -1, -1, -1, -1, 1], mask [False, False, True, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 5 , satae [1, 1, 0, 0, -1, -1, -1, -1, 1], mask [False, False, True, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 4 , satae [1, 1, 0, 0, -1, -1, -1, -1, 1], mask [False, False, True, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 1 , satae [1, 1, 0, 0, -1, -1, -1, -1, 1], mask [False, False, True, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 0 , satae [1, 1, 0, 0, -1, -1, -1, -1, 1], mask [False, False, True, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 5 , satae [1, 1, 0, 0, -1, -1, -1, -1, 1], mask [False, False, True, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [1, 1, 0, 0, -1, -1, -1, -1, 1], mask [False, False, True, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [1, 1, 0, 0, -1, -1, -1, -1, 1], mask [False, False, True, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [1, 1, 0, 0, -1, -1, -1, -1, 1], mask [False, False, True, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 4 , satae [1, 1, 0, 0, -1, -1, -1, -1, 1], mask [False, False, True, True, False, False, False, False, False]\n",
            "mcts won  11  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  nan q value nan  reward : -1\n",
            "game #num:  37\n",
            "mcts won  12  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  nan q value nan  reward : -1\n",
            "game #num:  38\n",
            "action not avaliable action<0,8> 7 , satae [0, 0, 0, -1, 0, -1, 0, 1, 0], mask [True, True, True, False, True, False, True, False, True]\n",
            "action not avaliable action<0,8> 7 , satae [0, 0, 0, -1, 0, -1, 0, 1, 0], mask [True, True, True, False, True, False, True, False, True]\n",
            "action not avaliable action<0,8> 5 , satae [0, -1, 1, -1, 0, -1, -1, 1, 1], mask [True, False, False, False, True, False, False, False, False]\n",
            "mcts won  13  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  nan q value nan  reward : -1\n",
            "game #num:  39\n",
            "action not avaliable action<0,8> 0 , satae [1, 0, -1, -1, 1, 1, 0, -1, -1], mask [False, True, False, False, False, False, True, False, False]\n",
            "draw  6  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0]\n",
            "################################################################################################\n",
            "game loss:  nan q value nan  reward : 0\n",
            "game #num:  40\n",
            "action not avaliable action<0,8> 6 , satae [-1, -1, 0, 0, 0, 0, 1, 1, -1], mask [False, False, True, True, True, True, False, False, False]\n",
            "action not avaliable action<0,8> 1 , satae [-1, -1, 0, 0, 0, 0, 1, 1, -1], mask [False, False, True, True, True, True, False, False, False]\n",
            "action not avaliable action<0,8> 0 , satae [-1, -1, 0, 0, 0, 0, 1, 1, -1], mask [False, False, True, True, True, True, False, False, False]\n",
            "action not avaliable action<0,8> 1 , satae [-1, -1, 0, 0, 0, 0, 1, 1, -1], mask [False, False, True, True, True, True, False, False, False]\n",
            "action not avaliable action<0,8> 1 , satae [-1, -1, 0, 0, 0, 0, 1, 1, -1], mask [False, False, True, True, True, True, False, False, False]\n",
            "mcts won  14  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  nan q value nan  reward : -1\n",
            "game #num:  41\n",
            "action not avaliable action<0,8> 2 , satae [0, 0, 1, 0, 0, 0, 0, -1, 0], mask [True, True, False, True, True, True, True, False, True]\n",
            "action not avaliable action<0,8> 2 , satae [-1, -1, 1, 1, 1, 0, 0, -1, 0], mask [False, False, False, False, False, True, True, False, True]\n",
            "action not avaliable action<0,8> 3 , satae [-1, -1, 1, 1, 1, 0, 0, -1, 0], mask [False, False, False, False, False, True, True, False, True]\n",
            "agent won  21  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  nan q value nan  reward : 1\n",
            "game #num:  42\n",
            "action not avaliable action<0,8> 7 , satae [-1, 1, 1, 1, 1, -1, -1, -1, 0], mask [False, False, False, False, False, False, False, False, True]\n",
            "action not avaliable action<0,8> 5 , satae [-1, 1, 1, 1, 1, -1, -1, -1, 0], mask [False, False, False, False, False, False, False, False, True]\n",
            "action not avaliable action<0,8> 1 , satae [-1, 1, 1, 1, 1, -1, -1, -1, 0], mask [False, False, False, False, False, False, False, False, True]\n",
            "action not avaliable action<0,8> 2 , satae [-1, 1, 1, 1, 1, -1, -1, -1, 0], mask [False, False, False, False, False, False, False, False, True]\n",
            "action not avaliable action<0,8> 5 , satae [-1, 1, 1, 1, 1, -1, -1, -1, 0], mask [False, False, False, False, False, False, False, False, True]\n",
            "action not avaliable action<0,8> 1 , satae [-1, 1, 1, 1, 1, -1, -1, -1, 0], mask [False, False, False, False, False, False, False, False, True]\n",
            "action not avaliable action<0,8> 3 , satae [-1, 1, 1, 1, 1, -1, -1, -1, 0], mask [False, False, False, False, False, False, False, False, True]\n",
            "agent won  22  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  nan q value nan  reward : 1\n",
            "game #num:  43\n",
            "action not avaliable action<0,8> 6 , satae [1, 0, -1, -1, 1, -1, 1, 0, 0], mask [False, True, False, False, False, False, False, True, True]\n",
            "action not avaliable action<0,8> 0 , satae [1, 0, -1, -1, 1, -1, 1, 0, 0], mask [False, True, False, False, False, False, False, True, True]\n",
            "mcts won  15  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  nan q value nan  reward : -1\n",
            "game #num:  44\n",
            "action not avaliable action<0,8> 6 , satae [0, 1, 0, -1, 0, 1, -1, 0, 0], mask [True, False, True, False, True, False, False, True, True]\n",
            "action not avaliable action<0,8> 5 , satae [0, 1, 0, -1, 0, 1, -1, 0, 0], mask [True, False, True, False, True, False, False, True, True]\n",
            "action not avaliable action<0,8> 5 , satae [0, 1, 0, -1, 0, 1, -1, 0, 0], mask [True, False, True, False, True, False, False, True, True]\n",
            "action not avaliable action<0,8> 3 , satae [1, 1, -1, -1, 0, 1, -1, 0, 0], mask [False, False, False, False, True, False, False, True, True]\n",
            "action not avaliable action<0,8> 5 , satae [1, 1, -1, -1, 0, 1, -1, 0, 0], mask [False, False, False, False, True, False, False, True, True]\n",
            "action not avaliable action<0,8> 1 , satae [1, 1, -1, -1, 0, 1, -1, 0, 0], mask [False, False, False, False, True, False, False, True, True]\n",
            "action not avaliable action<0,8> 6 , satae [1, 1, -1, -1, 0, 1, -1, -1, 1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 5 , satae [1, 1, -1, -1, 0, 1, -1, -1, 1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [1, 1, -1, -1, 0, 1, -1, -1, 1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [1, 1, -1, -1, 0, 1, -1, -1, 1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 5 , satae [1, 1, -1, -1, 0, 1, -1, -1, 1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 0 , satae [1, 1, -1, -1, 0, 1, -1, -1, 1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [1, 1, -1, -1, 0, 1, -1, -1, 1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 2 , satae [1, 1, -1, -1, 0, 1, -1, -1, 1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 2 , satae [1, 1, -1, -1, 0, 1, -1, -1, 1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [1, 1, -1, -1, 0, 1, -1, -1, 1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [1, 1, -1, -1, 0, 1, -1, -1, 1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [1, 1, -1, -1, 0, 1, -1, -1, 1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 2 , satae [1, 1, -1, -1, 0, 1, -1, -1, 1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 0 , satae [1, 1, -1, -1, 0, 1, -1, -1, 1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [1, 1, -1, -1, 0, 1, -1, -1, 1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 5 , satae [1, 1, -1, -1, 0, 1, -1, -1, 1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 1 , satae [1, 1, -1, -1, 0, 1, -1, -1, 1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 2 , satae [1, 1, -1, -1, 0, 1, -1, -1, 1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [1, 1, -1, -1, 0, 1, -1, -1, 1], mask [False, False, False, False, True, False, False, False, False]\n",
            "agent won  23  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  nan q value nan  reward : 1\n",
            "game #num:  45\n",
            "action not avaliable action<0,8> 3 , satae [0, 0, 0, 1, 0, 0, -1, 1, -1], mask [True, True, True, False, True, True, False, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [0, 0, 0, 1, 0, 0, -1, 1, -1], mask [True, True, True, False, True, True, False, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [0, 0, 0, 1, 0, 0, -1, 1, -1], mask [True, True, True, False, True, True, False, False, False]\n",
            "action not avaliable action<0,8> 5 , satae [0, -1, 0, 1, 0, 1, -1, 1, -1], mask [True, False, True, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [0, -1, 0, 1, 0, 1, -1, 1, -1], mask [True, False, True, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [0, -1, 0, 1, 0, 1, -1, 1, -1], mask [True, False, True, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 5 , satae [0, -1, 0, 1, 0, 1, -1, 1, -1], mask [True, False, True, False, True, False, False, False, False]\n",
            "mcts won  16  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  nan q value nan  reward : -1\n",
            "game #num:  46\n",
            "action not avaliable action<0,8> 6 , satae [0, 1, -1, -1, 1, 1, 1, -1, -1], mask [True, False, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 3 , satae [0, 1, -1, -1, 1, 1, 1, -1, -1], mask [True, False, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 2 , satae [0, 1, -1, -1, 1, 1, 1, -1, -1], mask [True, False, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 2 , satae [0, 1, -1, -1, 1, 1, 1, -1, -1], mask [True, False, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 1 , satae [0, 1, -1, -1, 1, 1, 1, -1, -1], mask [True, False, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 1 , satae [0, 1, -1, -1, 1, 1, 1, -1, -1], mask [True, False, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 3 , satae [0, 1, -1, -1, 1, 1, 1, -1, -1], mask [True, False, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [0, 1, -1, -1, 1, 1, 1, -1, -1], mask [True, False, False, False, False, False, False, False, False]\n",
            "draw  7  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "################################################################################################\n",
            "game loss:  nan q value nan  reward : 0\n",
            "game #num:  47\n",
            "action not avaliable action<0,8> 0 , satae [1, 1, 0, 0, -1, 0, 0, 0, -1], mask [False, False, True, True, False, True, True, True, False]\n",
            "action not avaliable action<0,8> 8 , satae [1, 1, 0, 0, -1, 1, 0, -1, -1], mask [False, False, True, True, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [1, 1, 0, 0, -1, 1, 0, -1, -1], mask [False, False, True, True, False, False, True, False, False]\n",
            "agent won  24  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  nan q value nan  reward : 1\n",
            "game #num:  48\n",
            "action not avaliable action<0,8> 3 , satae [0, 0, -1, 1, 0, 0, 0, 0, 0], mask [True, True, False, False, True, True, True, True, True]\n",
            "action not avaliable action<0,8> 7 , satae [0, 0, -1, 1, 0, 1, 1, -1, -1], mask [True, True, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 2 , satae [0, 0, -1, 1, 0, 1, 1, -1, -1], mask [True, True, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 2 , satae [0, 0, -1, 1, 0, 1, 1, -1, -1], mask [True, True, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 2 , satae [0, 0, -1, 1, 0, 1, 1, -1, -1], mask [True, True, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [0, 0, -1, 1, 0, 1, 1, -1, -1], mask [True, True, False, False, True, False, False, False, False]\n",
            "mcts won  17  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  nan q value nan  reward : -1\n",
            "game #num:  49\n",
            "action not avaliable action<0,8> 3 , satae [0, 1, 0, -1, 1, 0, 1, -1, -1], mask [True, False, True, False, False, True, False, False, False]\n",
            "action not avaliable action<0,8> 2 , satae [0, 1, -1, -1, 1, 1, 1, -1, -1], mask [True, False, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [0, 1, -1, -1, 1, 1, 1, -1, -1], mask [True, False, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 5 , satae [0, 1, -1, -1, 1, 1, 1, -1, -1], mask [True, False, False, False, False, False, False, False, False]\n",
            "draw  8  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "################################################################################################\n",
            "game loss:  nan q value nan  reward : 0\n",
            "game #num:  50\n",
            "action not avaliable action<0,8> 8 , satae [1, 1, 0, 1, 0, -1, -1, 0, -1], mask [False, False, True, False, True, False, False, True, False]\n",
            "action not avaliable action<0,8> 5 , satae [1, 1, 0, 1, 0, -1, -1, 0, -1], mask [False, False, True, False, True, False, False, True, False]\n",
            "action not avaliable action<0,8> 6 , satae [1, 1, 0, 1, 0, -1, -1, 0, -1], mask [False, False, True, False, True, False, False, True, False]\n",
            "agent won  25  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  nan q value nan  reward : 1\n",
            "game #num:  51\n",
            "action not avaliable action<0,8> 4 , satae [0, 0, 1, 0, -1, 0, 0, 0, -1], mask [True, True, False, True, False, True, True, True, False]\n",
            "action not avaliable action<0,8> 5 , satae [1, 0, 1, 1, -1, -1, -1, 0, -1], mask [False, True, False, False, False, False, False, True, False]\n",
            "action not avaliable action<0,8> 4 , satae [1, 0, 1, 1, -1, -1, -1, 0, -1], mask [False, True, False, False, False, False, False, True, False]\n",
            "action not avaliable action<0,8> 5 , satae [1, 0, 1, 1, -1, -1, -1, 0, -1], mask [False, True, False, False, False, False, False, True, False]\n",
            "action not avaliable action<0,8> 5 , satae [1, 0, 1, 1, -1, -1, -1, 0, -1], mask [False, True, False, False, False, False, False, True, False]\n",
            "action not avaliable action<0,8> 8 , satae [1, 0, 1, 1, -1, -1, -1, 0, -1], mask [False, True, False, False, False, False, False, True, False]\n",
            "action not avaliable action<0,8> 5 , satae [1, 0, 1, 1, -1, -1, -1, 0, -1], mask [False, True, False, False, False, False, False, True, False]\n",
            "agent won  26  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  nan q value nan  reward : 1\n",
            "game #num:  52\n",
            "action not avaliable action<0,8> 3 , satae [-1, -1, 0, -1, 1, 1, 1, 1, -1], mask [False, False, True, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [-1, -1, 0, -1, 1, 1, 1, 1, -1], mask [False, False, True, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [-1, -1, 0, -1, 1, 1, 1, 1, -1], mask [False, False, True, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 4 , satae [-1, -1, 0, -1, 1, 1, 1, 1, -1], mask [False, False, True, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [-1, -1, 0, -1, 1, 1, 1, 1, -1], mask [False, False, True, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [-1, -1, 0, -1, 1, 1, 1, 1, -1], mask [False, False, True, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 0 , satae [-1, -1, 0, -1, 1, 1, 1, 1, -1], mask [False, False, True, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [-1, -1, 0, -1, 1, 1, 1, 1, -1], mask [False, False, True, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 4 , satae [-1, -1, 0, -1, 1, 1, 1, 1, -1], mask [False, False, True, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 3 , satae [-1, -1, 0, -1, 1, 1, 1, 1, -1], mask [False, False, True, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 0 , satae [-1, -1, 0, -1, 1, 1, 1, 1, -1], mask [False, False, True, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 5 , satae [-1, -1, 0, -1, 1, 1, 1, 1, -1], mask [False, False, True, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 0 , satae [-1, -1, 0, -1, 1, 1, 1, 1, -1], mask [False, False, True, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [-1, -1, 0, -1, 1, 1, 1, 1, -1], mask [False, False, True, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [-1, -1, 0, -1, 1, 1, 1, 1, -1], mask [False, False, True, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 5 , satae [-1, -1, 0, -1, 1, 1, 1, 1, -1], mask [False, False, True, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 5 , satae [-1, -1, 0, -1, 1, 1, 1, 1, -1], mask [False, False, True, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 0 , satae [-1, -1, 0, -1, 1, 1, 1, 1, -1], mask [False, False, True, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [-1, -1, 0, -1, 1, 1, 1, 1, -1], mask [False, False, True, False, False, False, False, False, False]\n",
            "agent won  27  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  nan q value nan  reward : 1\n",
            "game #num:  53\n",
            "action not avaliable action<0,8> 2 , satae [-1, 0, -1, 1, 0, 0, 0, 1, 0], mask [False, True, False, False, True, True, True, False, True]\n",
            "mcts won  18  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  nan q value nan  reward : -1\n",
            "game #num:  54\n",
            "action not avaliable action<0,8> 6 , satae [0, 1, 0, 0, 0, 0, -1, 0, -1], mask [True, False, True, True, True, True, False, True, False]\n",
            "action not avaliable action<0,8> 1 , satae [0, 1, 0, 0, 0, 0, -1, 0, -1], mask [True, False, True, True, True, True, False, True, False]\n",
            "action not avaliable action<0,8> 5 , satae [-1, 1, 0, 0, 0, 1, -1, 0, -1], mask [False, False, True, True, True, False, False, True, False]\n",
            "agent won  28  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  nan q value nan  reward : 1\n",
            "game #num:  55\n",
            "action not avaliable action<0,8> 0 , satae [-1, 1, 0, 0, 0, 0, 0, 0, 0], mask [False, False, True, True, True, True, True, True, True]\n",
            "action not avaliable action<0,8> 7 , satae [-1, 1, 0, 0, -1, 0, 0, 1, 0], mask [False, False, True, True, False, True, True, False, True]\n",
            "action not avaliable action<0,8> 0 , satae [-1, 1, 0, 0, -1, 0, 0, 1, 0], mask [False, False, True, True, False, True, True, False, True]\n",
            "action not avaliable action<0,8> 1 , satae [-1, 1, 0, 1, -1, -1, 0, 1, 0], mask [False, False, True, False, False, False, True, False, True]\n",
            "mcts won  19  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  nan q value nan  reward : -1\n",
            "game #num:  56\n",
            "action not avaliable action<0,8> 8 , satae [0, -1, 0, 0, 0, 0, 1, -1, 1], mask [True, False, True, True, True, True, False, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [0, -1, 0, 0, 0, 0, 1, -1, 1], mask [True, False, True, True, True, True, False, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [0, -1, 1, -1, 0, 0, 1, -1, 1], mask [True, False, False, False, True, True, False, False, False]\n",
            "agent won  29  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  nan q value nan  reward : 1\n",
            "game #num:  57\n",
            "action not avaliable action<0,8> 0 , satae [1, -1, 0, 1, 1, -1, 0, 0, -1], mask [False, False, True, False, False, False, True, True, False]\n",
            "action not avaliable action<0,8> 3 , satae [1, -1, 0, 1, 1, -1, 0, 0, -1], mask [False, False, True, False, False, False, True, True, False]\n",
            "action not avaliable action<0,8> 0 , satae [1, -1, 1, 1, 1, -1, 0, -1, -1], mask [False, False, False, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 1 , satae [1, -1, 1, 1, 1, -1, 0, -1, -1], mask [False, False, False, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 5 , satae [1, -1, 1, 1, 1, -1, 0, -1, -1], mask [False, False, False, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 0 , satae [1, -1, 1, 1, 1, -1, 0, -1, -1], mask [False, False, False, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [1, -1, 1, 1, 1, -1, 0, -1, -1], mask [False, False, False, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 5 , satae [1, -1, 1, 1, 1, -1, 0, -1, -1], mask [False, False, False, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 5 , satae [1, -1, 1, 1, 1, -1, 0, -1, -1], mask [False, False, False, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 0 , satae [1, -1, 1, 1, 1, -1, 0, -1, -1], mask [False, False, False, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 4 , satae [1, -1, 1, 1, 1, -1, 0, -1, -1], mask [False, False, False, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 0 , satae [1, -1, 1, 1, 1, -1, 0, -1, -1], mask [False, False, False, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 2 , satae [1, -1, 1, 1, 1, -1, 0, -1, -1], mask [False, False, False, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [1, -1, 1, 1, 1, -1, 0, -1, -1], mask [False, False, False, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 0 , satae [1, -1, 1, 1, 1, -1, 0, -1, -1], mask [False, False, False, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 5 , satae [1, -1, 1, 1, 1, -1, 0, -1, -1], mask [False, False, False, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 3 , satae [1, -1, 1, 1, 1, -1, 0, -1, -1], mask [False, False, False, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [1, -1, 1, 1, 1, -1, 0, -1, -1], mask [False, False, False, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [1, -1, 1, 1, 1, -1, 0, -1, -1], mask [False, False, False, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 0 , satae [1, -1, 1, 1, 1, -1, 0, -1, -1], mask [False, False, False, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 1 , satae [1, -1, 1, 1, 1, -1, 0, -1, -1], mask [False, False, False, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 1 , satae [1, -1, 1, 1, 1, -1, 0, -1, -1], mask [False, False, False, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 2 , satae [1, -1, 1, 1, 1, -1, 0, -1, -1], mask [False, False, False, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 0 , satae [1, -1, 1, 1, 1, -1, 0, -1, -1], mask [False, False, False, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 5 , satae [1, -1, 1, 1, 1, -1, 0, -1, -1], mask [False, False, False, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [1, -1, 1, 1, 1, -1, 0, -1, -1], mask [False, False, False, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 5 , satae [1, -1, 1, 1, 1, -1, 0, -1, -1], mask [False, False, False, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 2 , satae [1, -1, 1, 1, 1, -1, 0, -1, -1], mask [False, False, False, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [1, -1, 1, 1, 1, -1, 0, -1, -1], mask [False, False, False, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 1 , satae [1, -1, 1, 1, 1, -1, 0, -1, -1], mask [False, False, False, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 4 , satae [1, -1, 1, 1, 1, -1, 0, -1, -1], mask [False, False, False, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [1, -1, 1, 1, 1, -1, 0, -1, -1], mask [False, False, False, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 0 , satae [1, -1, 1, 1, 1, -1, 0, -1, -1], mask [False, False, False, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 5 , satae [1, -1, 1, 1, 1, -1, 0, -1, -1], mask [False, False, False, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 0 , satae [1, -1, 1, 1, 1, -1, 0, -1, -1], mask [False, False, False, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 0 , satae [1, -1, 1, 1, 1, -1, 0, -1, -1], mask [False, False, False, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 2 , satae [1, -1, 1, 1, 1, -1, 0, -1, -1], mask [False, False, False, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 4 , satae [1, -1, 1, 1, 1, -1, 0, -1, -1], mask [False, False, False, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 4 , satae [1, -1, 1, 1, 1, -1, 0, -1, -1], mask [False, False, False, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 1 , satae [1, -1, 1, 1, 1, -1, 0, -1, -1], mask [False, False, False, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 5 , satae [1, -1, 1, 1, 1, -1, 0, -1, -1], mask [False, False, False, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [1, -1, 1, 1, 1, -1, 0, -1, -1], mask [False, False, False, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 0 , satae [1, -1, 1, 1, 1, -1, 0, -1, -1], mask [False, False, False, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 0 , satae [1, -1, 1, 1, 1, -1, 0, -1, -1], mask [False, False, False, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 0 , satae [1, -1, 1, 1, 1, -1, 0, -1, -1], mask [False, False, False, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 0 , satae [1, -1, 1, 1, 1, -1, 0, -1, -1], mask [False, False, False, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 3 , satae [1, -1, 1, 1, 1, -1, 0, -1, -1], mask [False, False, False, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 0 , satae [1, -1, 1, 1, 1, -1, 0, -1, -1], mask [False, False, False, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 1 , satae [1, -1, 1, 1, 1, -1, 0, -1, -1], mask [False, False, False, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 4 , satae [1, -1, 1, 1, 1, -1, 0, -1, -1], mask [False, False, False, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 4 , satae [1, -1, 1, 1, 1, -1, 0, -1, -1], mask [False, False, False, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 4 , satae [1, -1, 1, 1, 1, -1, 0, -1, -1], mask [False, False, False, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 4 , satae [1, -1, 1, 1, 1, -1, 0, -1, -1], mask [False, False, False, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 0 , satae [1, -1, 1, 1, 1, -1, 0, -1, -1], mask [False, False, False, False, False, False, True, False, False]\n",
            "agent won  30  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  nan q value nan  reward : 1\n",
            "game #num:  58\n",
            "action not avaliable action<0,8> 0 , satae [1, 0, -1, 0, 0, 0, 0, 0, -1], mask [False, True, False, True, True, True, True, True, False]\n",
            "action not avaliable action<0,8> 8 , satae [1, 0, -1, 0, 0, 0, 0, 0, -1], mask [False, True, False, True, True, True, True, True, False]\n",
            "action not avaliable action<0,8> 0 , satae [1, 0, -1, 0, 0, 0, 0, 0, -1], mask [False, True, False, True, True, True, True, True, False]\n",
            "mcts won  20  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  nan q value nan  reward : -1\n",
            "game #num:  59\n",
            "action not avaliable action<0,8> 4 , satae [-1, 1, -1, -1, -1, 1, 1, 1, 0], mask [False, False, False, False, False, False, False, False, True]\n",
            "action not avaliable action<0,8> 0 , satae [-1, 1, -1, -1, -1, 1, 1, 1, 0], mask [False, False, False, False, False, False, False, False, True]\n",
            "action not avaliable action<0,8> 1 , satae [-1, 1, -1, -1, -1, 1, 1, 1, 0], mask [False, False, False, False, False, False, False, False, True]\n",
            "action not avaliable action<0,8> 2 , satae [-1, 1, -1, -1, -1, 1, 1, 1, 0], mask [False, False, False, False, False, False, False, False, True]\n",
            "action not avaliable action<0,8> 5 , satae [-1, 1, -1, -1, -1, 1, 1, 1, 0], mask [False, False, False, False, False, False, False, False, True]\n",
            "action not avaliable action<0,8> 5 , satae [-1, 1, -1, -1, -1, 1, 1, 1, 0], mask [False, False, False, False, False, False, False, False, True]\n",
            "action not avaliable action<0,8> 3 , satae [-1, 1, -1, -1, -1, 1, 1, 1, 0], mask [False, False, False, False, False, False, False, False, True]\n",
            "action not avaliable action<0,8> 1 , satae [-1, 1, -1, -1, -1, 1, 1, 1, 0], mask [False, False, False, False, False, False, False, False, True]\n",
            "action not avaliable action<0,8> 5 , satae [-1, 1, -1, -1, -1, 1, 1, 1, 0], mask [False, False, False, False, False, False, False, False, True]\n",
            "agent won  31  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  nan q value nan  reward : 1\n",
            "game #num:  60\n",
            "agent won  32  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  nan q value nan  reward : 1\n",
            "game #num:  61\n",
            "action not avaliable action<0,8> 1 , satae [0, -1, 0, 1, 0, -1, 0, 0, 0], mask [True, False, True, False, True, False, True, True, True]\n",
            "action not avaliable action<0,8> 4 , satae [1, -1, 0, 1, -1, -1, 0, 1, -1], mask [False, False, True, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 4 , satae [1, -1, 0, 1, -1, -1, 0, 1, -1], mask [False, False, True, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 1 , satae [1, -1, 0, 1, -1, -1, 0, 1, -1], mask [False, False, True, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 4 , satae [1, -1, 0, 1, -1, -1, 0, 1, -1], mask [False, False, True, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 0 , satae [1, -1, 0, 1, -1, -1, 0, 1, -1], mask [False, False, True, False, False, False, True, False, False]\n",
            "agent won  33  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  nan q value nan  reward : 1\n",
            "game #num:  62\n",
            "action not avaliable action<0,8> 5 , satae [0, -1, 0, 0, 1, 1, 0, 0, -1], mask [True, False, True, True, False, False, True, True, False]\n",
            "action not avaliable action<0,8> 5 , satae [0, -1, 1, -1, 1, 1, -1, 1, -1], mask [True, False, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [0, -1, 1, -1, 1, 1, -1, 1, -1], mask [True, False, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [0, -1, 1, -1, 1, 1, -1, 1, -1], mask [True, False, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 1 , satae [0, -1, 1, -1, 1, 1, -1, 1, -1], mask [True, False, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 5 , satae [0, -1, 1, -1, 1, 1, -1, 1, -1], mask [True, False, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 2 , satae [0, -1, 1, -1, 1, 1, -1, 1, -1], mask [True, False, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 1 , satae [0, -1, 1, -1, 1, 1, -1, 1, -1], mask [True, False, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 4 , satae [0, -1, 1, -1, 1, 1, -1, 1, -1], mask [True, False, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [0, -1, 1, -1, 1, 1, -1, 1, -1], mask [True, False, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [0, -1, 1, -1, 1, 1, -1, 1, -1], mask [True, False, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 4 , satae [0, -1, 1, -1, 1, 1, -1, 1, -1], mask [True, False, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 4 , satae [0, -1, 1, -1, 1, 1, -1, 1, -1], mask [True, False, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [0, -1, 1, -1, 1, 1, -1, 1, -1], mask [True, False, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 5 , satae [0, -1, 1, -1, 1, 1, -1, 1, -1], mask [True, False, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 1 , satae [0, -1, 1, -1, 1, 1, -1, 1, -1], mask [True, False, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 1 , satae [0, -1, 1, -1, 1, 1, -1, 1, -1], mask [True, False, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [0, -1, 1, -1, 1, 1, -1, 1, -1], mask [True, False, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [0, -1, 1, -1, 1, 1, -1, 1, -1], mask [True, False, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 3 , satae [0, -1, 1, -1, 1, 1, -1, 1, -1], mask [True, False, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 3 , satae [0, -1, 1, -1, 1, 1, -1, 1, -1], mask [True, False, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 5 , satae [0, -1, 1, -1, 1, 1, -1, 1, -1], mask [True, False, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 3 , satae [0, -1, 1, -1, 1, 1, -1, 1, -1], mask [True, False, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [0, -1, 1, -1, 1, 1, -1, 1, -1], mask [True, False, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 5 , satae [0, -1, 1, -1, 1, 1, -1, 1, -1], mask [True, False, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 1 , satae [0, -1, 1, -1, 1, 1, -1, 1, -1], mask [True, False, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [0, -1, 1, -1, 1, 1, -1, 1, -1], mask [True, False, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 4 , satae [0, -1, 1, -1, 1, 1, -1, 1, -1], mask [True, False, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 4 , satae [0, -1, 1, -1, 1, 1, -1, 1, -1], mask [True, False, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 3 , satae [0, -1, 1, -1, 1, 1, -1, 1, -1], mask [True, False, False, False, False, False, False, False, False]\n",
            "agent won  34  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  nan q value nan  reward : 1\n",
            "game #num:  63\n",
            "action not avaliable action<0,8> 6 , satae [1, -1, 1, 1, -1, -1, -1, 0, 1], mask [False, False, False, False, False, False, False, True, False]\n",
            "action not avaliable action<0,8> 0 , satae [1, -1, 1, 1, -1, -1, -1, 0, 1], mask [False, False, False, False, False, False, False, True, False]\n",
            "action not avaliable action<0,8> 2 , satae [1, -1, 1, 1, -1, -1, -1, 0, 1], mask [False, False, False, False, False, False, False, True, False]\n",
            "action not avaliable action<0,8> 6 , satae [1, -1, 1, 1, -1, -1, -1, 0, 1], mask [False, False, False, False, False, False, False, True, False]\n",
            "action not avaliable action<0,8> 8 , satae [1, -1, 1, 1, -1, -1, -1, 0, 1], mask [False, False, False, False, False, False, False, True, False]\n",
            "action not avaliable action<0,8> 2 , satae [1, -1, 1, 1, -1, -1, -1, 0, 1], mask [False, False, False, False, False, False, False, True, False]\n",
            "action not avaliable action<0,8> 8 , satae [1, -1, 1, 1, -1, -1, -1, 0, 1], mask [False, False, False, False, False, False, False, True, False]\n",
            "action not avaliable action<0,8> 8 , satae [1, -1, 1, 1, -1, -1, -1, 0, 1], mask [False, False, False, False, False, False, False, True, False]\n",
            "action not avaliable action<0,8> 6 , satae [1, -1, 1, 1, -1, -1, -1, 0, 1], mask [False, False, False, False, False, False, False, True, False]\n",
            "action not avaliable action<0,8> 5 , satae [1, -1, 1, 1, -1, -1, -1, 0, 1], mask [False, False, False, False, False, False, False, True, False]\n",
            "action not avaliable action<0,8> 0 , satae [1, -1, 1, 1, -1, -1, -1, 0, 1], mask [False, False, False, False, False, False, False, True, False]\n",
            "draw  9  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "################################################################################################\n",
            "game loss:  nan q value nan  reward : 0\n",
            "game #num:  64\n",
            "mcts won  21  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  nan q value nan  reward : -1\n",
            "game #num:  65\n",
            "action not avaliable action<0,8> 6 , satae [-1, -1, 0, 0, 0, 1, 1, -1, 1], mask [False, False, True, True, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [-1, -1, 0, 0, 0, 1, 1, -1, 1], mask [False, False, True, True, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [-1, -1, 0, 0, 0, 1, 1, -1, 1], mask [False, False, True, True, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [-1, -1, 0, -1, 1, 1, 1, -1, 1], mask [False, False, True, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 0 , satae [-1, -1, 0, -1, 1, 1, 1, -1, 1], mask [False, False, True, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 0 , satae [-1, -1, 0, -1, 1, 1, 1, -1, 1], mask [False, False, True, False, False, False, False, False, False]\n",
            "agent won  35  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.11223000784715016 q value 0.037541058328416615  reward : 1\n",
            "game #num:  66\n",
            "action not avaliable action<0,8> 8 , satae [1, -1, -1, 1, 0, 0, -1, 1, -1], mask [False, False, False, False, True, True, False, False, False]\n",
            "mcts won  22  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.11156129837036133 q value 0.046502111852169035  reward : -1\n",
            "game #num:  67\n",
            "action not avaliable action<0,8> 5 , satae [0, 1, -1, 0, 0, -1, -1, 1, 0], mask [True, False, False, True, True, False, False, False, True]\n",
            "action not avaliable action<0,8> 5 , satae [0, 1, -1, 0, 0, -1, -1, 1, 0], mask [True, False, False, True, True, False, False, False, True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:921: UserWarning: Using a target size (torch.Size([256, 1, 1])) that is different to the input size (torch.Size([256, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.1153393414887515 q value 0.32308229262178595  reward : 1\n",
            "game #num:  14552\n",
            "action not avaliable action<0,8> 6 , satae [0, 0, 0, 0, 0, -1, -1, 1, 1], mask [True, True, True, True, True, False, False, False, False]\n",
            "mcts won  5201  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.1121131032705307 q value 0.3247246265411377  reward : -1\n",
            "game #num:  14553\n",
            "mcts won  5202  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.09726466238498688 q value 0.3247484713792801  reward : -1\n",
            "game #num:  14554\n",
            "action not avaliable action<0,8> 6 , satae [0, 0, 0, 0, -1, 0, 1, 0, 0], mask [True, True, True, True, False, True, False, True, True]\n",
            "action not avaliable action<0,8> 6 , satae [0, -1, 0, 1, -1, 0, 1, 0, 0], mask [True, False, True, False, False, True, False, True, True]\n",
            "action not avaliable action<0,8> 6 , satae [-1, -1, 1, 1, -1, 0, 1, 0, 0], mask [False, False, False, False, False, True, False, True, True]\n",
            "action not avaliable action<0,8> 4 , satae [-1, -1, 1, 1, -1, -1, 1, 0, 1], mask [False, False, False, False, False, False, False, True, False]\n",
            "action not avaliable action<0,8> 4 , satae [-1, -1, 1, 1, -1, -1, 1, 0, 1], mask [False, False, False, False, False, False, False, True, False]\n",
            "action not avaliable action<0,8> 6 , satae [-1, -1, 1, 1, -1, -1, 1, 0, 1], mask [False, False, False, False, False, False, False, True, False]\n",
            "agent won  7928  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.11469745906916531 q value 0.3246748149394989  reward : 1\n",
            "game #num:  14555\n",
            "action not avaliable action<0,8> 4 , satae [0, 0, 0, 0, -1, 0, 0, 0, 1], mask [True, True, True, True, False, True, True, True, False]\n",
            "action not avaliable action<0,8> 7 , satae [0, 1, 0, 1, -1, -1, 0, -1, 1], mask [True, False, True, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 1 , satae [0, 1, 0, 1, -1, -1, 0, -1, 1], mask [True, False, True, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [0, 1, 0, 1, -1, -1, 0, -1, 1], mask [True, False, True, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 1 , satae [0, 1, 0, 1, -1, -1, 0, -1, 1], mask [True, False, True, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 3 , satae [0, 1, 0, 1, -1, -1, 0, -1, 1], mask [True, False, True, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 4 , satae [0, 1, 0, 1, -1, -1, 0, -1, 1], mask [True, False, True, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [0, 1, 0, 1, -1, -1, 0, -1, 1], mask [True, False, True, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [0, 1, 0, 1, -1, -1, 0, -1, 1], mask [True, False, True, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 3 , satae [0, 1, 0, 1, -1, -1, 0, -1, 1], mask [True, False, True, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [0, 1, 0, 1, -1, -1, 0, -1, 1], mask [True, False, True, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 5 , satae [0, 1, 0, 1, -1, -1, 0, -1, 1], mask [True, False, True, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [0, 1, 0, 1, -1, -1, 0, -1, 1], mask [True, False, True, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 4 , satae [0, 1, 0, 1, -1, -1, 0, -1, 1], mask [True, False, True, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 3 , satae [0, 1, 0, 1, -1, -1, 0, -1, 1], mask [True, False, True, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [0, 1, 0, 1, -1, -1, 0, -1, 1], mask [True, False, True, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 1 , satae [1, 1, 0, 1, -1, -1, -1, -1, 1], mask [False, False, True, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [1, 1, 0, 1, -1, -1, -1, -1, 1], mask [False, False, True, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [1, 1, 0, 1, -1, -1, -1, -1, 1], mask [False, False, True, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [1, 1, 0, 1, -1, -1, -1, -1, 1], mask [False, False, True, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [1, 1, 0, 1, -1, -1, -1, -1, 1], mask [False, False, True, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [1, 1, 0, 1, -1, -1, -1, -1, 1], mask [False, False, True, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 4 , satae [1, 1, 0, 1, -1, -1, -1, -1, 1], mask [False, False, True, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [1, 1, 0, 1, -1, -1, -1, -1, 1], mask [False, False, True, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [1, 1, 0, 1, -1, -1, -1, -1, 1], mask [False, False, True, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [1, 1, 0, 1, -1, -1, -1, -1, 1], mask [False, False, True, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 1 , satae [1, 1, 0, 1, -1, -1, -1, -1, 1], mask [False, False, True, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [1, 1, 0, 1, -1, -1, -1, -1, 1], mask [False, False, True, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 5 , satae [1, 1, 0, 1, -1, -1, -1, -1, 1], mask [False, False, True, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 3 , satae [1, 1, 0, 1, -1, -1, -1, -1, 1], mask [False, False, True, False, False, False, False, False, False]\n",
            "agent won  7929  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.11401796234505517 q value 0.3199204845087869  reward : 1\n",
            "game #num:  14556\n",
            "action not avaliable action<0,8> 4 , satae [0, -1, -1, -1, 1, 1, 0, 0, 1], mask [True, False, False, False, False, False, True, True, False]\n",
            "action not avaliable action<0,8> 2 , satae [0, -1, -1, -1, 1, 1, 0, 0, 1], mask [True, False, False, False, False, False, True, True, False]\n",
            "action not avaliable action<0,8> 2 , satae [0, -1, -1, -1, 1, 1, 0, 0, 1], mask [True, False, False, False, False, False, True, True, False]\n",
            "action not avaliable action<0,8> 2 , satae [0, -1, -1, -1, 1, 1, 0, 0, 1], mask [True, False, False, False, False, False, True, True, False]\n",
            "action not avaliable action<0,8> 1 , satae [0, -1, -1, -1, 1, 1, 0, 0, 1], mask [True, False, False, False, False, False, True, True, False]\n",
            "action not avaliable action<0,8> 5 , satae [0, -1, -1, -1, 1, 1, 0, 0, 1], mask [True, False, False, False, False, False, True, True, False]\n",
            "action not avaliable action<0,8> 5 , satae [0, -1, -1, -1, 1, 1, 0, 0, 1], mask [True, False, False, False, False, False, True, True, False]\n",
            "action not avaliable action<0,8> 4 , satae [0, -1, -1, -1, 1, 1, 0, 0, 1], mask [True, False, False, False, False, False, True, True, False]\n",
            "action not avaliable action<0,8> 2 , satae [0, -1, -1, -1, 1, 1, 0, 0, 1], mask [True, False, False, False, False, False, True, True, False]\n",
            "action not avaliable action<0,8> 8 , satae [0, -1, -1, -1, 1, 1, 0, 0, 1], mask [True, False, False, False, False, False, True, True, False]\n",
            "action not avaliable action<0,8> 5 , satae [0, -1, -1, -1, 1, 1, 0, 0, 1], mask [True, False, False, False, False, False, True, True, False]\n",
            "action not avaliable action<0,8> 5 , satae [0, -1, -1, -1, 1, 1, 0, 0, 1], mask [True, False, False, False, False, False, True, True, False]\n",
            "action not avaliable action<0,8> 2 , satae [0, -1, -1, -1, 1, 1, 0, 0, 1], mask [True, False, False, False, False, False, True, True, False]\n",
            "action not avaliable action<0,8> 2 , satae [0, -1, -1, -1, 1, 1, 0, 0, 1], mask [True, False, False, False, False, False, True, True, False]\n",
            "action not avaliable action<0,8> 5 , satae [0, -1, -1, -1, 1, 1, 0, 0, 1], mask [True, False, False, False, False, False, True, True, False]\n",
            "action not avaliable action<0,8> 2 , satae [0, -1, -1, -1, 1, 1, 0, 0, 1], mask [True, False, False, False, False, False, True, True, False]\n",
            "action not avaliable action<0,8> 5 , satae [0, -1, -1, -1, 1, 1, 0, 0, 1], mask [True, False, False, False, False, False, True, True, False]\n",
            "action not avaliable action<0,8> 2 , satae [0, -1, -1, -1, 1, 1, 0, 0, 1], mask [True, False, False, False, False, False, True, True, False]\n",
            "agent won  7930  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.11303896152160385 q value 0.3185090950944207  reward : 1\n",
            "game #num:  14557\n",
            "action not avaliable action<0,8> 1 , satae [0, -1, 0, 0, -1, 0, 1, 0, 0], mask [True, False, True, True, False, True, False, True, True]\n",
            "action not avaliable action<0,8> 6 , satae [0, -1, 0, 0, -1, -1, 1, 1, 0], mask [True, False, True, True, False, False, False, False, True]\n",
            "action not avaliable action<0,8> 5 , satae [0, -1, 0, 0, -1, -1, 1, 1, 0], mask [True, False, True, True, False, False, False, False, True]\n",
            "action not avaliable action<0,8> 6 , satae [0, -1, 0, 0, -1, -1, 1, 1, 0], mask [True, False, True, True, False, False, False, False, True]\n",
            "action not avaliable action<0,8> 5 , satae [0, -1, 0, 0, -1, -1, 1, 1, 0], mask [True, False, True, True, False, False, False, False, True]\n",
            "action not avaliable action<0,8> 1 , satae [0, -1, 0, 0, -1, -1, 1, 1, 0], mask [True, False, True, True, False, False, False, False, True]\n",
            "action not avaliable action<0,8> 5 , satae [0, -1, 0, 0, -1, -1, 1, 1, 0], mask [True, False, True, True, False, False, False, False, True]\n",
            "action not avaliable action<0,8> 5 , satae [0, -1, 0, 0, -1, -1, 1, 1, 0], mask [True, False, True, True, False, False, False, False, True]\n",
            "action not avaliable action<0,8> 5 , satae [0, -1, 0, 0, -1, -1, 1, 1, 0], mask [True, False, True, True, False, False, False, False, True]\n",
            "action not avaliable action<0,8> 1 , satae [0, -1, 0, 0, -1, -1, 1, 1, 0], mask [True, False, True, True, False, False, False, False, True]\n",
            "action not avaliable action<0,8> 5 , satae [0, -1, 0, 0, -1, -1, 1, 1, 0], mask [True, False, True, True, False, False, False, False, True]\n",
            "action not avaliable action<0,8> 6 , satae [0, -1, 0, 0, -1, -1, 1, 1, 0], mask [True, False, True, True, False, False, False, False, True]\n",
            "action not avaliable action<0,8> 8 , satae [0, -1, 0, 1, -1, -1, 1, 1, -1], mask [True, False, True, False, False, False, False, False, False]\n",
            "agent won  7931  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.11111056892310872 q value 0.3186146091012394  reward : 1\n",
            "game #num:  14558\n",
            "action not avaliable action<0,8> 5 , satae [0, 1, -1, 0, 1, 1, -1, -1, 0], mask [True, False, False, True, False, False, False, False, True]\n",
            "action not avaliable action<0,8> 5 , satae [0, 1, -1, 0, 1, 1, -1, -1, 0], mask [True, False, False, True, False, False, False, False, True]\n",
            "action not avaliable action<0,8> 6 , satae [0, 1, -1, 0, 1, 1, -1, -1, 0], mask [True, False, False, True, False, False, False, False, True]\n",
            "action not avaliable action<0,8> 1 , satae [0, 1, -1, 0, 1, 1, -1, -1, 0], mask [True, False, False, True, False, False, False, False, True]\n",
            "action not avaliable action<0,8> 1 , satae [-1, 1, -1, 0, 1, 1, -1, -1, 1], mask [False, False, False, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [-1, 1, -1, 0, 1, 1, -1, -1, 1], mask [False, False, False, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 5 , satae [-1, 1, -1, 0, 1, 1, -1, -1, 1], mask [False, False, False, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 1 , satae [-1, 1, -1, 0, 1, 1, -1, -1, 1], mask [False, False, False, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [-1, 1, -1, 0, 1, 1, -1, -1, 1], mask [False, False, False, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [-1, 1, -1, 0, 1, 1, -1, -1, 1], mask [False, False, False, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 5 , satae [-1, 1, -1, 0, 1, 1, -1, -1, 1], mask [False, False, False, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 0 , satae [-1, 1, -1, 0, 1, 1, -1, -1, 1], mask [False, False, False, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 1 , satae [-1, 1, -1, 0, 1, 1, -1, -1, 1], mask [False, False, False, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 1 , satae [-1, 1, -1, 0, 1, 1, -1, -1, 1], mask [False, False, False, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 1 , satae [-1, 1, -1, 0, 1, 1, -1, -1, 1], mask [False, False, False, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [-1, 1, -1, 0, 1, 1, -1, -1, 1], mask [False, False, False, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [-1, 1, -1, 0, 1, 1, -1, -1, 1], mask [False, False, False, True, False, False, False, False, False]\n",
            "agent won  7932  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.11440456184473904 q value 0.3192564574154941  reward : 1\n",
            "game #num:  14559\n",
            "action not avaliable action<0,8> 8 , satae [0, 0, 0, 0, 0, -1, 0, 1, -1], mask [True, True, True, True, True, False, True, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [0, 0, 0, 1, 0, -1, -1, 1, -1], mask [True, True, True, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [1, -1, 0, 1, 0, -1, -1, 1, -1], mask [False, False, True, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 0 , satae [1, -1, 0, 1, 0, -1, -1, 1, -1], mask [False, False, True, False, True, False, False, False, False]\n",
            "agent won  7933  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.10952487029135227 q value 0.31889282912015915  reward : 1\n",
            "game #num:  14560\n",
            "mcts won  5203  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.11475558827320735 q value 0.31857388218243915  reward : -1\n",
            "game #num:  14561\n",
            "action not avaliable action<0,8> 1 , satae [-1, 1, 0, 0, 0, 0, 0, 0, -1], mask [False, False, True, True, True, True, True, True, False]\n",
            "action not avaliable action<0,8> 0 , satae [-1, 1, 0, 1, 0, -1, 0, 0, -1], mask [False, False, True, False, True, False, True, True, False]\n",
            "mcts won  5204  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.11823021173477173 q value 0.3172376096248627  reward : -1\n",
            "game #num:  14562\n",
            "agent won  7934  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.10679491423070431 q value 0.31568048149347305  reward : 1\n",
            "game #num:  14563\n",
            "action not avaliable action<0,8> 5 , satae [1, 0, 0, 0, 0, -1, 0, 0, 0], mask [False, True, True, True, True, False, True, True, True]\n",
            "action not avaliable action<0,8> 0 , satae [1, 0, 0, -1, 0, -1, 0, 1, 0], mask [False, True, True, False, True, False, True, False, True]\n",
            "action not avaliable action<0,8> 0 , satae [1, 0, 0, -1, 0, -1, 0, 1, 0], mask [False, True, True, False, True, False, True, False, True]\n",
            "agent won  7935  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.11485086878140767 q value 0.31603140632311505  reward : 1\n",
            "game #num:  14564\n",
            "agent won  7936  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.1039020096262296 q value 0.31693480412165326  reward : 1\n",
            "game #num:  14565\n",
            "action not avaliable action<0,8> 7 , satae [0, 0, -1, 0, -1, 1, 0, 1, 0], mask [True, True, False, True, False, False, True, False, True]\n",
            "action not avaliable action<0,8> 7 , satae [-1, 1, -1, 0, -1, 1, 0, 1, 0], mask [False, False, False, True, False, False, True, False, True]\n",
            "agent won  7937  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.10487018153071404 q value 0.31868896385033924  reward : 1\n",
            "game #num:  14566\n",
            "action not avaliable action<0,8> 4 , satae [0, -1, 1, -1, -1, 0, 1, 0, 1], mask [True, False, False, False, False, True, False, True, False]\n",
            "action not avaliable action<0,8> 6 , satae [0, -1, 1, -1, -1, 0, 1, 0, 1], mask [True, False, False, False, False, True, False, True, False]\n",
            "action not avaliable action<0,8> 1 , satae [0, -1, 1, -1, -1, 0, 1, 0, 1], mask [True, False, False, False, False, True, False, True, False]\n",
            "agent won  7938  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.11022446517433439 q value 0.3201947935989925  reward : 1\n",
            "game #num:  14567\n",
            "action not avaliable action<0,8> 4 , satae [0, 0, 0, 0, -1, 0, 1, 0, 0], mask [True, True, True, True, False, True, False, True, True]\n",
            "action not avaliable action<0,8> 4 , satae [0, 0, 0, 0, -1, 0, 1, 0, 0], mask [True, True, True, True, False, True, False, True, True]\n",
            "action not avaliable action<0,8> 6 , satae [0, 0, 0, 0, -1, 0, 1, 0, 0], mask [True, True, True, True, False, True, False, True, True]\n",
            "action not avaliable action<0,8> 4 , satae [0, 0, 0, 0, -1, 0, 1, 0, 0], mask [True, True, True, True, False, True, False, True, True]\n",
            "action not avaliable action<0,8> 6 , satae [-1, 0, 0, 1, -1, 0, 1, 0, 0], mask [False, True, True, False, False, True, False, True, True]\n",
            "action not avaliable action<0,8> 0 , satae [-1, 0, 0, 1, -1, 0, 1, 0, 0], mask [False, True, True, False, False, True, False, True, True]\n",
            "action not avaliable action<0,8> 4 , satae [-1, 0, 0, 1, -1, 0, 1, 0, 0], mask [False, True, True, False, False, True, False, True, True]\n",
            "action not avaliable action<0,8> 0 , satae [-1, 0, 0, 1, -1, 0, 1, 0, 0], mask [False, True, True, False, False, True, False, True, True]\n",
            "agent won  7939  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.10925744338469072 q value 0.32336975227702747  reward : 1\n",
            "game #num:  14568\n",
            "action not avaliable action<0,8> 5 , satae [0, -1, -1, 1, 0, 1, 0, -1, 1], mask [True, False, False, False, True, False, True, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [0, -1, -1, 1, 0, 1, 0, -1, 1], mask [True, False, False, False, True, False, True, False, False]\n",
            "mcts won  5205  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.11832546070218086 q value 0.32645490268866223  reward : -1\n",
            "game #num:  14569\n",
            "action not avaliable action<0,8> 2 , satae [-1, 0, 1, 0, -1, 1, -1, 1, 0], mask [False, True, False, True, False, False, False, False, True]\n",
            "action not avaliable action<0,8> 7 , satae [-1, 0, 1, 0, -1, 1, -1, 1, 0], mask [False, True, False, True, False, False, False, False, True]\n",
            "mcts won  5206  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.1183454083899657 q value 0.32496418058872223  reward : -1\n",
            "game #num:  14570\n",
            "action not avaliable action<0,8> 6 , satae [0, 0, 0, 0, 0, 0, -1, 1, 0], mask [True, True, True, True, True, True, False, False, True]\n",
            "action not avaliable action<0,8> 6 , satae [0, 0, 0, 0, 0, 0, -1, 1, 0], mask [True, True, True, True, True, True, False, False, True]\n",
            "action not avaliable action<0,8> 5 , satae [1, -1, 0, 0, -1, 1, -1, 1, 0], mask [False, False, True, True, False, False, False, False, True]\n",
            "action not avaliable action<0,8> 5 , satae [1, -1, 0, 0, -1, 1, -1, 1, 0], mask [False, False, True, True, False, False, False, False, True]\n",
            "action not avaliable action<0,8> 1 , satae [1, -1, 0, 0, -1, 1, -1, 1, 0], mask [False, False, True, True, False, False, False, False, True]\n",
            "action not avaliable action<0,8> 1 , satae [1, -1, 0, 0, -1, 1, -1, 1, 0], mask [False, False, True, True, False, False, False, False, True]\n",
            "action not avaliable action<0,8> 1 , satae [1, -1, 0, 0, -1, 1, -1, 1, 0], mask [False, False, True, True, False, False, False, False, True]\n",
            "action not avaliable action<0,8> 6 , satae [1, -1, 0, 0, -1, 1, -1, 1, 0], mask [False, False, True, True, False, False, False, False, True]\n",
            "action not avaliable action<0,8> 0 , satae [1, -1, 0, 0, -1, 1, -1, 1, 0], mask [False, False, True, True, False, False, False, False, True]\n",
            "action not avaliable action<0,8> 7 , satae [1, -1, 0, 0, -1, 1, -1, 1, 0], mask [False, False, True, True, False, False, False, False, True]\n",
            "action not avaliable action<0,8> 1 , satae [1, -1, 0, 0, -1, 1, -1, 1, 0], mask [False, False, True, True, False, False, False, False, True]\n",
            "action not avaliable action<0,8> 0 , satae [1, -1, 1, 0, -1, 1, -1, 1, -1], mask [False, False, False, True, False, False, False, False, False]\n",
            "draw  1425  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "################################################################################################\n",
            "game loss:  0.10913544498822268 q value 0.32337669064016905  reward : 0\n",
            "game #num:  14571\n",
            "action not avaliable action<0,8> 1 , satae [-1, 1, 0, -1, 0, 0, 0, 0, 0], mask [False, False, True, False, True, True, True, True, True]\n",
            "mcts won  5207  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.10860474705696106 q value 0.32519580125808717  reward : -1\n",
            "game #num:  14572\n",
            "action not avaliable action<0,8> 7 , satae [0, -1, 0, 1, 0, 0, 0, -1, 0], mask [True, False, True, False, True, True, True, False, True]\n",
            "action not avaliable action<0,8> 1 , satae [0, -1, 0, 1, 0, 0, 0, -1, 0], mask [True, False, True, False, True, True, True, False, True]\n",
            "action not avaliable action<0,8> 1 , satae [0, -1, 0, 1, 0, 0, 0, -1, 0], mask [True, False, True, False, True, True, True, False, True]\n",
            "action not avaliable action<0,8> 1 , satae [0, -1, 0, 1, 0, 0, 0, -1, 0], mask [True, False, True, False, True, True, True, False, True]\n",
            "action not avaliable action<0,8> 1 , satae [0, -1, 1, 1, 0, 0, 0, -1, -1], mask [True, False, False, False, True, True, True, False, False]\n",
            "action not avaliable action<0,8> 2 , satae [0, -1, 1, 1, 0, 0, 0, -1, -1], mask [True, False, False, False, True, True, True, False, False]\n",
            "mcts won  5208  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.10696468353271485 q value 0.32575848400592805  reward : -1\n",
            "game #num:  14573\n",
            "agent won  7940  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.11593891680240631 q value 0.32433488965034485  reward : 1\n",
            "game #num:  14574\n",
            "action not avaliable action<0,8> 7 , satae [0, -1, 0, 1, 1, 0, -1, -1, 0], mask [True, False, True, False, False, True, False, False, True]\n",
            "action not avaliable action<0,8> 4 , satae [0, -1, 0, 1, 1, 0, -1, -1, 0], mask [True, False, True, False, False, True, False, False, True]\n",
            "action not avaliable action<0,8> 4 , satae [0, -1, 0, 1, 1, 0, -1, -1, 0], mask [True, False, True, False, False, True, False, False, True]\n",
            "action not avaliable action<0,8> 7 , satae [0, -1, 0, 1, 1, 0, -1, -1, 0], mask [True, False, True, False, False, True, False, False, True]\n",
            "action not avaliable action<0,8> 7 , satae [0, -1, 0, 1, 1, 0, -1, -1, 0], mask [True, False, True, False, False, True, False, False, True]\n",
            "agent won  7941  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.11437357796563043 q value 0.32184775008095634  reward : 1\n",
            "game #num:  14575\n",
            "action not avaliable action<0,8> 2 , satae [0, 0, -1, 1, 0, 0, 0, 0, 0], mask [True, True, False, False, True, True, True, True, True]\n",
            "action not avaliable action<0,8> 2 , satae [1, 0, -1, 1, 0, 0, 0, -1, 0], mask [False, True, False, False, True, True, True, False, True]\n",
            "mcts won  5209  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.11227654814720153 q value 0.3190354287624359  reward : -1\n",
            "game #num:  14576\n",
            "action not avaliable action<0,8> 2 , satae [-1, 0, -1, 0, 0, 1, 0, 1, 0], mask [False, True, False, True, True, False, True, False, True]\n",
            "action not avaliable action<0,8> 2 , satae [-1, 0, -1, 0, 0, 1, 0, 1, 0], mask [False, True, False, True, True, False, True, False, True]\n",
            "action not avaliable action<0,8> 5 , satae [-1, 0, -1, 0, 0, 1, 0, 1, 0], mask [False, True, False, True, True, False, True, False, True]\n",
            "action not avaliable action<0,8> 5 , satae [-1, 0, -1, 0, 0, 1, 0, 1, 0], mask [False, True, False, True, True, False, True, False, True]\n",
            "action not avaliable action<0,8> 0 , satae [-1, 0, -1, 0, 0, 1, 0, 1, 0], mask [False, True, False, True, True, False, True, False, True]\n",
            "action not avaliable action<0,8> 8 , satae [-1, 0, -1, 0, 0, 1, 1, 1, -1], mask [False, True, False, True, True, False, False, False, False]\n",
            "agent won  7942  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.1140756718814373 q value 0.3170604884624481  reward : 1\n",
            "game #num:  14577\n",
            "mcts won  5210  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.09963547190030415 q value 0.3143206139405568  reward : -1\n",
            "game #num:  14578\n",
            "action not avaliable action<0,8> 6 , satae [1, 0, 0, 0, 0, 0, -1, 0, 0], mask [False, True, True, True, True, True, False, True, True]\n",
            "action not avaliable action<0,8> 0 , satae [1, 0, 0, 0, 0, 0, -1, 0, 0], mask [False, True, True, True, True, True, False, True, True]\n",
            "action not avaliable action<0,8> 6 , satae [1, 0, 0, 0, 0, 1, -1, 0, -1], mask [False, True, True, True, True, False, False, True, False]\n",
            "agent won  7943  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.12056678533554077 q value 0.31341602546828135  reward : 1\n",
            "game #num:  14579\n",
            "action not avaliable action<0,8> 2 , satae [0, 0, -1, 1, 1, -1, -1, -1, 1], mask [True, True, False, False, False, False, False, False, False]\n",
            "mcts won  5211  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.10484508275985718 q value 0.3138784050941467  reward : -1\n",
            "game #num:  14580\n",
            "action not avaliable action<0,8> 3 , satae [0, 0, 0, 1, -1, 0, -1, 0, 0], mask [True, True, True, False, False, True, False, True, True]\n",
            "action not avaliable action<0,8> 1 , satae [0, 1, 0, 1, -1, 0, -1, 0, -1], mask [True, False, True, False, False, True, False, True, False]\n",
            "agent won  7944  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.1115364357829094 q value 0.3156908690929413  reward : 1\n",
            "game #num:  14581\n",
            "action not avaliable action<0,8> 1 , satae [0, -1, 0, 0, 0, 0, 0, 0, 0], mask [True, False, True, True, True, True, True, True, True]\n",
            "action not avaliable action<0,8> 8 , satae [0, -1, -1, 1, 0, 0, 0, 1, -1], mask [True, False, False, False, True, True, True, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [0, -1, -1, 1, 0, 0, 0, 1, -1], mask [True, False, False, False, True, True, True, False, False]\n",
            "action not avaliable action<0,8> 2 , satae [0, -1, -1, 1, 0, 0, 0, 1, -1], mask [True, False, False, False, True, True, True, False, False]\n",
            "action not avaliable action<0,8> 2 , satae [0, -1, -1, 1, 0, 1, -1, 1, -1], mask [True, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 5 , satae [0, -1, -1, 1, 0, 1, -1, 1, -1], mask [True, False, False, False, True, False, False, False, False]\n",
            "mcts won  5212  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.10853290930390358 q value 0.31933774054050446  reward : -1\n",
            "game #num:  14582\n",
            "agent won  7945  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.10087114075819652 q value 0.3218013842900594  reward : 1\n",
            "game #num:  14583\n",
            "action not avaliable action<0,8> 2 , satae [0, 0, 1, -1, -1, 0, -1, 1, 1], mask [True, True, False, False, False, True, False, False, False]\n",
            "action not avaliable action<0,8> 2 , satae [0, 0, 1, -1, -1, 0, -1, 1, 1], mask [True, True, False, False, False, True, False, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [0, 0, 1, -1, -1, 0, -1, 1, 1], mask [True, True, False, False, False, True, False, False, False]\n",
            "action not avaliable action<0,8> 3 , satae [0, 0, 1, -1, -1, 0, -1, 1, 1], mask [True, True, False, False, False, True, False, False, False]\n",
            "action not avaliable action<0,8> 2 , satae [0, 0, 1, -1, -1, 0, -1, 1, 1], mask [True, True, False, False, False, True, False, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [0, 0, 1, -1, -1, 0, -1, 1, 1], mask [True, True, False, False, False, True, False, False, False]\n",
            "action not avaliable action<0,8> 3 , satae [0, 0, 1, -1, -1, 0, -1, 1, 1], mask [True, True, False, False, False, True, False, False, False]\n",
            "action not avaliable action<0,8> 2 , satae [0, 0, 1, -1, -1, 0, -1, 1, 1], mask [True, True, False, False, False, True, False, False, False]\n",
            "action not avaliable action<0,8> 2 , satae [0, 0, 1, -1, -1, 0, -1, 1, 1], mask [True, True, False, False, False, True, False, False, False]\n",
            "action not avaliable action<0,8> 2 , satae [0, 0, 1, -1, -1, 0, -1, 1, 1], mask [True, True, False, False, False, True, False, False, False]\n",
            "agent won  7946  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.1134721434542111 q value 0.32473589054175783  reward : 1\n",
            "game #num:  14584\n",
            "action not avaliable action<0,8> 5 , satae [1, 1, -1, -1, -1, 1, 0, 0, 0], mask [False, False, False, False, False, False, True, True, True]\n",
            "mcts won  5213  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.12494490295648575 q value 0.3226284980773926  reward : -1\n",
            "game #num:  14585\n",
            "action not avaliable action<0,8> 0 , satae [1, 0, -1, -1, 0, 0, 0, 0, 0], mask [False, True, False, False, True, True, True, True, True]\n",
            "action not avaliable action<0,8> 0 , satae [1, 0, -1, -1, 0, 0, 0, 0, 0], mask [False, True, False, False, True, True, True, True, True]\n",
            "action not avaliable action<0,8> 6 , satae [1, 0, -1, -1, 0, 0, 1, -1, 0], mask [False, True, False, False, True, True, False, False, True]\n",
            "action not avaliable action<0,8> 7 , satae [1, 0, -1, -1, 0, 0, 1, -1, 0], mask [False, True, False, False, True, True, False, False, True]\n",
            "action not avaliable action<0,8> 6 , satae [1, 0, -1, -1, 0, 0, 1, -1, 0], mask [False, True, False, False, True, True, False, False, True]\n",
            "action not avaliable action<0,8> 7 , satae [1, 0, -1, -1, 0, 0, 1, -1, 0], mask [False, True, False, False, True, True, False, False, True]\n",
            "action not avaliable action<0,8> 2 , satae [1, 0, -1, -1, 0, 0, 1, -1, 0], mask [False, True, False, False, True, True, False, False, True]\n",
            "action not avaliable action<0,8> 0 , satae [1, 0, -1, -1, 0, 1, 1, -1, -1], mask [False, True, False, False, True, False, False, False, False]\n",
            "draw  1426  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "################################################################################################\n",
            "game loss:  0.10518838092684746 q value 0.3190273965398471  reward : 0\n",
            "game #num:  14586\n",
            "action not avaliable action<0,8> 6 , satae [-1, 0, -1, 1, -1, -1, 1, 0, 1], mask [False, True, False, False, False, False, False, True, False]\n",
            "draw  1427  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0]\n",
            "################################################################################################\n",
            "game loss:  0.10552300810813904 q value 0.3185614824295044  reward : 0\n",
            "game #num:  14587\n",
            "action not avaliable action<0,8> 2 , satae [0, 0, 1, 0, 0, 0, -1, 0, 0], mask [True, True, False, True, True, True, False, True, True]\n",
            "action not avaliable action<0,8> 2 , satae [1, 0, 1, 0, -1, 0, -1, 0, 0], mask [False, True, False, True, False, True, False, True, True]\n",
            "agent won  7947  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.10098051403959592 q value 0.32079780598481494  reward : 1\n",
            "game #num:  14588\n",
            "agent won  7948  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.12775493413209915 q value 0.3228739798069  reward : 1\n",
            "game #num:  14589\n",
            "action not avaliable action<0,8> 5 , satae [0, 0, -1, 0, 1, 1, -1, 0, 0], mask [True, True, False, True, False, False, False, True, True]\n",
            "action not avaliable action<0,8> 4 , satae [0, 1, -1, 0, 1, 1, -1, -1, 0], mask [True, False, False, True, False, False, False, False, True]\n",
            "mcts won  5214  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.11900501201550166 q value 0.3237084597349167  reward : -1\n",
            "game #num:  14590\n",
            "action not avaliable action<0,8> 7 , satae [-1, 0, 1, 0, 0, 0, 0, -1, 0], mask [False, True, False, True, True, True, True, False, True]\n",
            "action not avaliable action<0,8> 7 , satae [-1, 1, 1, -1, 0, 0, 1, -1, -1], mask [False, False, False, False, True, True, False, False, False]\n",
            "action not avaliable action<0,8> 2 , satae [-1, 1, 1, -1, 0, 0, 1, -1, -1], mask [False, False, False, False, True, True, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [-1, 1, 1, -1, 0, 0, 1, -1, -1], mask [False, False, False, False, True, True, False, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [-1, 1, 1, -1, 0, 0, 1, -1, -1], mask [False, False, False, False, True, True, False, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [-1, 1, 1, -1, 0, 0, 1, -1, -1], mask [False, False, False, False, True, True, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [-1, 1, 1, -1, 0, 0, 1, -1, -1], mask [False, False, False, False, True, True, False, False, False]\n",
            "mcts won  5215  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.11295133558186618 q value 0.32216066122055054  reward : -1\n",
            "game #num:  14591\n",
            "action not avaliable action<0,8> 5 , satae [1, 0, 0, -1, 0, 1, -1, -1, 0], mask [False, True, True, False, True, False, False, False, True]\n",
            "action not avaliable action<0,8> 6 , satae [1, 0, 0, -1, 0, 1, -1, -1, 0], mask [False, True, True, False, True, False, False, False, True]\n",
            "action not avaliable action<0,8> 3 , satae [1, 0, 0, -1, 0, 1, -1, -1, 0], mask [False, True, True, False, True, False, False, False, True]\n",
            "agent won  7949  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.11521219568593162 q value 0.32150089740753174  reward : 1\n",
            "game #num:  14592\n",
            "action not avaliable action<0,8> 1 , satae [1, -1, -1, 0, 0, 0, 0, 0, 0], mask [False, False, False, True, True, True, True, True, True]\n",
            "action not avaliable action<0,8> 0 , satae [1, -1, -1, -1, 0, -1, 0, 1, 1], mask [False, False, False, False, True, False, True, False, False]\n",
            "action not avaliable action<0,8> 5 , satae [1, -1, -1, -1, 0, -1, 0, 1, 1], mask [False, False, False, False, True, False, True, False, False]\n",
            "action not avaliable action<0,8> 0 , satae [1, -1, -1, -1, 0, -1, 0, 1, 1], mask [False, False, False, False, True, False, True, False, False]\n",
            "mcts won  5216  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.10150631610304117 q value 0.3215409070253372  reward : -1\n",
            "game #num:  14593\n",
            "action not avaliable action<0,8> 7 , satae [0, 0, 0, 0, 1, 0, 0, -1, 0], mask [True, True, True, True, False, True, True, False, True]\n",
            "action not avaliable action<0,8> 7 , satae [0, 0, 0, 1, 1, -1, 0, -1, 0], mask [True, True, True, False, False, False, True, False, True]\n",
            "action not avaliable action<0,8> 7 , satae [0, 0, 0, 1, 1, -1, 1, -1, -1], mask [True, True, True, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [0, 0, 0, 1, 1, -1, 1, -1, -1], mask [True, True, True, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [0, 0, 0, 1, 1, -1, 1, -1, -1], mask [True, True, True, False, False, False, False, False, False]\n",
            "agent won  7950  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.1165297312868966 q value 0.3256956438223521  reward : 1\n",
            "game #num:  14594\n",
            "action not avaliable action<0,8> 6 , satae [-1, 1, 0, 1, 0, -1, 1, -1, 0], mask [False, False, True, False, True, False, False, False, True]\n",
            "action not avaliable action<0,8> 5 , satae [-1, 1, 0, 1, 0, -1, 1, -1, 0], mask [False, False, True, False, True, False, False, False, True]\n",
            "action not avaliable action<0,8> 7 , satae [-1, 1, 1, 1, 0, -1, 1, -1, -1], mask [False, False, False, False, True, False, False, False, False]\n",
            "agent won  7951  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.11169810127466917 q value 0.3282075934112072  reward : 1\n",
            "game #num:  14595\n",
            "agent won  7952  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.11916160956025124 q value 0.3276924714446068  reward : 1\n",
            "game #num:  14596\n",
            "action not avaliable action<0,8> 5 , satae [0, 0, 0, 0, 0, -1, 0, 0, 1], mask [True, True, True, True, True, False, True, True, False]\n",
            "action not avaliable action<0,8> 5 , satae [0, 0, 0, 0, 0, -1, 0, 0, 1], mask [True, True, True, True, True, False, True, True, False]\n",
            "action not avaliable action<0,8> 8 , satae [0, 0, 0, 0, 0, -1, -1, 1, 1], mask [True, True, True, True, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [0, 0, 0, 0, 0, -1, -1, 1, 1], mask [True, True, True, True, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 1 , satae [-1, 1, 1, 0, -1, -1, -1, 1, 1], mask [False, False, False, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 5 , satae [-1, 1, 1, 0, -1, -1, -1, 1, 1], mask [False, False, False, True, False, False, False, False, False]\n",
            "draw  1428  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "################################################################################################\n",
            "game loss:  0.11318725686181676 q value 0.32676120779731055  reward : 0\n",
            "game #num:  14597\n",
            "agent won  7953  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.11981244757771492 q value 0.32488372921943665  reward : 1\n",
            "game #num:  14598\n",
            "action not avaliable action<0,8> 1 , satae [-1, 1, -1, 0, 0, 1, -1, -1, 1], mask [False, False, False, True, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 0 , satae [-1, 1, -1, 0, 0, 1, -1, -1, 1], mask [False, False, False, True, True, False, False, False, False]\n",
            "mcts won  5217  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.11448234568039577 q value 0.32285143931706745  reward : -1\n",
            "game #num:  14599\n",
            "action not avaliable action<0,8> 6 , satae [0, 0, 1, 0, -1, 0, 1, -1, -1], mask [True, True, False, True, False, True, False, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [0, 0, 1, 0, -1, 0, 1, -1, -1], mask [True, True, False, True, False, True, False, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [0, 0, 1, 0, -1, 0, 1, -1, -1], mask [True, True, False, True, False, True, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [0, 0, 1, 0, -1, 0, 1, -1, -1], mask [True, True, False, True, False, True, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [0, 0, 1, 0, -1, 0, 1, -1, -1], mask [True, True, False, True, False, True, False, False, False]\n",
            "action not avaliable action<0,8> 2 , satae [0, 0, 1, 0, -1, 0, 1, -1, -1], mask [True, True, False, True, False, True, False, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [0, 0, 1, 0, -1, 0, 1, -1, -1], mask [True, True, False, True, False, True, False, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [0, 0, 1, 0, -1, 0, 1, -1, -1], mask [True, True, False, True, False, True, False, False, False]\n",
            "action not avaliable action<0,8> 4 , satae [0, 0, 1, 0, -1, 0, 1, -1, -1], mask [True, True, False, True, False, True, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [0, 0, 1, 0, -1, 0, 1, -1, -1], mask [True, True, False, True, False, True, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [0, 0, 1, 0, -1, 0, 1, -1, -1], mask [True, True, False, True, False, True, False, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [0, 0, 1, 0, -1, 0, 1, -1, -1], mask [True, True, False, True, False, True, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [0, 0, 1, 0, -1, 0, 1, -1, -1], mask [True, True, False, True, False, True, False, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [0, 0, 1, 0, -1, 0, 1, -1, -1], mask [True, True, False, True, False, True, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [0, 0, 1, 0, -1, 0, 1, -1, -1], mask [True, True, False, True, False, True, False, False, False]\n",
            "action not avaliable action<0,8> 2 , satae [0, 0, 1, 0, -1, 0, 1, -1, -1], mask [True, True, False, True, False, True, False, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [0, 0, 1, 0, -1, 0, 1, -1, -1], mask [True, True, False, True, False, True, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [0, 0, 1, 0, -1, 0, 1, -1, -1], mask [True, True, False, True, False, True, False, False, False]\n",
            "action not avaliable action<0,8> 2 , satae [0, 0, 1, 0, -1, 0, 1, -1, -1], mask [True, True, False, True, False, True, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [0, 0, 1, -1, -1, 1, 1, -1, -1], mask [True, True, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [0, 0, 1, -1, -1, 1, 1, -1, -1], mask [True, True, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [0, 0, 1, -1, -1, 1, 1, -1, -1], mask [True, True, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [0, 0, 1, -1, -1, 1, 1, -1, -1], mask [True, True, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 2 , satae [0, 0, 1, -1, -1, 1, 1, -1, -1], mask [True, True, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [0, 0, 1, -1, -1, 1, 1, -1, -1], mask [True, True, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 5 , satae [0, 0, 1, -1, -1, 1, 1, -1, -1], mask [True, True, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [0, 0, 1, -1, -1, 1, 1, -1, -1], mask [True, True, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 3 , satae [0, 0, 1, -1, -1, 1, 1, -1, -1], mask [True, True, False, False, False, False, False, False, False]\n",
            "mcts won  5218  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.11171659268438816 q value 0.31727441865950823  reward : -1\n",
            "game #num:  14600\n",
            "action not avaliable action<0,8> 3 , satae [-1, 1, 0, 1, 0, -1, -1, 1, 0], mask [False, False, True, False, True, False, False, False, True]\n",
            "action not avaliable action<0,8> 7 , satae [-1, 1, 0, 1, 0, -1, -1, 1, 0], mask [False, False, True, False, True, False, False, False, True]\n",
            "agent won  7954  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.1178038902580738 q value 0.31832025448481244  reward : 1\n",
            "game #num:  14601\n",
            "action not avaliable action<0,8> 3 , satae [0, 0, 0, 1, -1, 0, -1, 0, 1], mask [True, True, True, False, False, True, False, True, False]\n",
            "action not avaliable action<0,8> 4 , satae [-1, 0, 1, 1, -1, 0, -1, 0, 1], mask [False, True, False, False, False, True, False, True, False]\n",
            "action not avaliable action<0,8> 2 , satae [-1, 0, 1, 1, -1, 0, -1, 0, 1], mask [False, True, False, False, False, True, False, True, False]\n",
            "action not avaliable action<0,8> 3 , satae [-1, 0, 1, 1, -1, 0, -1, 0, 1], mask [False, True, False, False, False, True, False, True, False]\n",
            "action not avaliable action<0,8> 0 , satae [-1, 0, 1, 1, -1, 0, -1, 0, 1], mask [False, True, False, False, False, True, False, True, False]\n",
            "action not avaliable action<0,8> 2 , satae [-1, 0, 1, 1, -1, 0, -1, 0, 1], mask [False, True, False, False, False, True, False, True, False]\n",
            "mcts won  5219  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.1086769551038742 q value 0.31711940467357635  reward : -1\n",
            "game #num:  14602\n",
            "action not avaliable action<0,8> 6 , satae [0, 0, 0, 1, 0, -1, -1, 0, 0], mask [True, True, True, False, True, False, False, True, True]\n",
            "agent won  7955  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.12733364664018154 q value 0.3153250887989998  reward : 1\n",
            "game #num:  14603\n",
            "agent won  7956  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.11321379616856575 q value 0.31335365772247314  reward : 1\n",
            "game #num:  14604\n",
            "action not avaliable action<0,8> 0 , satae [-1, 1, 1, 0, -1, 0, 0, -1, 1], mask [False, False, False, True, False, True, True, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [-1, 1, 1, 1, -1, 0, -1, -1, 1], mask [False, False, False, False, False, True, False, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [-1, 1, 1, 1, -1, 0, -1, -1, 1], mask [False, False, False, False, False, True, False, False, False]\n",
            "draw  1429  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0]\n",
            "################################################################################################\n",
            "game loss:  0.1125642666593194 q value 0.3109656795859337  reward : 0\n",
            "game #num:  14605\n",
            "action not avaliable action<0,8> 7 , satae [1, 0, 1, 0, 0, 0, 0, -1, -1], mask [False, True, False, True, True, True, True, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [1, 0, 1, 0, 0, 0, 0, -1, -1], mask [False, True, False, True, True, True, True, False, False]\n",
            "mcts won  5220  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.1130264550447464 q value 0.30992911458015443  reward : -1\n",
            "game #num:  14606\n",
            "action not avaliable action<0,8> 8 , satae [1, 1, 0, -1, -1, 0, 0, 0, -1], mask [False, False, True, False, False, True, True, True, False]\n",
            "action not avaliable action<0,8> 0 , satae [1, 1, 0, -1, -1, 0, 0, 0, -1], mask [False, False, True, False, False, True, True, True, False]\n",
            "action not avaliable action<0,8> 4 , satae [1, 1, 0, -1, -1, 0, 0, 0, -1], mask [False, False, True, False, False, True, True, True, False]\n",
            "agent won  7957  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.11321946978569031 q value 0.3096081068118413  reward : 1\n",
            "game #num:  14607\n",
            "action not avaliable action<0,8> 8 , satae [-1, 0, -1, 0, 0, 0, 0, 0, 1], mask [False, True, False, True, True, True, True, True, False]\n",
            "action not avaliable action<0,8> 8 , satae [-1, 0, -1, 0, 0, 0, 0, 0, 1], mask [False, True, False, True, True, True, True, True, False]\n",
            "draw  1430  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0]\n",
            "################################################################################################\n",
            "game loss:  0.11185747136672337 q value 0.31009600063165027  reward : 0\n",
            "game #num:  14608\n",
            "action not avaliable action<0,8> 0 , satae [-1, 0, 0, 0, 0, 0, 0, 0, 1], mask [False, True, True, True, True, True, True, True, False]\n",
            "action not avaliable action<0,8> 3 , satae [-1, 0, 1, -1, 0, 0, 0, 0, 1], mask [False, True, False, False, True, True, True, True, False]\n",
            "action not avaliable action<0,8> 0 , satae [-1, 0, 1, -1, 0, 0, 0, 0, 1], mask [False, True, False, False, True, True, True, True, False]\n",
            "action not avaliable action<0,8> 3 , satae [-1, 0, 1, -1, -1, 0, 1, 0, 1], mask [False, True, False, False, False, True, False, True, False]\n",
            "mcts won  5221  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.11014231853187084 q value 0.3130413368344307  reward : -1\n",
            "game #num:  14609\n",
            "action not avaliable action<0,8> 2 , satae [-1, 0, 1, 0, 0, 0, 0, -1, 0], mask [False, True, False, True, True, True, True, False, True]\n",
            "action not avaliable action<0,8> 2 , satae [-1, 0, 1, 0, 0, 0, 0, -1, 0], mask [False, True, False, True, True, True, True, False, True]\n",
            "action not avaliable action<0,8> 0 , satae [-1, 0, 1, 0, 0, 0, 0, -1, 0], mask [False, True, False, True, True, True, True, False, True]\n",
            "action not avaliable action<0,8> 7 , satae [-1, 0, 1, 0, 0, 0, 0, -1, 0], mask [False, True, False, True, True, True, True, False, True]\n",
            "action not avaliable action<0,8> 7 , satae [-1, 0, 1, 0, 0, 0, 0, -1, 0], mask [False, True, False, True, True, True, True, False, True]\n",
            "action not avaliable action<0,8> 0 , satae [-1, 0, 1, 0, 0, 0, 1, -1, -1], mask [False, True, False, True, True, True, False, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [-1, 0, 1, 0, 0, 0, 1, -1, -1], mask [False, True, False, True, True, True, False, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [-1, 0, 1, 0, 0, 0, 1, -1, -1], mask [False, True, False, True, True, True, False, False, False]\n",
            "action not avaliable action<0,8> 0 , satae [-1, 0, 1, 0, 0, 0, 1, -1, -1], mask [False, True, False, True, True, True, False, False, False]\n",
            "action not avaliable action<0,8> 2 , satae [-1, 0, 1, 0, 0, 0, 1, -1, -1], mask [False, True, False, True, True, True, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [-1, 0, 1, 0, 0, 0, 1, -1, -1], mask [False, True, False, True, True, True, False, False, False]\n",
            "action not avaliable action<0,8> 0 , satae [-1, 0, 1, 0, 0, 0, 1, -1, -1], mask [False, True, False, True, True, True, False, False, False]\n",
            "agent won  7958  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.11233666638533274 q value 0.319889509677887  reward : 1\n",
            "game #num:  14610\n",
            "action not avaliable action<0,8> 6 , satae [0, -1, 0, 0, 1, -1, 1, 0, 0], mask [True, False, True, True, False, False, False, True, True]\n",
            "action not avaliable action<0,8> 6 , satae [0, -1, 0, 0, 1, -1, 1, 1, -1], mask [True, False, True, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 5 , satae [0, -1, 0, 0, 1, -1, 1, 1, -1], mask [True, False, True, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [0, -1, 0, 0, 1, -1, 1, 1, -1], mask [True, False, True, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 4 , satae [0, -1, 0, 0, 1, -1, 1, 1, -1], mask [True, False, True, True, False, False, False, False, False]\n",
            "agent won  7959  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.10958158555958006 q value 0.3228577739662594  reward : 1\n",
            "game #num:  14611\n",
            "action not avaliable action<0,8> 8 , satae [0, 0, 0, 0, 0, 0, 0, 0, -1], mask [True, True, True, True, True, True, True, True, False]\n",
            "action not avaliable action<0,8> 3 , satae [1, 0, 0, -1, 1, 0, -1, 0, -1], mask [False, True, True, False, False, True, False, True, False]\n",
            "agent won  7960  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.11496418565511704 q value 0.32493795156478883  reward : 1\n",
            "game #num:  14612\n",
            "action not avaliable action<0,8> 6 , satae [0, 0, 0, 0, -1, 1, -1, 0, 0], mask [True, True, True, True, False, False, False, True, True]\n",
            "action not avaliable action<0,8> 8 , satae [1, 0, 0, 0, -1, 1, -1, 0, -1], mask [False, True, True, True, False, False, False, True, False]\n",
            "action not avaliable action<0,8> 5 , satae [1, 0, 0, 0, -1, 1, -1, 0, -1], mask [False, True, True, True, False, False, False, True, False]\n",
            "action not avaliable action<0,8> 8 , satae [1, 0, 0, 0, -1, 1, -1, 0, -1], mask [False, True, True, True, False, False, False, True, False]\n",
            "action not avaliable action<0,8> 8 , satae [1, 0, 0, 0, -1, 1, -1, 0, -1], mask [False, True, True, True, False, False, False, True, False]\n",
            "action not avaliable action<0,8> 8 , satae [1, 0, 0, 0, -1, 1, -1, 0, -1], mask [False, True, True, True, False, False, False, True, False]\n",
            "action not avaliable action<0,8> 5 , satae [1, 0, 0, 0, -1, 1, -1, 0, -1], mask [False, True, True, True, False, False, False, True, False]\n",
            "mcts won  5222  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.11409282311797142 q value 0.3277102649211884  reward : -1\n",
            "game #num:  14613\n",
            "mcts won  5223  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.10996139049530029 q value 0.32825416326522827  reward : -1\n",
            "game #num:  14614\n",
            "action not avaliable action<0,8> 8 , satae [1, 0, 0, 0, 1, 0, 0, -1, -1], mask [False, True, True, True, False, True, True, False, False]\n",
            "action not avaliable action<0,8> 5 , satae [1, 0, 1, 0, 1, -1, 0, -1, -1], mask [False, True, False, True, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [1, 0, 1, 0, 1, -1, 0, -1, -1], mask [False, True, False, True, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [1, 0, 1, 0, 1, -1, 0, -1, -1], mask [False, True, False, True, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [1, 0, 1, 0, 1, -1, 0, -1, -1], mask [False, True, False, True, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 2 , satae [1, 0, 1, 0, 1, -1, 0, -1, -1], mask [False, True, False, True, False, False, True, False, False]\n",
            "agent won  7961  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.11059513986110688 q value 0.32685900330543516  reward : 1\n",
            "game #num:  14615\n",
            "action not avaliable action<0,8> 4 , satae [0, -1, 0, 1, 1, 0, -1, -1, 1], mask [True, False, True, False, False, True, False, False, False]\n",
            "action not avaliable action<0,8> 1 , satae [0, -1, 0, 1, 1, 0, -1, -1, 1], mask [True, False, True, False, False, True, False, False, False]\n",
            "action not avaliable action<0,8> 4 , satae [0, -1, 0, 1, 1, 0, -1, -1, 1], mask [True, False, True, False, False, True, False, False, False]\n",
            "action not avaliable action<0,8> 4 , satae [0, -1, 0, 1, 1, 0, -1, -1, 1], mask [True, False, True, False, False, True, False, False, False]\n",
            "action not avaliable action<0,8> 4 , satae [0, -1, 0, 1, 1, 0, -1, -1, 1], mask [True, False, True, False, False, True, False, False, False]\n",
            "mcts won  5224  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.11599752555290858 q value 0.3219447169038985  reward : -1\n",
            "game #num:  14616\n",
            "action not avaliable action<0,8> 8 , satae [0, -1, 0, -1, 0, 0, 0, 0, 1], mask [True, False, True, False, True, True, True, True, False]\n",
            "action not avaliable action<0,8> 6 , satae [0, -1, -1, -1, 0, 0, 1, 0, 1], mask [True, False, False, False, True, True, False, True, False]\n",
            "action not avaliable action<0,8> 1 , satae [0, -1, -1, -1, 0, 0, 1, 0, 1], mask [True, False, False, False, True, True, False, True, False]\n",
            "agent won  7962  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.11043524245421092 q value 0.31999526421229046  reward : 1\n",
            "game #num:  14617\n",
            "action not avaliable action<0,8> 0 , satae [-1, 0, 0, 0, 0, 0, 1, 0, -1], mask [False, True, True, True, True, True, False, True, False]\n",
            "agent won  7963  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.12257879227399826 q value 0.32107189297676086  reward : 1\n",
            "game #num:  14618\n",
            "action not avaliable action<0,8> 4 , satae [0, 0, -1, -1, -1, 1, 0, 0, 1], mask [True, True, False, False, False, False, True, True, False]\n",
            "action not avaliable action<0,8> 5 , satae [0, 0, -1, -1, -1, 1, 0, 0, 1], mask [True, True, False, False, False, False, True, True, False]\n",
            "agent won  7964  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.11624177421132724 q value 0.3214162190755208  reward : 1\n",
            "game #num:  14619\n",
            "action not avaliable action<0,8> 3 , satae [1, -1, -1, -1, 0, 1, 1, -1, 0], mask [False, False, False, False, True, False, False, False, True]\n",
            "action not avaliable action<0,8> 1 , satae [1, -1, -1, -1, 0, 1, 1, -1, 0], mask [False, False, False, False, True, False, False, False, True]\n",
            "action not avaliable action<0,8> 0 , satae [1, -1, -1, -1, 0, 1, 1, -1, 0], mask [False, False, False, False, True, False, False, False, True]\n",
            "action not avaliable action<0,8> 0 , satae [1, -1, -1, -1, 0, 1, 1, -1, 0], mask [False, False, False, False, True, False, False, False, True]\n",
            "action not avaliable action<0,8> 1 , satae [1, -1, -1, -1, 0, 1, 1, -1, 0], mask [False, False, False, False, True, False, False, False, True]\n",
            "mcts won  5225  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.10237794700596067 q value 0.3239969313144684  reward : -1\n",
            "game #num:  14620\n",
            "action not avaliable action<0,8> 7 , satae [1, 1, -1, 0, 1, -1, 0, -1, 0], mask [False, False, False, True, False, False, True, False, True]\n",
            "action not avaliable action<0,8> 0 , satae [1, 1, -1, 0, 1, -1, 0, -1, 0], mask [False, False, False, True, False, False, True, False, True]\n",
            "action not avaliable action<0,8> 7 , satae [1, 1, -1, 0, 1, -1, 0, -1, 0], mask [False, False, False, True, False, False, True, False, True]\n",
            "action not avaliable action<0,8> 5 , satae [1, 1, -1, 0, 1, -1, 0, -1, 0], mask [False, False, False, True, False, False, True, False, True]\n",
            "action not avaliable action<0,8> 7 , satae [1, 1, -1, 0, 1, -1, 0, -1, 0], mask [False, False, False, True, False, False, True, False, True]\n",
            "action not avaliable action<0,8> 4 , satae [1, 1, -1, 0, 1, -1, 0, -1, 0], mask [False, False, False, True, False, False, True, False, True]\n",
            "mcts won  5226  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.12715496197342874 q value 0.3266561537981033  reward : -1\n",
            "game #num:  14621\n",
            "action not avaliable action<0,8> 3 , satae [-1, -1, 0, 1, 1, -1, 1, -1, 1], mask [False, False, True, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [-1, -1, 0, 1, 1, -1, 1, -1, 1], mask [False, False, True, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [-1, -1, 0, 1, 1, -1, 1, -1, 1], mask [False, False, True, False, False, False, False, False, False]\n",
            "agent won  7965  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.11939384136348963 q value 0.3232548274099827  reward : 1\n",
            "game #num:  14622\n",
            "action not avaliable action<0,8> 6 , satae [0, 1, -1, -1, 1, -1, -1, 0, 1], mask [True, False, False, False, False, False, False, True, False]\n",
            "action not avaliable action<0,8> 4 , satae [0, 1, -1, -1, 1, -1, -1, 0, 1], mask [True, False, False, False, False, False, False, True, False]\n",
            "action not avaliable action<0,8> 3 , satae [0, 1, -1, -1, 1, -1, -1, 0, 1], mask [True, False, False, False, False, False, False, True, False]\n",
            "action not avaliable action<0,8> 4 , satae [0, 1, -1, -1, 1, -1, -1, 0, 1], mask [True, False, False, False, False, False, False, True, False]\n",
            "action not avaliable action<0,8> 2 , satae [0, 1, -1, -1, 1, -1, -1, 0, 1], mask [True, False, False, False, False, False, False, True, False]\n",
            "action not avaliable action<0,8> 5 , satae [0, 1, -1, -1, 1, -1, -1, 0, 1], mask [True, False, False, False, False, False, False, True, False]\n",
            "action not avaliable action<0,8> 5 , satae [0, 1, -1, -1, 1, -1, -1, 0, 1], mask [True, False, False, False, False, False, False, True, False]\n",
            "action not avaliable action<0,8> 4 , satae [0, 1, -1, -1, 1, -1, -1, 0, 1], mask [True, False, False, False, False, False, False, True, False]\n",
            "action not avaliable action<0,8> 2 , satae [0, 1, -1, -1, 1, -1, -1, 0, 1], mask [True, False, False, False, False, False, False, True, False]\n",
            "agent won  7966  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.11828082857223657 q value 0.32318912331874555  reward : 1\n",
            "game #num:  14623\n",
            "action not avaliable action<0,8> 2 , satae [0, 0, 1, -1, 1, 0, -1, -1, 0], mask [True, True, False, False, False, True, False, False, True]\n",
            "action not avaliable action<0,8> 7 , satae [0, -1, 1, -1, 1, 1, -1, -1, 0], mask [True, False, False, False, False, False, False, False, True]\n",
            "action not avaliable action<0,8> 3 , satae [0, -1, 1, -1, 1, 1, -1, -1, 0], mask [True, False, False, False, False, False, False, False, True]\n",
            "action not avaliable action<0,8> 7 , satae [0, -1, 1, -1, 1, 1, -1, -1, 0], mask [True, False, False, False, False, False, False, False, True]\n",
            "agent won  7967  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.11763859447091818 q value 0.32347485795617104  reward : 1\n",
            "game #num:  14624\n",
            "action not avaliable action<0,8> 6 , satae [0, 0, 0, 0, -1, 0, 1, 0, 0], mask [True, True, True, True, False, True, False, True, True]\n",
            "action not avaliable action<0,8> 4 , satae [0, 0, 0, 0, -1, 0, 1, 0, 0], mask [True, True, True, True, False, True, False, True, True]\n",
            "action not avaliable action<0,8> 6 , satae [0, 0, 0, 0, -1, 0, 1, 0, 0], mask [True, True, True, True, False, True, False, True, True]\n",
            "action not avaliable action<0,8> 6 , satae [0, 0, -1, 0, -1, 1, 1, 0, 0], mask [True, True, False, True, False, False, False, True, True]\n",
            "action not avaliable action<0,8> 2 , satae [0, 0, -1, 0, -1, 1, 1, 0, 0], mask [True, True, False, True, False, False, False, True, True]\n",
            "action not avaliable action<0,8> 6 , satae [0, 0, -1, 0, -1, 1, 1, 0, 0], mask [True, True, False, True, False, False, False, True, True]\n",
            "action not avaliable action<0,8> 2 , satae [0, 1, -1, 0, -1, 1, 1, 0, -1], mask [True, False, False, True, False, False, False, True, False]\n",
            "action not avaliable action<0,8> 2 , satae [0, 1, -1, 0, -1, 1, 1, 0, -1], mask [True, False, False, True, False, False, False, True, False]\n",
            "agent won  7968  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.11146149970591068 q value 0.3207375705242157  reward : 1\n",
            "game #num:  14625\n",
            "agent won  7969  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.1201062227288882 q value 0.31854432821273804  reward : 1\n",
            "game #num:  14626\n",
            "action not avaliable action<0,8> 0 , satae [-1, -1, 1, 0, 0, 0, -1, 1, 0], mask [False, False, False, True, True, True, False, False, True]\n",
            "draw  1431  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0]\n",
            "################################################################################################\n",
            "game loss:  0.11590210795402527 q value 0.31762059926986697  reward : 0\n",
            "game #num:  14627\n",
            "action not avaliable action<0,8> 4 , satae [0, -1, 0, -1, 1, 0, 1, 0, 0], mask [True, False, True, False, False, True, False, True, True]\n",
            "action not avaliable action<0,8> 4 , satae [0, -1, 0, -1, 1, 0, 1, 0, 0], mask [True, False, True, False, False, True, False, True, True]\n",
            "action not avaliable action<0,8> 6 , satae [0, -1, 0, -1, 1, 0, 1, 0, 0], mask [True, False, True, False, False, True, False, True, True]\n",
            "action not avaliable action<0,8> 6 , satae [0, -1, 0, -1, 1, 0, 1, 0, 0], mask [True, False, True, False, False, True, False, True, True]\n",
            "action not avaliable action<0,8> 6 , satae [0, -1, 0, -1, 1, 0, 1, 0, 0], mask [True, False, True, False, False, True, False, True, True]\n",
            "action not avaliable action<0,8> 7 , satae [1, -1, 0, -1, 1, 0, 1, -1, 0], mask [False, False, True, False, False, True, False, False, True]\n",
            "action not avaliable action<0,8> 0 , satae [1, -1, 0, -1, 1, 0, 1, -1, 0], mask [False, False, True, False, False, True, False, False, True]\n",
            "action not avaliable action<0,8> 1 , satae [1, -1, 0, -1, 1, 0, 1, -1, 0], mask [False, False, True, False, False, True, False, False, True]\n",
            "action not avaliable action<0,8> 4 , satae [1, -1, 0, -1, 1, 0, 1, -1, 0], mask [False, False, True, False, False, True, False, False, True]\n",
            "action not avaliable action<0,8> 1 , satae [1, -1, 0, -1, 1, 0, 1, -1, 0], mask [False, False, True, False, False, True, False, False, True]\n",
            "action not avaliable action<0,8> 7 , satae [1, -1, -1, -1, 1, 1, 1, -1, 0], mask [False, False, False, False, False, False, False, False, True]\n",
            "action not avaliable action<0,8> 1 , satae [1, -1, -1, -1, 1, 1, 1, -1, 0], mask [False, False, False, False, False, False, False, False, True]\n",
            "action not avaliable action<0,8> 5 , satae [1, -1, -1, -1, 1, 1, 1, -1, 0], mask [False, False, False, False, False, False, False, False, True]\n",
            "draw  1432  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "################################################################################################\n",
            "game loss:  0.10729165458016926 q value 0.31926387714015114  reward : 0\n",
            "game #num:  14628\n",
            "action not avaliable action<0,8> 8 , satae [0, 1, 1, 0, 0, 0, -1, 0, -1], mask [True, False, False, True, True, True, False, True, False]\n",
            "action not avaliable action<0,8> 6 , satae [0, 1, 1, 0, 0, 0, -1, 0, -1], mask [True, False, False, True, True, True, False, True, False]\n",
            "action not avaliable action<0,8> 6 , satae [0, 1, 1, 0, 0, 0, -1, 0, -1], mask [True, False, False, True, True, True, False, True, False]\n",
            "action not avaliable action<0,8> 1 , satae [0, 1, 1, 0, 0, 0, -1, 0, -1], mask [True, False, False, True, True, True, False, True, False]\n",
            "action not avaliable action<0,8> 8 , satae [0, 1, 1, 0, 0, 0, -1, 0, -1], mask [True, False, False, True, True, True, False, True, False]\n",
            "action not avaliable action<0,8> 1 , satae [0, 1, 1, 0, 0, 0, -1, 0, -1], mask [True, False, False, True, True, True, False, True, False]\n",
            "action not avaliable action<0,8> 2 , satae [0, 1, 1, 0, 0, 0, -1, 0, -1], mask [True, False, False, True, True, True, False, True, False]\n",
            "agent won  7970  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.11565879136323928 q value 0.32270863354206086  reward : 1\n",
            "game #num:  14629\n",
            "action not avaliable action<0,8> 1 , satae [0, -1, 1, -1, -1, 0, 1, 0, 1], mask [True, False, False, False, False, True, False, True, False]\n",
            "action not avaliable action<0,8> 3 , satae [0, -1, 1, -1, -1, 0, 1, 0, 1], mask [True, False, False, False, False, True, False, True, False]\n",
            "action not avaliable action<0,8> 3 , satae [0, -1, 1, -1, -1, 0, 1, 0, 1], mask [True, False, False, False, False, True, False, True, False]\n",
            "action not avaliable action<0,8> 1 , satae [0, -1, 1, -1, -1, 0, 1, 0, 1], mask [True, False, False, False, False, True, False, True, False]\n",
            "agent won  7971  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.10846017766743898 q value 0.32481955736875534  reward : 1\n",
            "game #num:  14630\n",
            "action not avaliable action<0,8> 6 , satae [0, 0, 0, 0, 0, 1, -1, -1, 1], mask [True, True, True, True, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [1, 0, 0, 0, -1, 1, -1, -1, 1], mask [False, True, True, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 0 , satae [1, 0, 0, 0, -1, 1, -1, -1, 1], mask [False, True, True, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 0 , satae [1, 0, 0, 0, -1, 1, -1, -1, 1], mask [False, True, True, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [1, 0, 0, 0, -1, 1, -1, -1, 1], mask [False, True, True, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 0 , satae [1, 0, 0, 0, -1, 1, -1, -1, 1], mask [False, True, True, True, False, False, False, False, False]\n",
            "mcts won  5227  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.11561105623841286 q value 0.3242608278989792  reward : -1\n",
            "game #num:  14631\n",
            "action not avaliable action<0,8> 0 , satae [1, 0, 1, -1, -1, 0, 0, -1, 0], mask [False, True, False, False, False, True, True, False, True]\n",
            "action not avaliable action<0,8> 2 , satae [1, 0, 1, -1, -1, 0, 0, -1, 0], mask [False, True, False, False, False, True, True, False, True]\n",
            "action not avaliable action<0,8> 7 , satae [1, 0, 1, -1, -1, 0, 0, -1, 0], mask [False, True, False, False, False, True, True, False, True]\n",
            "agent won  7972  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.1091827464600404 q value 0.3237747053305308  reward : 1\n",
            "game #num:  14632\n",
            "action not avaliable action<0,8> 0 , satae [1, 0, 0, -1, 0, -1, 0, 1, 0], mask [False, True, True, False, True, False, True, False, True]\n",
            "action not avaliable action<0,8> 5 , satae [1, 0, -1, -1, 0, -1, 1, 1, 0], mask [False, True, False, False, True, False, False, False, True]\n",
            "action not avaliable action<0,8> 0 , satae [1, 0, -1, -1, 0, -1, 1, 1, 0], mask [False, True, False, False, True, False, False, False, True]\n",
            "agent won  7973  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.11755187277282987 q value 0.3234582841396332  reward : 1\n",
            "game #num:  14633\n",
            "action not avaliable action<0,8> 4 , satae [0, 0, 0, 0, -1, 0, 0, 0, 0], mask [True, True, True, True, False, True, True, True, True]\n",
            "action not avaliable action<0,8> 0 , satae [1, 0, 0, 0, -1, 0, 0, -1, 0], mask [False, True, True, True, False, True, True, False, True]\n",
            "action not avaliable action<0,8> 0 , satae [1, 0, 0, 0, -1, 0, 0, -1, 0], mask [False, True, True, True, False, True, True, False, True]\n",
            "action not avaliable action<0,8> 0 , satae [1, 0, 0, 0, -1, 0, 0, -1, 0], mask [False, True, True, True, False, True, True, False, True]\n",
            "action not avaliable action<0,8> 0 , satae [1, 0, 1, 0, -1, 0, -1, -1, 0], mask [False, True, False, True, False, True, False, False, True]\n",
            "action not avaliable action<0,8> 6 , satae [1, 0, 1, 0, -1, 0, -1, -1, 0], mask [False, True, False, True, False, True, False, False, True]\n",
            "action not avaliable action<0,8> 2 , satae [1, 0, 1, 0, -1, 0, -1, -1, 0], mask [False, True, False, True, False, True, False, False, True]\n",
            "mcts won  5228  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.10946590229868888 q value 0.3255854189395905  reward : -1\n",
            "game #num:  14634\n",
            "action not avaliable action<0,8> 0 , satae [-1, 1, 0, 0, 0, 0, 0, -1, 0], mask [False, False, True, True, True, True, True, False, True]\n",
            "action not avaliable action<0,8> 6 , satae [-1, 1, 0, 0, 0, -1, 1, -1, 0], mask [False, False, True, True, True, False, False, False, True]\n",
            "action not avaliable action<0,8> 6 , satae [-1, 1, 0, 1, -1, -1, 1, -1, 0], mask [False, False, True, False, False, False, False, False, True]\n",
            "action not avaliable action<0,8> 5 , satae [-1, 1, 0, 1, -1, -1, 1, -1, 0], mask [False, False, True, False, False, False, False, False, True]\n",
            "action not avaliable action<0,8> 5 , satae [-1, 1, 0, 1, -1, -1, 1, -1, 0], mask [False, False, True, False, False, False, False, False, True]\n",
            "action not avaliable action<0,8> 5 , satae [-1, 1, 0, 1, -1, -1, 1, -1, 0], mask [False, False, True, False, False, False, False, False, True]\n",
            "action not avaliable action<0,8> 7 , satae [-1, 1, 0, 1, -1, -1, 1, -1, 0], mask [False, False, True, False, False, False, False, False, True]\n",
            "action not avaliable action<0,8> 7 , satae [-1, 1, 0, 1, -1, -1, 1, -1, 0], mask [False, False, True, False, False, False, False, False, True]\n",
            "action not avaliable action<0,8> 3 , satae [-1, 1, 0, 1, -1, -1, 1, -1, 0], mask [False, False, True, False, False, False, False, False, True]\n",
            "mcts won  5229  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.10869449950181521 q value 0.3324744517986591  reward : -1\n",
            "game #num:  14635\n",
            "action not avaliable action<0,8> 4 , satae [0, 0, -1, 0, 1, 1, -1, 1, -1], mask [True, True, False, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [0, 0, -1, 0, 1, 1, -1, 1, -1], mask [True, True, False, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [0, 0, -1, 0, 1, 1, -1, 1, -1], mask [True, True, False, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [0, 0, -1, 0, 1, 1, -1, 1, -1], mask [True, True, False, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 2 , satae [0, 0, -1, 0, 1, 1, -1, 1, -1], mask [True, True, False, True, False, False, False, False, False]\n",
            "agent won  7974  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.11601277358002132 q value 0.33544765909512836  reward : 1\n",
            "game #num:  14636\n",
            "action not avaliable action<0,8> 7 , satae [0, 0, 0, 1, 0, 0, 0, -1, 0], mask [True, True, True, False, True, True, True, False, True]\n",
            "action not avaliable action<0,8> 0 , satae [-1, 1, -1, 1, 0, -1, 1, -1, 1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 2 , satae [-1, 1, -1, 1, 0, -1, 1, -1, 1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [-1, 1, -1, 1, 0, -1, 1, -1, 1], mask [False, False, False, False, True, False, False, False, False]\n",
            "draw  1433  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "################################################################################################\n",
            "game loss:  0.10508219732178582 q value 0.33445444371965194  reward : 0\n",
            "game #num:  14637\n",
            "mcts won  5230  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.11673053540289402 q value 0.33235036581754684  reward : -1\n",
            "game #num:  14638\n",
            "action not avaliable action<0,8> 2 , satae [-1, 0, -1, 0, 0, 1, 0, 0, 0], mask [False, True, False, True, True, False, True, True, True]\n",
            "action not avaliable action<0,8> 2 , satae [-1, 0, -1, 0, 0, 1, 0, 0, 0], mask [False, True, False, True, True, False, True, True, True]\n",
            "mcts won  5231  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.11822324246168137 q value 0.3304314762353897  reward : -1\n",
            "game #num:  14639\n",
            "action not avaliable action<0,8> 7 , satae [0, -1, 0, 0, 0, 0, 0, -1, 1], mask [True, False, True, True, True, True, True, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [0, -1, 0, 0, 0, 0, 0, -1, 1], mask [True, False, True, True, True, True, True, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [0, -1, 0, 0, 0, 0, 0, -1, 1], mask [True, False, True, True, True, True, True, False, False]\n",
            "agent won  7975  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.12835377330581346 q value 0.3270522554715474  reward : 1\n",
            "game #num:  14640\n",
            "action not avaliable action<0,8> 1 , satae [0, -1, 0, 0, -1, 0, 0, 0, 1], mask [True, False, True, True, False, True, True, True, False]\n",
            "action not avaliable action<0,8> 5 , satae [1, -1, -1, 0, -1, -1, 0, 1, 1], mask [False, False, False, True, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 5 , satae [1, -1, -1, 0, -1, -1, 0, 1, 1], mask [False, False, False, True, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 1 , satae [1, -1, -1, 0, -1, -1, 0, 1, 1], mask [False, False, False, True, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [1, -1, -1, 0, -1, -1, 0, 1, 1], mask [False, False, False, True, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [1, -1, -1, 0, -1, -1, 0, 1, 1], mask [False, False, False, True, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [1, -1, -1, 0, -1, -1, 0, 1, 1], mask [False, False, False, True, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 1 , satae [1, -1, -1, 0, -1, -1, 0, 1, 1], mask [False, False, False, True, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [1, -1, -1, 0, -1, -1, 0, 1, 1], mask [False, False, False, True, False, False, True, False, False]\n",
            "agent won  7976  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.1147458226634906 q value 0.322053652543288  reward : 1\n",
            "game #num:  14641\n",
            "action not avaliable action<0,8> 0 , satae [1, 0, -1, -1, 0, 1, 0, 0, 0], mask [False, True, False, False, True, False, True, True, True]\n",
            "action not avaliable action<0,8> 0 , satae [1, 0, -1, -1, 0, 1, 0, 0, 0], mask [False, True, False, False, True, False, True, True, True]\n",
            "action not avaliable action<0,8> 6 , satae [1, -1, -1, -1, 0, 1, 1, 0, 0], mask [False, False, False, False, True, False, False, True, True]\n",
            "action not avaliable action<0,8> 0 , satae [1, -1, -1, -1, 0, 1, 1, 0, 0], mask [False, False, False, False, True, False, False, True, True]\n",
            "action not avaliable action<0,8> 8 , satae [1, -1, -1, -1, 0, 1, 1, 1, -1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 3 , satae [1, -1, -1, -1, 0, 1, 1, 1, -1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 3 , satae [1, -1, -1, -1, 0, 1, 1, 1, -1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [1, -1, -1, -1, 0, 1, 1, 1, -1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 5 , satae [1, -1, -1, -1, 0, 1, 1, 1, -1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 1 , satae [1, -1, -1, -1, 0, 1, 1, 1, -1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [1, -1, -1, -1, 0, 1, 1, 1, -1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [1, -1, -1, -1, 0, 1, 1, 1, -1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [1, -1, -1, -1, 0, 1, 1, 1, -1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 2 , satae [1, -1, -1, -1, 0, 1, 1, 1, -1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 5 , satae [1, -1, -1, -1, 0, 1, 1, 1, -1], mask [False, False, False, False, True, False, False, False, False]\n",
            "draw  1434  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "################################################################################################\n",
            "game loss:  0.12816423401236535 q value 0.31687785089015963  reward : 0\n",
            "game #num:  14642\n",
            "action not avaliable action<0,8> 6 , satae [1, -1, 1, 0, 1, -1, -1, 1, -1], mask [False, False, False, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 0 , satae [1, -1, 1, 0, 1, -1, -1, 1, -1], mask [False, False, False, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [1, -1, 1, 0, 1, -1, -1, 1, -1], mask [False, False, False, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 5 , satae [1, -1, 1, 0, 1, -1, -1, 1, -1], mask [False, False, False, True, False, False, False, False, False]\n",
            "draw  1435  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "################################################################################################\n",
            "game loss:  0.11503660264942381 q value 0.3129337893591987  reward : 0\n",
            "game #num:  14643\n",
            "action not avaliable action<0,8> 1 , satae [0, -1, 0, 0, 1, 0, 0, -1, 1], mask [True, False, True, True, False, True, True, False, False]\n",
            "action not avaliable action<0,8> 1 , satae [0, -1, 0, 0, 1, 0, 0, -1, 1], mask [True, False, True, True, False, True, True, False, False]\n",
            "agent won  7977  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.11344129145145417 q value 0.31375077962875364  reward : 1\n",
            "game #num:  14644\n",
            "action not avaliable action<0,8> 3 , satae [0, 0, 0, -1, 0, 0, 1, 0, 0], mask [True, True, True, False, True, True, False, True, True]\n",
            "action not avaliable action<0,8> 7 , satae [0, -1, 0, -1, 0, 1, 1, -1, 1], mask [True, False, True, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [0, -1, 0, -1, 0, 1, 1, -1, 1], mask [True, False, True, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 1 , satae [0, -1, 0, -1, 0, 1, 1, -1, 1], mask [True, False, True, False, True, False, False, False, False]\n",
            "mcts won  5232  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.12344927620142698 q value 0.3175048790872097  reward : -1\n",
            "game #num:  14645\n",
            "action not avaliable action<0,8> 3 , satae [1, 0, 0, -1, 0, 0, 0, 0, -1], mask [False, True, True, False, True, True, True, True, False]\n",
            "action not avaliable action<0,8> 8 , satae [1, 0, 0, -1, 0, 0, 0, 0, -1], mask [False, True, True, False, True, True, True, True, False]\n",
            "action not avaliable action<0,8> 3 , satae [1, 0, 0, -1, 1, -1, -1, 1, -1], mask [False, True, True, False, False, False, False, False, False]\n",
            "draw  1436  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0]\n",
            "################################################################################################\n",
            "game loss:  0.10833509904997689 q value 0.31945742879595074  reward : 0\n",
            "game #num:  14646\n",
            "action not avaliable action<0,8> 6 , satae [0, 0, 0, -1, 0, -1, 1, 0, 0], mask [True, True, True, False, True, False, False, True, True]\n",
            "action not avaliable action<0,8> 3 , satae [0, 0, 0, -1, 0, -1, 1, 0, 0], mask [True, True, True, False, True, False, False, True, True]\n",
            "action not avaliable action<0,8> 5 , satae [0, 0, 0, -1, 0, -1, 1, 0, 0], mask [True, True, True, False, True, False, False, True, True]\n",
            "action not avaliable action<0,8> 5 , satae [0, 0, 0, -1, 0, -1, 1, 0, 0], mask [True, True, True, False, True, False, False, True, True]\n",
            "action not avaliable action<0,8> 6 , satae [0, 0, 0, -1, 0, -1, 1, 0, 0], mask [True, True, True, False, True, False, False, True, True]\n",
            "mcts won  5233  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.10907932464033365 q value 0.3203307241201401  reward : -1\n",
            "game #num:  14647\n",
            "action not avaliable action<0,8> 5 , satae [1, 0, 0, 0, 0, -1, 0, -1, 1], mask [False, True, True, True, True, False, True, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [1, 0, -1, 0, 0, -1, 1, -1, 1], mask [False, True, False, True, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [1, 0, -1, 0, 0, -1, 1, -1, 1], mask [False, True, False, True, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 0 , satae [1, 0, -1, 0, 0, -1, 1, -1, 1], mask [False, True, False, True, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 0 , satae [1, 0, -1, 0, 0, -1, 1, -1, 1], mask [False, True, False, True, True, False, False, False, False]\n",
            "mcts won  5234  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.10858783374230067 q value 0.3232692778110504  reward : -1\n",
            "game #num:  14648\n",
            "action not avaliable action<0,8> 3 , satae [0, 0, -1, 1, 1, -1, -1, 1, 0], mask [True, True, False, False, False, False, False, False, True]\n",
            "action not avaliable action<0,8> 2 , satae [0, 0, -1, 1, 1, -1, -1, 1, 0], mask [True, True, False, False, False, False, False, False, True]\n",
            "action not avaliable action<0,8> 5 , satae [0, 0, -1, 1, 1, -1, -1, 1, 0], mask [True, True, False, False, False, False, False, False, True]\n",
            "action not avaliable action<0,8> 4 , satae [0, 0, -1, 1, 1, -1, -1, 1, 0], mask [True, True, False, False, False, False, False, False, True]\n",
            "agent won  7978  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.11751929204910994 q value 0.3255138732492924  reward : 1\n",
            "game #num:  14649\n",
            "action not avaliable action<0,8> 4 , satae [0, 0, 0, 0, -1, 0, 0, 0, 0], mask [True, True, True, True, False, True, True, True, True]\n",
            "mcts won  5235  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.10677777230739594 q value 0.32622234026590985  reward : -1\n",
            "game #num:  14650\n",
            "action not avaliable action<0,8> 1 , satae [0, -1, 0, 0, 0, 0, 1, -1, 1], mask [True, False, True, True, True, True, False, False, False]\n",
            "action not avaliable action<0,8> 0 , satae [-1, -1, 0, 0, 0, 1, 1, -1, 1], mask [False, False, True, True, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 5 , satae [-1, -1, 0, 0, 0, 1, 1, -1, 1], mask [False, False, True, True, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 0 , satae [-1, -1, 0, 0, 0, 1, 1, -1, 1], mask [False, False, True, True, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 0 , satae [-1, -1, 0, 0, 0, 1, 1, -1, 1], mask [False, False, True, True, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 1 , satae [-1, -1, 0, 0, 0, 1, 1, -1, 1], mask [False, False, True, True, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [-1, -1, 0, 0, 0, 1, 1, -1, 1], mask [False, False, True, True, True, False, False, False, False]\n",
            "mcts won  5236  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.11325349590995094 q value 0.3248948725787076  reward : -1\n",
            "game #num:  14651\n",
            "action not avaliable action<0,8> 3 , satae [0, 1, 1, -1, 1, -1, -1, -1, 1], mask [True, False, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 3 , satae [0, 1, 1, -1, 1, -1, -1, -1, 1], mask [True, False, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 3 , satae [0, 1, 1, -1, 1, -1, -1, -1, 1], mask [True, False, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [0, 1, 1, -1, 1, -1, -1, -1, 1], mask [True, False, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 3 , satae [0, 1, 1, -1, 1, -1, -1, -1, 1], mask [True, False, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 5 , satae [0, 1, 1, -1, 1, -1, -1, -1, 1], mask [True, False, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 2 , satae [0, 1, 1, -1, 1, -1, -1, -1, 1], mask [True, False, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 1 , satae [0, 1, 1, -1, 1, -1, -1, -1, 1], mask [True, False, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [0, 1, 1, -1, 1, -1, -1, -1, 1], mask [True, False, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 1 , satae [0, 1, 1, -1, 1, -1, -1, -1, 1], mask [True, False, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 1 , satae [0, 1, 1, -1, 1, -1, -1, -1, 1], mask [True, False, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [0, 1, 1, -1, 1, -1, -1, -1, 1], mask [True, False, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [0, 1, 1, -1, 1, -1, -1, -1, 1], mask [True, False, False, False, False, False, False, False, False]\n",
            "agent won  7979  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.11598184580604236 q value 0.3215950346655316  reward : 1\n",
            "game #num:  14652\n",
            "action not avaliable action<0,8> 0 , satae [1, 0, 0, -1, -1, 0, 0, 0, 0], mask [False, True, True, False, False, True, True, True, True]\n",
            "action not avaliable action<0,8> 3 , satae [1, 0, 0, -1, -1, 1, -1, 0, 0], mask [False, True, True, False, False, False, False, True, True]\n",
            "agent won  7980  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.11405410319566726 q value 0.3180316507816315  reward : 1\n",
            "game #num:  14653\n",
            "action not avaliable action<0,8> 7 , satae [0, 0, 0, 0, 0, 0, 0, -1, 0], mask [True, True, True, True, True, True, True, False, True]\n",
            "action not avaliable action<0,8> 5 , satae [0, 0, -1, 0, 0, 1, 0, -1, 0], mask [True, True, False, True, True, False, True, False, True]\n",
            "action not avaliable action<0,8> 7 , satae [0, 0, -1, -1, 0, 1, 0, -1, 1], mask [True, True, False, False, True, False, True, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [0, 0, -1, -1, 0, 1, 0, -1, 1], mask [True, True, False, False, True, False, True, False, False]\n",
            "action not avaliable action<0,8> 5 , satae [0, 0, -1, -1, 0, 1, 0, -1, 1], mask [True, True, False, False, True, False, True, False, False]\n",
            "action not avaliable action<0,8> 5 , satae [0, 0, -1, -1, 0, 1, 0, -1, 1], mask [True, True, False, False, True, False, True, False, False]\n",
            "mcts won  5237  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.11385190039873123 q value 0.3151981770992279  reward : -1\n",
            "game #num:  14654\n",
            "action not avaliable action<0,8> 7 , satae [0, 1, 0, 1, 0, -1, 0, -1, 0], mask [True, False, True, False, True, False, True, False, True]\n",
            "action not avaliable action<0,8> 1 , satae [0, 1, 0, 1, 0, -1, 0, -1, 0], mask [True, False, True, False, True, False, True, False, True]\n",
            "action not avaliable action<0,8> 7 , satae [0, 1, 0, 1, 0, -1, 0, -1, 0], mask [True, False, True, False, True, False, True, False, True]\n",
            "action not avaliable action<0,8> 1 , satae [0, 1, 0, 1, 0, -1, 0, -1, 0], mask [True, False, True, False, True, False, True, False, True]\n",
            "action not avaliable action<0,8> 7 , satae [0, 1, 0, 1, 0, -1, 0, -1, 0], mask [True, False, True, False, True, False, True, False, True]\n",
            "action not avaliable action<0,8> 3 , satae [-1, 1, 0, 1, 0, -1, 1, -1, 0], mask [False, False, True, False, True, False, False, False, True]\n",
            "action not avaliable action<0,8> 6 , satae [-1, 1, 0, 1, 0, -1, 1, -1, 0], mask [False, False, True, False, True, False, False, False, True]\n",
            "agent won  7981  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.11466076783835888 q value 0.31399456163247425  reward : 1\n",
            "game #num:  14655\n",
            "action not avaliable action<0,8> 8 , satae [0, -1, 0, -1, 0, 0, 0, 0, 1], mask [True, False, True, False, True, True, True, True, False]\n",
            "action not avaliable action<0,8> 1 , satae [0, -1, 0, -1, 0, 0, 0, 0, 1], mask [True, False, True, False, True, True, True, True, False]\n",
            "action not avaliable action<0,8> 0 , satae [1, -1, 0, -1, -1, 0, 0, 0, 1], mask [False, False, True, False, False, True, True, True, False]\n",
            "action not avaliable action<0,8> 4 , satae [1, -1, 0, -1, -1, 0, 0, 0, 1], mask [False, False, True, False, False, True, True, True, False]\n",
            "action not avaliable action<0,8> 0 , satae [1, -1, -1, -1, -1, 0, 1, 0, 1], mask [False, False, False, False, False, True, False, True, False]\n",
            "action not avaliable action<0,8> 2 , satae [1, -1, -1, -1, -1, 0, 1, 0, 1], mask [False, False, False, False, False, True, False, True, False]\n",
            "agent won  7982  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.1182890735566616 q value 0.3157687336206436  reward : 1\n",
            "game #num:  14656\n",
            "action not avaliable action<0,8> 5 , satae [0, -1, -1, 0, 0, 1, 0, 1, 0], mask [True, False, False, True, True, False, True, False, True]\n",
            "action not avaliable action<0,8> 1 , satae [0, -1, -1, 0, 0, 1, 0, 1, 0], mask [True, False, False, True, True, False, True, False, True]\n",
            "action not avaliable action<0,8> 7 , satae [0, -1, -1, 0, 0, 1, 0, 1, 0], mask [True, False, False, True, True, False, True, False, True]\n",
            "action not avaliable action<0,8> 2 , satae [0, -1, -1, 0, 0, 1, 0, 1, 0], mask [True, False, False, True, True, False, True, False, True]\n",
            "action not avaliable action<0,8> 5 , satae [0, -1, -1, 0, -1, 1, 0, 1, 1], mask [True, False, False, True, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [0, -1, -1, 0, -1, 1, 0, 1, 1], mask [True, False, False, True, False, False, True, False, False]\n",
            "mcts won  5238  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.10919201523065566 q value 0.3178239673376083  reward : -1\n",
            "game #num:  14657\n",
            "mcts won  5239  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.11168336868286133 q value 0.32030583918094635  reward : -1\n",
            "game #num:  14658\n",
            "action not avaliable action<0,8> 8 , satae [1, 0, 0, 0, 0, 0, -1, 0, -1], mask [False, True, True, True, True, True, False, True, False]\n",
            "mcts won  5240  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.11869406948486964 q value 0.3216344912846883  reward : -1\n",
            "game #num:  14659\n",
            "action not avaliable action<0,8> 6 , satae [0, 0, 0, 0, 0, 0, 1, -1, 0], mask [True, True, True, True, True, True, False, False, True]\n",
            "action not avaliable action<0,8> 7 , satae [0, 0, 0, 0, 0, 0, 1, -1, 0], mask [True, True, True, True, True, True, False, False, True]\n",
            "action not avaliable action<0,8> 7 , satae [0, 0, 0, 0, 0, 0, 1, -1, 0], mask [True, True, True, True, True, True, False, False, True]\n",
            "action not avaliable action<0,8> 6 , satae [0, 0, 0, 0, 0, 0, 1, -1, 0], mask [True, True, True, True, True, True, False, False, True]\n",
            "action not avaliable action<0,8> 3 , satae [1, 1, -1, -1, 0, 0, 1, -1, 0], mask [False, False, False, False, True, True, False, False, True]\n",
            "action not avaliable action<0,8> 6 , satae [1, 1, -1, -1, 0, 0, 1, -1, 0], mask [False, False, False, False, True, True, False, False, True]\n",
            "action not avaliable action<0,8> 6 , satae [1, 1, -1, -1, 0, 0, 1, -1, 0], mask [False, False, False, False, True, True, False, False, True]\n",
            "action not avaliable action<0,8> 7 , satae [1, 1, -1, -1, 0, 0, 1, -1, 0], mask [False, False, False, False, True, True, False, False, True]\n",
            "action not avaliable action<0,8> 7 , satae [1, 1, -1, -1, 0, 0, 1, -1, 0], mask [False, False, False, False, True, True, False, False, True]\n",
            "action not avaliable action<0,8> 7 , satae [1, 1, -1, -1, 0, 0, 1, -1, 0], mask [False, False, False, False, True, True, False, False, True]\n",
            "action not avaliable action<0,8> 7 , satae [1, 1, -1, -1, 0, 0, 1, -1, 0], mask [False, False, False, False, True, True, False, False, True]\n",
            "action not avaliable action<0,8> 0 , satae [1, 1, -1, -1, 0, 0, 1, -1, 0], mask [False, False, False, False, True, True, False, False, True]\n",
            "action not avaliable action<0,8> 0 , satae [1, 1, -1, -1, 0, 0, 1, -1, 0], mask [False, False, False, False, True, True, False, False, True]\n",
            "action not avaliable action<0,8> 6 , satae [1, 1, -1, -1, 0, -1, 1, -1, 1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 2 , satae [1, 1, -1, -1, 0, -1, 1, -1, 1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [1, 1, -1, -1, 0, -1, 1, -1, 1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 3 , satae [1, 1, -1, -1, 0, -1, 1, -1, 1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [1, 1, -1, -1, 0, -1, 1, -1, 1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [1, 1, -1, -1, 0, -1, 1, -1, 1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [1, 1, -1, -1, 0, -1, 1, -1, 1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [1, 1, -1, -1, 0, -1, 1, -1, 1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [1, 1, -1, -1, 0, -1, 1, -1, 1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [1, 1, -1, -1, 0, -1, 1, -1, 1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 2 , satae [1, 1, -1, -1, 0, -1, 1, -1, 1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [1, 1, -1, -1, 0, -1, 1, -1, 1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 5 , satae [1, 1, -1, -1, 0, -1, 1, -1, 1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 5 , satae [1, 1, -1, -1, 0, -1, 1, -1, 1], mask [False, False, False, False, True, False, False, False, False]\n",
            "agent won  7983  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.11261377949267626 q value 0.32345539703965187  reward : 1\n",
            "game #num:  14660\n",
            "action not avaliable action<0,8> 5 , satae [0, 1, 1, -1, 0, -1, 1, 0, -1], mask [True, False, False, False, True, False, False, True, False]\n",
            "action not avaliable action<0,8> 1 , satae [0, 1, 1, -1, 0, -1, 1, 0, -1], mask [True, False, False, False, True, False, False, True, False]\n",
            "action not avaliable action<0,8> 1 , satae [0, 1, 1, -1, 0, -1, 1, 0, -1], mask [True, False, False, False, True, False, False, True, False]\n",
            "action not avaliable action<0,8> 3 , satae [0, 1, 1, -1, 0, -1, 1, 0, -1], mask [True, False, False, False, True, False, False, True, False]\n",
            "action not avaliable action<0,8> 3 , satae [0, 1, 1, -1, 0, -1, 1, 0, -1], mask [True, False, False, False, True, False, False, True, False]\n",
            "action not avaliable action<0,8> 3 , satae [0, 1, 1, -1, 0, -1, 1, 0, -1], mask [True, False, False, False, True, False, False, True, False]\n",
            "action not avaliable action<0,8> 3 , satae [0, 1, 1, -1, 0, -1, 1, 0, -1], mask [True, False, False, False, True, False, False, True, False]\n",
            "mcts won  5241  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.12298950552940369 q value 0.3213961259885268  reward : -1\n",
            "game #num:  14661\n",
            "action not avaliable action<0,8> 2 , satae [0, -1, -1, -1, 1, 1, 0, 1, 0], mask [True, False, False, False, False, False, True, False, True]\n",
            "action not avaliable action<0,8> 3 , satae [1, -1, -1, -1, 1, 1, -1, 1, 0], mask [False, False, False, False, False, False, False, False, True]\n",
            "action not avaliable action<0,8> 2 , satae [1, -1, -1, -1, 1, 1, -1, 1, 0], mask [False, False, False, False, False, False, False, False, True]\n",
            "action not avaliable action<0,8> 0 , satae [1, -1, -1, -1, 1, 1, -1, 1, 0], mask [False, False, False, False, False, False, False, False, True]\n",
            "action not avaliable action<0,8> 2 , satae [1, -1, -1, -1, 1, 1, -1, 1, 0], mask [False, False, False, False, False, False, False, False, True]\n",
            "action not avaliable action<0,8> 7 , satae [1, -1, -1, -1, 1, 1, -1, 1, 0], mask [False, False, False, False, False, False, False, False, True]\n",
            "action not avaliable action<0,8> 4 , satae [1, -1, -1, -1, 1, 1, -1, 1, 0], mask [False, False, False, False, False, False, False, False, True]\n",
            "action not avaliable action<0,8> 7 , satae [1, -1, -1, -1, 1, 1, -1, 1, 0], mask [False, False, False, False, False, False, False, False, True]\n",
            "action not avaliable action<0,8> 1 , satae [1, -1, -1, -1, 1, 1, -1, 1, 0], mask [False, False, False, False, False, False, False, False, True]\n",
            "action not avaliable action<0,8> 6 , satae [1, -1, -1, -1, 1, 1, -1, 1, 0], mask [False, False, False, False, False, False, False, False, True]\n",
            "action not avaliable action<0,8> 5 , satae [1, -1, -1, -1, 1, 1, -1, 1, 0], mask [False, False, False, False, False, False, False, False, True]\n",
            "action not avaliable action<0,8> 5 , satae [1, -1, -1, -1, 1, 1, -1, 1, 0], mask [False, False, False, False, False, False, False, False, True]\n",
            "action not avaliable action<0,8> 0 , satae [1, -1, -1, -1, 1, 1, -1, 1, 0], mask [False, False, False, False, False, False, False, False, True]\n",
            "action not avaliable action<0,8> 2 , satae [1, -1, -1, -1, 1, 1, -1, 1, 0], mask [False, False, False, False, False, False, False, False, True]\n",
            "action not avaliable action<0,8> 3 , satae [1, -1, -1, -1, 1, 1, -1, 1, 0], mask [False, False, False, False, False, False, False, False, True]\n",
            "action not avaliable action<0,8> 2 , satae [1, -1, -1, -1, 1, 1, -1, 1, 0], mask [False, False, False, False, False, False, False, False, True]\n",
            "action not avaliable action<0,8> 0 , satae [1, -1, -1, -1, 1, 1, -1, 1, 0], mask [False, False, False, False, False, False, False, False, True]\n",
            "action not avaliable action<0,8> 0 , satae [1, -1, -1, -1, 1, 1, -1, 1, 0], mask [False, False, False, False, False, False, False, False, True]\n",
            "action not avaliable action<0,8> 3 , satae [1, -1, -1, -1, 1, 1, -1, 1, 0], mask [False, False, False, False, False, False, False, False, True]\n",
            "action not avaliable action<0,8> 4 , satae [1, -1, -1, -1, 1, 1, -1, 1, 0], mask [False, False, False, False, False, False, False, False, True]\n",
            "action not avaliable action<0,8> 0 , satae [1, -1, -1, -1, 1, 1, -1, 1, 0], mask [False, False, False, False, False, False, False, False, True]\n",
            "action not avaliable action<0,8> 5 , satae [1, -1, -1, -1, 1, 1, -1, 1, 0], mask [False, False, False, False, False, False, False, False, True]\n",
            "action not avaliable action<0,8> 0 , satae [1, -1, -1, -1, 1, 1, -1, 1, 0], mask [False, False, False, False, False, False, False, False, True]\n",
            "action not avaliable action<0,8> 5 , satae [1, -1, -1, -1, 1, 1, -1, 1, 0], mask [False, False, False, False, False, False, False, False, True]\n",
            "action not avaliable action<0,8> 1 , satae [1, -1, -1, -1, 1, 1, -1, 1, 0], mask [False, False, False, False, False, False, False, False, True]\n",
            "action not avaliable action<0,8> 6 , satae [1, -1, -1, -1, 1, 1, -1, 1, 0], mask [False, False, False, False, False, False, False, False, True]\n",
            "draw  1437  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "################################################################################################\n",
            "game loss:  0.11039527770011656 q value 0.31624325725340074  reward : 0\n",
            "game #num:  14662\n",
            "action not avaliable action<0,8> 3 , satae [0, 0, -1, -1, 1, 0, 0, 0, 0], mask [True, True, False, False, False, True, True, True, True]\n",
            "action not avaliable action<0,8> 5 , satae [0, -1, -1, -1, 1, 1, -1, 0, 1], mask [True, False, False, False, False, False, False, True, False]\n",
            "action not avaliable action<0,8> 3 , satae [0, -1, -1, -1, 1, 1, -1, 0, 1], mask [True, False, False, False, False, False, False, True, False]\n",
            "action not avaliable action<0,8> 4 , satae [0, -1, -1, -1, 1, 1, -1, 0, 1], mask [True, False, False, False, False, False, False, True, False]\n",
            "action not avaliable action<0,8> 1 , satae [0, -1, -1, -1, 1, 1, -1, 0, 1], mask [True, False, False, False, False, False, False, True, False]\n",
            "agent won  7984  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.1134398372636901 q value 0.3189953863620758  reward : 1\n",
            "game #num:  14663\n",
            "action not avaliable action<0,8> 2 , satae [0, 0, 1, -1, 0, -1, 0, 0, 0], mask [True, True, False, False, True, False, True, True, True]\n",
            "action not avaliable action<0,8> 3 , satae [0, 1, 1, -1, 0, -1, -1, 0, 0], mask [True, False, False, False, True, False, False, True, True]\n",
            "action not avaliable action<0,8> 3 , satae [0, 1, 1, -1, 0, -1, -1, 1, -1], mask [True, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [0, 1, 1, -1, 0, -1, -1, 1, -1], mask [True, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 5 , satae [0, 1, 1, -1, 0, -1, -1, 1, -1], mask [True, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 1 , satae [0, 1, 1, -1, 0, -1, -1, 1, -1], mask [True, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 1 , satae [0, 1, 1, -1, 0, -1, -1, 1, -1], mask [True, False, False, False, True, False, False, False, False]\n",
            "agent won  7985  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.11711554229259491 q value 0.32281072302298114  reward : 1\n",
            "game #num:  14664\n",
            "action not avaliable action<0,8> 6 , satae [0, -1, -1, -1, 1, 1, 1, 0, -1], mask [True, False, False, False, False, False, False, True, False]\n",
            "action not avaliable action<0,8> 2 , satae [0, -1, -1, -1, 1, 1, 1, 0, -1], mask [True, False, False, False, False, False, False, True, False]\n",
            "action not avaliable action<0,8> 3 , satae [0, -1, -1, -1, 1, 1, 1, 0, -1], mask [True, False, False, False, False, False, False, True, False]\n",
            "action not avaliable action<0,8> 4 , satae [0, -1, -1, -1, 1, 1, 1, 0, -1], mask [True, False, False, False, False, False, False, True, False]\n",
            "draw  1438  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0]\n",
            "################################################################################################\n",
            "game loss:  0.12223961297422647 q value 0.3232524134218693  reward : 0\n",
            "game #num:  14665\n",
            "action not avaliable action<0,8> 1 , satae [0, 1, -1, 1, -1, 0, 0, 0, 0], mask [True, False, False, False, False, True, True, True, True]\n",
            "action not avaliable action<0,8> 4 , satae [0, 1, -1, 1, -1, 0, 0, 0, 0], mask [True, False, False, False, False, True, True, True, True]\n",
            "action not avaliable action<0,8> 2 , satae [0, 1, -1, 1, -1, 0, 0, 0, 0], mask [True, False, False, False, False, True, True, True, True]\n",
            "action not avaliable action<0,8> 4 , satae [0, 1, -1, 1, -1, 0, 0, 0, 0], mask [True, False, False, False, False, True, True, True, True]\n",
            "action not avaliable action<0,8> 2 , satae [0, 1, -1, 1, -1, 1, 0, -1, 0], mask [True, False, False, False, False, False, True, False, True]\n",
            "action not avaliable action<0,8> 2 , satae [0, 1, -1, 1, -1, 1, 0, -1, 0], mask [True, False, False, False, False, False, True, False, True]\n",
            "action not avaliable action<0,8> 6 , satae [0, 1, -1, 1, -1, 1, 1, -1, -1], mask [True, False, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 4 , satae [0, 1, -1, 1, -1, 1, 1, -1, -1], mask [True, False, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [0, 1, -1, 1, -1, 1, 1, -1, -1], mask [True, False, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 5 , satae [0, 1, -1, 1, -1, 1, 1, -1, -1], mask [True, False, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 5 , satae [0, 1, -1, 1, -1, 1, 1, -1, -1], mask [True, False, False, False, False, False, False, False, False]\n",
            "agent won  7986  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.11586363101378083 q value 0.3188959024846554  reward : 1\n",
            "game #num:  14666\n",
            "action not avaliable action<0,8> 1 , satae [0, 1, -1, 0, 0, -1, 0, 0, 1], mask [True, False, False, True, True, False, True, True, False]\n",
            "action not avaliable action<0,8> 8 , satae [0, 1, -1, 0, 0, -1, 0, 0, 1], mask [True, False, False, True, True, False, True, True, False]\n",
            "action not avaliable action<0,8> 6 , satae [0, 1, -1, 1, -1, -1, 1, -1, 1], mask [True, False, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 2 , satae [0, 1, -1, 1, -1, -1, 1, -1, 1], mask [True, False, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 1 , satae [0, 1, -1, 1, -1, -1, 1, -1, 1], mask [True, False, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [0, 1, -1, 1, -1, -1, 1, -1, 1], mask [True, False, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 1 , satae [0, 1, -1, 1, -1, -1, 1, -1, 1], mask [True, False, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 1 , satae [0, 1, -1, 1, -1, -1, 1, -1, 1], mask [True, False, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 2 , satae [0, 1, -1, 1, -1, -1, 1, -1, 1], mask [True, False, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 4 , satae [0, 1, -1, 1, -1, -1, 1, -1, 1], mask [True, False, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 4 , satae [0, 1, -1, 1, -1, -1, 1, -1, 1], mask [True, False, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 2 , satae [0, 1, -1, 1, -1, -1, 1, -1, 1], mask [True, False, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [0, 1, -1, 1, -1, -1, 1, -1, 1], mask [True, False, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [0, 1, -1, 1, -1, -1, 1, -1, 1], mask [True, False, False, False, False, False, False, False, False]\n",
            "draw  1439  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "################################################################################################\n",
            "game loss:  0.10373347664349958 q value 0.31756726848451716  reward : 0\n",
            "game #num:  14667\n",
            "action not avaliable action<0,8> 7 , satae [0, 0, 0, 0, 0, 0, 0, -1, 0], mask [True, True, True, True, True, True, True, False, True]\n",
            "mcts won  5242  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.11521693170070649 q value 0.322960102558136  reward : -1\n",
            "game #num:  14668\n",
            "action not avaliable action<0,8> 6 , satae [0, 0, 0, -1, 0, 0, 1, 0, 0], mask [True, True, True, False, True, True, False, True, True]\n",
            "mcts won  5243  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.11699049472808838 q value 0.3245080471038818  reward : -1\n",
            "game #num:  14669\n",
            "action not avaliable action<0,8> 7 , satae [1, -1, 0, 0, 0, 0, 0, -1, 1], mask [False, False, True, True, True, True, True, False, False]\n",
            "agent won  7987  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.11178893893957138 q value 0.3237919628620148  reward : 1\n",
            "game #num:  14670\n",
            "action not avaliable action<0,8> 8 , satae [0, 0, 0, 0, 0, 0, 0, 0, -1], mask [True, True, True, True, True, True, True, True, False]\n",
            "agent won  7988  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.11871359944343567 q value 0.3220416188240051  reward : 1\n",
            "game #num:  14671\n",
            "action not avaliable action<0,8> 3 , satae [0, 0, 0, -1, 1, 0, 0, -1, 1], mask [True, True, True, False, False, True, True, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [0, 0, 0, -1, 1, 0, 0, -1, 1], mask [True, True, True, False, False, True, True, False, False]\n",
            "action not avaliable action<0,8> 3 , satae [0, 0, 0, -1, 1, 0, 0, -1, 1], mask [True, True, True, False, False, True, True, False, False]\n",
            "action not avaliable action<0,8> 3 , satae [0, 0, 0, -1, 1, 0, 0, -1, 1], mask [True, True, True, False, False, True, True, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [0, 0, 1, -1, 1, -1, 0, -1, 1], mask [True, True, False, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 5 , satae [0, 0, 1, -1, 1, -1, 0, -1, 1], mask [True, True, False, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 4 , satae [0, 0, 1, -1, 1, -1, 0, -1, 1], mask [True, True, False, False, False, False, True, False, False]\n",
            "agent won  7989  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.11064721982587468 q value 0.32145322452891956  reward : 1\n",
            "game #num:  14672\n",
            "mcts won  5244  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.12364831566810608 q value 0.3209682106971741  reward : -1\n",
            "game #num:  14673\n",
            "agent won  7990  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.10765937467416127 q value 0.32016028960545856  reward : 1\n",
            "game #num:  14674\n",
            "action not avaliable action<0,8> 6 , satae [0, 0, 0, 0, -1, 0, 1, 0, 0], mask [True, True, True, True, False, True, False, True, True]\n",
            "action not avaliable action<0,8> 1 , satae [0, 1, 0, 0, -1, -1, 1, 0, 0], mask [True, False, True, True, False, False, False, True, True]\n",
            "action not avaliable action<0,8> 5 , satae [0, 1, 0, 0, -1, -1, 1, 0, 0], mask [True, False, True, True, False, False, False, True, True]\n",
            "action not avaliable action<0,8> 4 , satae [0, 1, 0, 0, -1, -1, 1, 0, 0], mask [True, False, True, True, False, False, False, True, True]\n",
            "action not avaliable action<0,8> 4 , satae [0, 1, 0, 0, -1, -1, 1, 0, 0], mask [True, False, True, True, False, False, False, True, True]\n",
            "action not avaliable action<0,8> 6 , satae [0, 1, 1, 0, -1, -1, 1, -1, 0], mask [True, False, False, True, False, False, False, False, True]\n",
            "action not avaliable action<0,8> 2 , satae [0, 1, 1, 0, -1, -1, 1, -1, 0], mask [True, False, False, True, False, False, False, False, True]\n",
            "agent won  7991  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.11553318426012993 q value 0.31977231552203494  reward : 1\n",
            "game #num:  14675\n",
            "action not avaliable action<0,8> 1 , satae [0, -1, 1, 0, 0, 1, -1, 0, 0], mask [True, False, False, True, True, False, False, True, True]\n",
            "action not avaliable action<0,8> 5 , satae [0, -1, 1, 0, 0, 1, -1, 0, 0], mask [True, False, False, True, True, False, False, True, True]\n",
            "action not avaliable action<0,8> 6 , satae [0, -1, 1, 0, 0, 1, -1, 0, 0], mask [True, False, False, True, True, False, False, True, True]\n",
            "action not avaliable action<0,8> 3 , satae [0, -1, 1, 1, 0, 1, -1, 0, -1], mask [True, False, False, False, True, False, False, True, False]\n",
            "action not avaliable action<0,8> 2 , satae [0, -1, 1, 1, 0, 1, -1, 0, -1], mask [True, False, False, False, True, False, False, True, False]\n",
            "action not avaliable action<0,8> 5 , satae [0, -1, 1, 1, 0, 1, -1, 0, -1], mask [True, False, False, False, True, False, False, True, False]\n",
            "agent won  7992  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.11395033225417137 q value 0.3185457706451416  reward : 1\n",
            "game #num:  14676\n",
            "action not avaliable action<0,8> 6 , satae [0, 0, 0, 1, 0, 0, 1, -1, -1], mask [True, True, True, False, True, True, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [0, 0, 0, 1, 0, 0, 1, -1, -1], mask [True, True, True, False, True, True, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [0, 0, 0, 1, 0, 0, 1, -1, -1], mask [True, True, True, False, True, True, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [0, 0, 0, 1, 0, 0, 1, -1, -1], mask [True, True, True, False, True, True, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [0, 0, 0, 1, 0, 0, 1, -1, -1], mask [True, True, True, False, True, True, False, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [0, 0, 0, 1, 0, 0, 1, -1, -1], mask [True, True, True, False, True, True, False, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [0, 0, 0, 1, -1, 1, 1, -1, -1], mask [True, True, True, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 4 , satae [0, 0, 0, 1, -1, 1, 1, -1, -1], mask [True, True, True, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 3 , satae [0, 0, 0, 1, -1, 1, 1, -1, -1], mask [True, True, True, False, False, False, False, False, False]\n",
            "mcts won  5245  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.11710402197562732 q value 0.3191510278445024  reward : -1\n",
            "game #num:  14677\n",
            "action not avaliable action<0,8> 8 , satae [0, 0, -1, 0, 0, 0, 0, -1, 1], mask [True, True, False, True, True, True, True, False, False]\n",
            "action not avaliable action<0,8> 2 , satae [0, 0, -1, 0, 0, 0, 0, -1, 1], mask [True, True, False, True, True, True, True, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [0, 0, -1, 0, 0, 0, 0, -1, 1], mask [True, True, False, True, True, True, True, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [0, 0, -1, 0, 0, 0, 0, -1, 1], mask [True, True, False, True, True, True, True, False, False]\n",
            "action not avaliable action<0,8> 2 , satae [0, 0, -1, 0, 0, 0, 0, -1, 1], mask [True, True, False, True, True, True, True, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [0, 1, -1, -1, 0, 0, 0, -1, 1], mask [True, False, False, False, True, True, True, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [0, 1, -1, -1, 0, 0, 0, -1, 1], mask [True, False, False, False, True, True, True, False, False]\n",
            "mcts won  5246  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.11290226267142729 q value 0.3206342241980813  reward : -1\n",
            "game #num:  14678\n",
            "action not avaliable action<0,8> 4 , satae [0, 0, 0, 1, 1, -1, 0, -1, 0], mask [True, True, True, False, False, False, True, False, True]\n",
            "action not avaliable action<0,8> 7 , satae [1, 0, 0, 1, 1, -1, -1, -1, 0], mask [False, True, True, False, False, False, False, False, True]\n",
            "action not avaliable action<0,8> 3 , satae [1, 0, 0, 1, 1, -1, -1, -1, 0], mask [False, True, True, False, False, False, False, False, True]\n",
            "action not avaliable action<0,8> 6 , satae [1, 0, 0, 1, 1, -1, -1, -1, 0], mask [False, True, True, False, False, False, False, False, True]\n",
            "action not avaliable action<0,8> 4 , satae [1, 0, 0, 1, 1, -1, -1, -1, 0], mask [False, True, True, False, False, False, False, False, True]\n",
            "action not avaliable action<0,8> 5 , satae [1, 0, 0, 1, 1, -1, -1, -1, 0], mask [False, True, True, False, False, False, False, False, True]\n",
            "action not avaliable action<0,8> 3 , satae [1, 0, 0, 1, 1, -1, -1, -1, 0], mask [False, True, True, False, False, False, False, False, True]\n",
            "agent won  7993  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.10831837559288199 q value 0.32528909228064795  reward : 1\n",
            "game #num:  14679\n",
            "action not avaliable action<0,8> 1 , satae [0, 1, -1, 0, 0, 0, 0, 0, 0], mask [True, False, False, True, True, True, True, True, True]\n",
            "action not avaliable action<0,8> 1 , satae [0, 1, -1, 0, 0, 0, 0, 0, 0], mask [True, False, False, True, True, True, True, True, True]\n",
            "action not avaliable action<0,8> 1 , satae [0, 1, -1, 0, 0, -1, 0, 1, 0], mask [True, False, False, True, True, False, True, False, True]\n",
            "action not avaliable action<0,8> 0 , satae [1, 1, -1, 0, 0, -1, -1, 1, 0], mask [False, False, False, True, True, False, False, False, True]\n",
            "action not avaliable action<0,8> 0 , satae [1, 1, -1, 0, 0, -1, -1, 1, 0], mask [False, False, False, True, True, False, False, False, True]\n",
            "mcts won  5247  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.10690954989857143 q value 0.3277870780891842  reward : -1\n",
            "game #num:  14680\n",
            "action not avaliable action<0,8> 1 , satae [-1, -1, 0, 0, -1, 1, -1, 1, 1], mask [False, False, True, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 0 , satae [-1, -1, 0, 0, -1, 1, -1, 1, 1], mask [False, False, True, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [-1, -1, 0, 0, -1, 1, -1, 1, 1], mask [False, False, True, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [-1, -1, 0, 0, -1, 1, -1, 1, 1], mask [False, False, True, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [-1, -1, 0, 0, -1, 1, -1, 1, 1], mask [False, False, True, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [-1, -1, 0, 0, -1, 1, -1, 1, 1], mask [False, False, True, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [-1, -1, 0, 0, -1, 1, -1, 1, 1], mask [False, False, True, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [-1, -1, 0, 0, -1, 1, -1, 1, 1], mask [False, False, True, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 1 , satae [-1, -1, 0, 0, -1, 1, -1, 1, 1], mask [False, False, True, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [-1, -1, 0, 0, -1, 1, -1, 1, 1], mask [False, False, True, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 1 , satae [-1, -1, 0, 0, -1, 1, -1, 1, 1], mask [False, False, True, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 0 , satae [-1, -1, 0, 0, -1, 1, -1, 1, 1], mask [False, False, True, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 0 , satae [-1, -1, 0, 0, -1, 1, -1, 1, 1], mask [False, False, True, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 4 , satae [-1, -1, 0, 0, -1, 1, -1, 1, 1], mask [False, False, True, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 4 , satae [-1, -1, 0, 0, -1, 1, -1, 1, 1], mask [False, False, True, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 0 , satae [-1, -1, 0, 0, -1, 1, -1, 1, 1], mask [False, False, True, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [-1, -1, 0, 0, -1, 1, -1, 1, 1], mask [False, False, True, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [-1, -1, 0, 0, -1, 1, -1, 1, 1], mask [False, False, True, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [-1, -1, 0, 0, -1, 1, -1, 1, 1], mask [False, False, True, True, False, False, False, False, False]\n",
            "agent won  7994  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.11741252405487973 q value 0.32130907152010046  reward : 1\n",
            "game #num:  14681\n",
            "action not avaliable action<0,8> 6 , satae [-1, 0, 1, -1, 0, -1, 1, 1, 0], mask [False, True, False, False, True, False, False, False, True]\n",
            "action not avaliable action<0,8> 6 , satae [-1, 0, 1, -1, 0, -1, 1, 1, 0], mask [False, True, False, False, True, False, False, False, True]\n",
            "action not avaliable action<0,8> 7 , satae [-1, 0, 1, -1, 0, -1, 1, 1, 0], mask [False, True, False, False, True, False, False, False, True]\n",
            "action not avaliable action<0,8> 7 , satae [-1, 0, 1, -1, 0, -1, 1, 1, 0], mask [False, True, False, False, True, False, False, False, True]\n",
            "agent won  7995  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.11027444247156382 q value 0.3182450495660305  reward : 1\n",
            "game #num:  14682\n",
            "action not avaliable action<0,8> 4 , satae [0, 0, 0, 0, -1, 0, 0, 0, 0], mask [True, True, True, True, False, True, True, True, True]\n",
            "action not avaliable action<0,8> 0 , satae [1, -1, 0, 0, -1, 0, 0, 0, 0], mask [False, False, True, True, False, True, True, True, True]\n",
            "agent won  7996  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.10772412829101086 q value 0.3200928643345833  reward : 1\n",
            "game #num:  14683\n",
            "agent won  7997  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.11621545255184174 q value 0.3210141658782959  reward : 1\n",
            "game #num:  14684\n",
            "action not avaliable action<0,8> 6 , satae [-1, 0, 0, -1, 0, 1, 1, 0, -1], mask [False, True, True, False, True, False, False, True, False]\n",
            "action not avaliable action<0,8> 6 , satae [-1, 0, 0, -1, 0, 1, 1, 0, -1], mask [False, True, True, False, True, False, False, True, False]\n",
            "action not avaliable action<0,8> 7 , satae [-1, 0, -1, -1, 0, 1, 1, 1, -1], mask [False, True, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 0 , satae [-1, 0, -1, -1, 0, 1, 1, 1, -1], mask [False, True, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 3 , satae [-1, 0, -1, -1, 0, 1, 1, 1, -1], mask [False, True, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [-1, 0, -1, -1, 0, 1, 1, 1, -1], mask [False, True, False, False, True, False, False, False, False]\n",
            "agent won  7998  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.10875879749655723 q value 0.3190281748771667  reward : 1\n",
            "game #num:  14685\n",
            "action not avaliable action<0,8> 5 , satae [0, 1, -1, -1, 0, 1, -1, 0, 0], mask [True, False, False, False, True, False, False, True, True]\n",
            "action not avaliable action<0,8> 3 , satae [0, 1, -1, -1, 0, 1, -1, 0, 0], mask [True, False, False, False, True, False, False, True, True]\n",
            "mcts won  5248  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.12144523561000824 q value 0.31664331555366515  reward : -1\n",
            "game #num:  14686\n",
            "action not avaliable action<0,8> 1 , satae [-1, 1, 0, 1, -1, 0, -1, 0, 0], mask [False, False, True, False, False, True, False, True, True]\n",
            "action not avaliable action<0,8> 3 , satae [-1, 1, 0, 1, -1, 0, -1, 0, 0], mask [False, False, True, False, False, True, False, True, True]\n",
            "action not avaliable action<0,8> 1 , satae [-1, 1, 0, 1, -1, 0, -1, 0, 0], mask [False, False, True, False, False, True, False, True, True]\n",
            "mcts won  5249  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.11001044511795044 q value 0.3173008660475413  reward : -1\n",
            "game #num:  14687\n",
            "agent won  7999  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.11428391685088475 q value 0.31826038161913556  reward : 1\n",
            "game #num:  14688\n",
            "action not avaliable action<0,8> 3 , satae [0, 0, 0, -1, 0, 0, 0, 0, 0], mask [True, True, True, False, True, True, True, True, True]\n",
            "action not avaliable action<0,8> 3 , satae [0, 0, 0, -1, 0, 0, 0, 0, 0], mask [True, True, True, False, True, True, True, True, True]\n",
            "action not avaliable action<0,8> 3 , satae [0, 0, 0, -1, 0, -1, 0, 0, 1], mask [True, True, True, False, True, False, True, True, False]\n",
            "mcts won  5250  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.10719820732871692 q value 0.31773659586906433  reward : -1\n",
            "game #num:  14689\n",
            "action not avaliable action<0,8> 3 , satae [0, 0, 0, -1, 0, 1, 0, -1, 1], mask [True, True, True, False, True, False, True, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [0, 0, 0, -1, 0, 1, 0, -1, 1], mask [True, True, True, False, True, False, True, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [0, 0, 0, -1, 0, 1, 0, -1, 1], mask [True, True, True, False, True, False, True, False, False]\n",
            "action not avaliable action<0,8> 0 , satae [1, -1, 0, -1, 0, 1, 0, -1, 1], mask [False, False, True, False, True, False, True, False, False]\n",
            "action not avaliable action<0,8> 5 , satae [1, -1, 0, -1, 0, 1, 0, -1, 1], mask [False, False, True, False, True, False, True, False, False]\n",
            "action not avaliable action<0,8> 1 , satae [1, -1, 0, -1, 0, 1, 0, -1, 1], mask [False, False, True, False, True, False, True, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [1, -1, 0, -1, 0, 1, 0, -1, 1], mask [False, False, True, False, True, False, True, False, False]\n",
            "action not avaliable action<0,8> 0 , satae [1, -1, 0, -1, 0, 1, 0, -1, 1], mask [False, False, True, False, True, False, True, False, False]\n",
            "mcts won  5251  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.1128683512409528 q value 0.318915198246638  reward : -1\n",
            "game #num:  14690\n",
            "action not avaliable action<0,8> 0 , satae [-1, 0, 0, 1, 0, 0, 0, -1, 0], mask [False, True, True, False, True, True, True, False, True]\n",
            "action not avaliable action<0,8> 5 , satae [-1, 0, 0, 1, 0, 1, -1, -1, 0], mask [False, True, True, False, True, False, False, False, True]\n",
            "action not avaliable action<0,8> 1 , satae [-1, -1, 1, 1, 0, 1, -1, -1, 0], mask [False, False, False, False, True, False, False, False, True]\n",
            "action not avaliable action<0,8> 6 , satae [-1, -1, 1, 1, 0, 1, -1, -1, 0], mask [False, False, False, False, True, False, False, False, True]\n",
            "action not avaliable action<0,8> 7 , satae [-1, -1, 1, 1, 0, 1, -1, -1, 0], mask [False, False, False, False, True, False, False, False, True]\n",
            "agent won  8000  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.12025852335823907 q value 0.31968550549613106  reward : 1\n",
            "game #num:  14691\n",
            "action not avaliable action<0,8> 0 , satae [-1, 0, 0, 0, 0, 0, 0, 0, 0], mask [False, True, True, True, True, True, True, True, True]\n",
            "action not avaliable action<0,8> 6 , satae [-1, 0, 0, 0, 0, 0, 1, 0, -1], mask [False, True, True, True, True, True, False, True, False]\n",
            "action not avaliable action<0,8> 6 , satae [-1, 0, 0, 0, 0, 1, 1, -1, -1], mask [False, True, True, True, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [-1, 0, 0, 0, 0, 1, 1, -1, -1], mask [False, True, True, True, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [-1, 0, 0, 0, 0, 1, 1, -1, -1], mask [False, True, True, True, True, False, False, False, False]\n",
            "draw  1440  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "################################################################################################\n",
            "game loss:  0.10949692461225721 q value 0.32050827476713395  reward : 0\n",
            "game #num:  14692\n",
            "draw  1441  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0]\n",
            "################################################################################################\n",
            "game loss:  0.10909595638513565 q value 0.32150588631629945  reward : 0\n",
            "game #num:  14693\n",
            "action not avaliable action<0,8> 0 , satae [1, -1, -1, 0, 1, -1, 0, 0, 0], mask [False, False, False, True, False, False, True, True, True]\n",
            "mcts won  5252  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.11414383910596371 q value 0.3223656639456749  reward : -1\n",
            "game #num:  14694\n",
            "action not avaliable action<0,8> 4 , satae [0, 0, 0, 0, -1, 0, 0, 0, 0], mask [True, True, True, True, False, True, True, True, True]\n",
            "action not avaliable action<0,8> 8 , satae [0, 0, 0, 1, -1, -1, 0, 1, -1], mask [True, True, True, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 3 , satae [0, 0, 1, 1, -1, -1, -1, 1, -1], mask [True, True, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 5 , satae [0, 0, 1, 1, -1, -1, -1, 1, -1], mask [True, True, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 4 , satae [0, 0, 1, 1, -1, -1, -1, 1, -1], mask [True, True, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [0, 0, 1, 1, -1, -1, -1, 1, -1], mask [True, True, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 5 , satae [0, 0, 1, 1, -1, -1, -1, 1, -1], mask [True, True, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 4 , satae [0, 0, 1, 1, -1, -1, -1, 1, -1], mask [True, True, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 2 , satae [0, 0, 1, 1, -1, -1, -1, 1, -1], mask [True, True, False, False, False, False, False, False, False]\n",
            "draw  1442  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "################################################################################################\n",
            "game loss:  0.11123146919103769 q value 0.3241367500561934  reward : 0\n",
            "game #num:  14695\n",
            "action not avaliable action<0,8> 1 , satae [0, -1, 0, 0, 0, 0, 0, 0, 0], mask [True, False, True, True, True, True, True, True, True]\n",
            "action not avaliable action<0,8> 5 , satae [0, -1, -1, 0, -1, 1, 0, 0, 1], mask [True, False, False, True, False, False, True, True, False]\n",
            "action not avaliable action<0,8> 4 , satae [0, -1, -1, 0, -1, 1, 0, 0, 1], mask [True, False, False, True, False, False, True, True, False]\n",
            "action not avaliable action<0,8> 8 , satae [0, -1, -1, 0, -1, 1, 0, 0, 1], mask [True, False, False, True, False, False, True, True, False]\n",
            "agent won  8001  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.10857311529772622 q value 0.32325246930122375  reward : 1\n",
            "game #num:  14696\n",
            "action not avaliable action<0,8> 7 , satae [1, 0, 0, -1, 0, 1, 0, -1, -1], mask [False, True, True, False, True, False, True, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [1, 0, 0, -1, 0, 1, 0, -1, -1], mask [False, True, True, False, True, False, True, False, False]\n",
            "action not avaliable action<0,8> 5 , satae [1, 0, 0, -1, 0, 1, 0, -1, -1], mask [False, True, True, False, True, False, True, False, False]\n",
            "action not avaliable action<0,8> 0 , satae [1, 0, 0, -1, 0, 1, 0, -1, -1], mask [False, True, True, False, True, False, True, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [1, 0, 0, -1, 0, 1, 0, -1, -1], mask [False, True, True, False, True, False, True, False, False]\n",
            "action not avaliable action<0,8> 0 , satae [1, 0, 0, -1, 0, 1, 0, -1, -1], mask [False, True, True, False, True, False, True, False, False]\n",
            "action not avaliable action<0,8> 3 , satae [1, 0, 0, -1, 0, 1, 0, -1, -1], mask [False, True, True, False, True, False, True, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [1, 0, 0, -1, 0, 1, 0, -1, -1], mask [False, True, True, False, True, False, True, False, False]\n",
            "mcts won  5253  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.11558773571794684 q value 0.3183696838942441  reward : -1\n",
            "game #num:  14697\n",
            "action not avaliable action<0,8> 1 , satae [0, -1, -1, 0, 1, 0, 0, 0, 0], mask [True, False, False, True, False, True, True, True, True]\n",
            "action not avaliable action<0,8> 4 , satae [0, -1, -1, 1, 1, 0, 0, -1, 0], mask [True, False, False, False, False, True, True, False, True]\n",
            "action not avaliable action<0,8> 4 , satae [0, -1, -1, 1, 1, 0, 0, -1, 0], mask [True, False, False, False, False, True, True, False, True]\n",
            "action not avaliable action<0,8> 3 , satae [0, -1, -1, 1, 1, -1, 1, -1, 0], mask [True, False, False, False, False, False, False, False, True]\n",
            "action not avaliable action<0,8> 3 , satae [0, -1, -1, 1, 1, -1, 1, -1, 0], mask [True, False, False, False, False, False, False, False, True]\n",
            "agent won  8002  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.10915201074547237 q value 0.31299207939041984  reward : 1\n",
            "game #num:  14698\n",
            "action not avaliable action<0,8> 5 , satae [0, 0, 0, 0, 0, -1, 0, 0, 0], mask [True, True, True, True, True, False, True, True, True]\n",
            "action not avaliable action<0,8> 5 , satae [0, 0, 0, 0, 1, -1, -1, -1, 1], mask [True, True, True, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 5 , satae [0, 0, 0, 0, 1, -1, -1, -1, 1], mask [True, True, True, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [0, -1, 1, 0, 1, -1, -1, -1, 1], mask [True, False, False, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [0, -1, 1, 0, 1, -1, -1, -1, 1], mask [True, False, False, True, False, False, False, False, False]\n",
            "draw  1443  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "################################################################################################\n",
            "game loss:  0.11605205883582433 q value 0.31113122900327045  reward : 0\n",
            "game #num:  14699\n",
            "action not avaliable action<0,8> 8 , satae [0, -1, 0, -1, 0, 1, 1, 0, -1], mask [True, False, True, False, True, False, False, True, False]\n",
            "action not avaliable action<0,8> 5 , satae [0, -1, 0, -1, 0, 1, 1, 0, -1], mask [True, False, True, False, True, False, False, True, False]\n",
            "action not avaliable action<0,8> 8 , satae [0, -1, 0, -1, 0, 1, 1, 0, -1], mask [True, False, True, False, True, False, False, True, False]\n",
            "action not avaliable action<0,8> 4 , satae [-1, -1, 0, -1, 1, 1, 1, 0, -1], mask [False, False, True, False, False, False, False, True, False]\n",
            "agent won  8003  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.11647308804094791 q value 0.3095315061509609  reward : 1\n",
            "game #num:  14700\n",
            "action not avaliable action<0,8> 6 , satae [1, -1, 0, -1, -1, 1, 1, 0, 0], mask [False, False, True, False, False, False, False, True, True]\n",
            "action not avaliable action<0,8> 0 , satae [1, -1, 0, -1, -1, 1, 1, 0, 0], mask [False, False, True, False, False, False, False, True, True]\n",
            "action not avaliable action<0,8> 6 , satae [1, -1, 1, -1, -1, 1, 1, 0, -1], mask [False, False, False, False, False, False, False, True, False]\n",
            "action not avaliable action<0,8> 1 , satae [1, -1, 1, -1, -1, 1, 1, 0, -1], mask [False, False, False, False, False, False, False, True, False]\n",
            "action not avaliable action<0,8> 6 , satae [1, -1, 1, -1, -1, 1, 1, 0, -1], mask [False, False, False, False, False, False, False, True, False]\n",
            "action not avaliable action<0,8> 3 , satae [1, -1, 1, -1, -1, 1, 1, 0, -1], mask [False, False, False, False, False, False, False, True, False]\n",
            "action not avaliable action<0,8> 8 , satae [1, -1, 1, -1, -1, 1, 1, 0, -1], mask [False, False, False, False, False, False, False, True, False]\n",
            "action not avaliable action<0,8> 8 , satae [1, -1, 1, -1, -1, 1, 1, 0, -1], mask [False, False, False, False, False, False, False, True, False]\n",
            "action not avaliable action<0,8> 0 , satae [1, -1, 1, -1, -1, 1, 1, 0, -1], mask [False, False, False, False, False, False, False, True, False]\n",
            "draw  1444  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "################################################################################################\n",
            "game loss:  0.11902838040675436 q value 0.3104427733591625  reward : 0\n",
            "game #num:  14701\n",
            "action not avaliable action<0,8> 6 , satae [-1, -1, 0, 0, 1, 1, -1, 0, 1], mask [False, False, True, True, False, False, False, True, False]\n",
            "mcts won  5254  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.10213116556406021 q value 0.31391183137893675  reward : -1\n",
            "game #num:  14702\n",
            "action not avaliable action<0,8> 4 , satae [1, 0, 0, 0, -1, 1, -1, 1, -1], mask [False, True, True, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [1, 0, 0, 0, -1, 1, -1, 1, -1], mask [False, True, True, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 4 , satae [1, 0, 0, 0, -1, 1, -1, 1, -1], mask [False, True, True, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [1, 0, 0, 0, -1, 1, -1, 1, -1], mask [False, True, True, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 2 , satae [1, 0, 1, -1, -1, 1, -1, 1, -1], mask [False, True, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 5 , satae [1, 0, 1, -1, -1, 1, -1, 1, -1], mask [False, True, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 2 , satae [1, 0, 1, -1, -1, 1, -1, 1, -1], mask [False, True, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [1, 0, 1, -1, -1, 1, -1, 1, -1], mask [False, True, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 0 , satae [1, 0, 1, -1, -1, 1, -1, 1, -1], mask [False, True, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 4 , satae [1, 0, 1, -1, -1, 1, -1, 1, -1], mask [False, True, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [1, 0, 1, -1, -1, 1, -1, 1, -1], mask [False, True, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 2 , satae [1, 0, 1, -1, -1, 1, -1, 1, -1], mask [False, True, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [1, 0, 1, -1, -1, 1, -1, 1, -1], mask [False, True, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [1, 0, 1, -1, -1, 1, -1, 1, -1], mask [False, True, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [1, 0, 1, -1, -1, 1, -1, 1, -1], mask [False, True, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 4 , satae [1, 0, 1, -1, -1, 1, -1, 1, -1], mask [False, True, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 2 , satae [1, 0, 1, -1, -1, 1, -1, 1, -1], mask [False, True, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 3 , satae [1, 0, 1, -1, -1, 1, -1, 1, -1], mask [False, True, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 0 , satae [1, 0, 1, -1, -1, 1, -1, 1, -1], mask [False, True, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 0 , satae [1, 0, 1, -1, -1, 1, -1, 1, -1], mask [False, True, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 4 , satae [1, 0, 1, -1, -1, 1, -1, 1, -1], mask [False, True, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [1, 0, 1, -1, -1, 1, -1, 1, -1], mask [False, True, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 2 , satae [1, 0, 1, -1, -1, 1, -1, 1, -1], mask [False, True, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [1, 0, 1, -1, -1, 1, -1, 1, -1], mask [False, True, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 2 , satae [1, 0, 1, -1, -1, 1, -1, 1, -1], mask [False, True, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 3 , satae [1, 0, 1, -1, -1, 1, -1, 1, -1], mask [False, True, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 2 , satae [1, 0, 1, -1, -1, 1, -1, 1, -1], mask [False, True, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 0 , satae [1, 0, 1, -1, -1, 1, -1, 1, -1], mask [False, True, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 2 , satae [1, 0, 1, -1, -1, 1, -1, 1, -1], mask [False, True, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [1, 0, 1, -1, -1, 1, -1, 1, -1], mask [False, True, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [1, 0, 1, -1, -1, 1, -1, 1, -1], mask [False, True, False, False, False, False, False, False, False]\n",
            "draw  1445  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "################################################################################################\n",
            "game loss:  0.1105947916706403 q value 0.32269694407780963  reward : 0\n",
            "game #num:  14703\n",
            "mcts won  5255  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.09879209846258163 q value 0.3256916304429372  reward : -1\n",
            "game #num:  14704\n",
            "action not avaliable action<0,8> 4 , satae [-1, 0, -1, 0, 1, 0, 0, 1, -1], mask [False, True, False, True, False, True, True, False, False]\n",
            "agent won  8004  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.10680830106139183 q value 0.3253551200032234  reward : 1\n",
            "game #num:  14705\n",
            "action not avaliable action<0,8> 5 , satae [0, 0, 1, 0, -1, 1, -1, -1, 0], mask [True, True, False, True, False, False, False, False, True]\n",
            "action not avaliable action<0,8> 4 , satae [0, 0, 1, 0, -1, 1, -1, -1, 0], mask [True, True, False, True, False, False, False, False, True]\n",
            "action not avaliable action<0,8> 7 , satae [-1, 0, 1, 1, -1, 1, -1, -1, 0], mask [False, True, False, False, False, False, False, False, True]\n",
            "agent won  8005  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.11776170986039299 q value 0.32422093408448355  reward : 1\n",
            "game #num:  14706\n",
            "action not avaliable action<0,8> 5 , satae [0, -1, 1, 0, 1, 1, -1, -1, 0], mask [True, False, False, True, False, False, False, False, True]\n",
            "action not avaliable action<0,8> 7 , satae [0, -1, 1, 0, 1, 1, -1, -1, 0], mask [True, False, False, True, False, False, False, False, True]\n",
            "action not avaliable action<0,8> 7 , satae [0, -1, 1, 0, 1, 1, -1, -1, 0], mask [True, False, False, True, False, False, False, False, True]\n",
            "action not avaliable action<0,8> 7 , satae [0, -1, 1, 0, 1, 1, -1, -1, 0], mask [True, False, False, True, False, False, False, False, True]\n",
            "action not avaliable action<0,8> 2 , satae [0, -1, 1, 0, 1, 1, -1, -1, 0], mask [True, False, False, True, False, False, False, False, True]\n",
            "agent won  8006  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.10987713601854113 q value 0.3214099638991886  reward : 1\n",
            "game #num:  14707\n",
            "mcts won  5256  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.1137315034866333 q value 0.3205341895421346  reward : -1\n",
            "game #num:  14708\n",
            "action not avaliable action<0,8> 4 , satae [0, -1, -1, 0, -1, 0, 1, 0, 1], mask [True, False, False, True, False, True, False, True, False]\n",
            "mcts won  5257  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.10135041736066341 q value 0.32095398008823395  reward : -1\n",
            "game #num:  14709\n",
            "mcts won  5258  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.11089438945055008 q value 0.32268481453259784  reward : -1\n",
            "game #num:  14710\n",
            "agent won  8007  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.11871246993541718 q value 0.3240012526512146  reward : 1\n",
            "game #num:  14711\n",
            "action not avaliable action<0,8> 4 , satae [0, 0, 0, 0, -1, 0, 0, 1, 0], mask [True, True, True, True, False, True, True, False, True]\n",
            "agent won  8008  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.10461650043725967 q value 0.325508850812912  reward : 1\n",
            "game #num:  14712\n",
            "action not avaliable action<0,8> 0 , satae [1, -1, 0, 1, -1, 0, 0, 0, 0], mask [False, False, True, False, False, True, True, True, True]\n",
            "action not avaliable action<0,8> 0 , satae [1, -1, 0, 1, -1, 0, 0, 0, 0], mask [False, False, True, False, False, True, True, True, True]\n",
            "action not avaliable action<0,8> 1 , satae [1, -1, 0, 1, -1, 0, 0, 0, 0], mask [False, False, True, False, False, True, True, True, True]\n",
            "action not avaliable action<0,8> 1 , satae [1, -1, 0, 1, -1, 0, 0, 0, 0], mask [False, False, True, False, False, True, True, True, True]\n",
            "action not avaliable action<0,8> 1 , satae [1, -1, 0, 1, -1, 0, 0, 0, 0], mask [False, False, True, False, False, True, True, True, True]\n",
            "action not avaliable action<0,8> 0 , satae [1, -1, -1, 1, -1, 0, 0, 1, 0], mask [False, False, False, False, False, True, True, False, True]\n",
            "action not avaliable action<0,8> 0 , satae [1, -1, -1, 1, -1, 0, 0, 1, 0], mask [False, False, False, False, False, True, True, False, True]\n",
            "mcts won  5259  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.11125526238571513 q value 0.32685655084523285  reward : -1\n",
            "game #num:  14713\n",
            "agent won  8009  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.1263750195503235 q value 0.3261432945728302  reward : 1\n",
            "game #num:  14714\n",
            "agent won  8010  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.13034090399742126 q value 0.32433706521987915  reward : 1\n",
            "game #num:  14715\n",
            "action not avaliable action<0,8> 8 , satae [0, 1, 0, -1, 0, 0, 0, 1, -1], mask [True, False, True, False, True, True, True, False, False]\n",
            "agent won  8011  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.11760171502828598 q value 0.32085558275381726  reward : 1\n",
            "game #num:  14716\n",
            "action not avaliable action<0,8> 6 , satae [0, 0, 0, -1, -1, 0, 1, 0, 0], mask [True, True, True, False, False, True, False, True, True]\n",
            "action not avaliable action<0,8> 6 , satae [0, 0, 0, -1, -1, 0, 1, 0, 0], mask [True, True, True, False, False, True, False, True, True]\n",
            "action not avaliable action<0,8> 6 , satae [0, 0, 0, -1, -1, 0, 1, 0, 0], mask [True, True, True, False, False, True, False, True, True]\n",
            "action not avaliable action<0,8> 0 , satae [1, -1, 0, -1, -1, 0, 1, 0, 0], mask [False, False, True, False, False, True, False, True, True]\n",
            "action not avaliable action<0,8> 8 , satae [1, -1, 0, -1, -1, 1, 1, 0, -1], mask [False, False, True, False, False, False, False, True, False]\n",
            "action not avaliable action<0,8> 8 , satae [1, -1, 0, -1, -1, 1, 1, 0, -1], mask [False, False, True, False, False, False, False, True, False]\n",
            "action not avaliable action<0,8> 5 , satae [1, -1, 0, -1, -1, 1, 1, 0, -1], mask [False, False, True, False, False, False, False, True, False]\n",
            "mcts won  5260  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.11474709212779999 q value 0.31621478362516925  reward : -1\n",
            "game #num:  14717\n",
            "action not avaliable action<0,8> 4 , satae [-1, 1, -1, 0, 1, 0, -1, 0, 0], mask [False, False, False, True, False, True, False, True, True]\n",
            "action not avaliable action<0,8> 4 , satae [-1, 1, -1, 0, 1, 0, -1, 0, 0], mask [False, False, False, True, False, True, False, True, True]\n",
            "mcts won  5261  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.12594273388385774 q value 0.3126597762107849  reward : -1\n",
            "game #num:  14718\n",
            "action not avaliable action<0,8> 8 , satae [-1, 0, 1, -1, 1, 0, 0, 0, -1], mask [False, True, False, False, False, True, True, True, False]\n",
            "action not avaliable action<0,8> 8 , satae [-1, 0, 1, -1, 1, 0, 0, 0, -1], mask [False, True, False, False, False, True, True, True, False]\n",
            "action not avaliable action<0,8> 2 , satae [-1, 0, 1, -1, 1, 0, 0, 0, -1], mask [False, True, False, False, False, True, True, True, False]\n",
            "agent won  8012  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.1081397437623569 q value 0.3116794696875981  reward : 1\n",
            "game #num:  14719\n",
            "action not avaliable action<0,8> 2 , satae [0, 0, -1, 0, 0, 0, 0, 1, 0], mask [True, True, False, True, True, True, True, False, True]\n",
            "action not avaliable action<0,8> 8 , satae [0, -1, -1, 0, 1, 0, 1, 1, -1], mask [True, False, False, True, False, True, False, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [0, -1, -1, 0, 1, 0, 1, 1, -1], mask [True, False, False, True, False, True, False, False, False]\n",
            "agent won  8013  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.11302383244037628 q value 0.30986455934388296  reward : 1\n",
            "game #num:  14720\n",
            "action not avaliable action<0,8> 6 , satae [0, -1, 0, 0, 0, 0, 1, 0, 0], mask [True, False, True, True, True, True, False, True, True]\n",
            "agent won  8014  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.11715687960386276 q value 0.3099684178829193  reward : 1\n",
            "game #num:  14721\n",
            "action not avaliable action<0,8> 5 , satae [0, 0, 0, 0, 0, -1, 0, 0, 0], mask [True, True, True, True, True, False, True, True, True]\n",
            "action not avaliable action<0,8> 5 , satae [0, 0, 0, 0, 0, -1, 0, 0, 0], mask [True, True, True, True, True, False, True, True, True]\n",
            "action not avaliable action<0,8> 2 , satae [-1, 1, -1, 1, -1, -1, 0, 1, 0], mask [False, False, False, False, False, False, True, False, True]\n",
            "action not avaliable action<0,8> 7 , satae [-1, 1, -1, 1, -1, -1, 0, 1, 0], mask [False, False, False, False, False, False, True, False, True]\n",
            "action not avaliable action<0,8> 4 , satae [-1, 1, -1, 1, -1, -1, 0, 1, 0], mask [False, False, False, False, False, False, True, False, True]\n",
            "action not avaliable action<0,8> 7 , satae [-1, 1, -1, 1, -1, -1, 0, 1, 0], mask [False, False, False, False, False, False, True, False, True]\n",
            "agent won  8015  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.11064429879188538 q value 0.31200900971889495  reward : 1\n",
            "game #num:  14722\n",
            "action not avaliable action<0,8> 7 , satae [-1, 0, 0, 0, 0, 0, -1, 1, 1], mask [False, True, True, True, True, True, False, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [-1, 0, 0, 0, 0, 0, -1, 1, 1], mask [False, True, True, True, True, True, False, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [-1, 0, 0, 0, 0, 0, -1, 1, 1], mask [False, True, True, True, True, True, False, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [-1, 0, 0, 0, 0, 0, -1, 1, 1], mask [False, True, True, True, True, True, False, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [-1, 0, 0, 0, 0, 0, -1, 1, 1], mask [False, True, True, True, True, True, False, False, False]\n",
            "action not avaliable action<0,8> 5 , satae [-1, 0, 0, 0, -1, 1, -1, 1, 1], mask [False, True, True, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 5 , satae [-1, 0, 0, 0, -1, 1, -1, 1, 1], mask [False, True, True, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 5 , satae [-1, 0, 0, 0, -1, 1, -1, 1, 1], mask [False, True, True, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 5 , satae [-1, 0, 0, 0, -1, 1, -1, 1, 1], mask [False, True, True, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 5 , satae [-1, 0, 0, 0, -1, 1, -1, 1, 1], mask [False, True, True, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [-1, 0, 0, 0, -1, 1, -1, 1, 1], mask [False, True, True, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 0 , satae [-1, 0, 0, 0, -1, 1, -1, 1, 1], mask [False, True, True, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [-1, 0, 0, 0, -1, 1, -1, 1, 1], mask [False, True, True, True, False, False, False, False, False]\n",
            "mcts won  5262  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.11331285229500603 q value 0.3135419821037966  reward : -1\n",
            "game #num:  14723\n",
            "action not avaliable action<0,8> 5 , satae [1, 0, 0, 0, 0, -1, 1, 0, -1], mask [False, True, True, True, True, False, False, True, False]\n",
            "mcts won  5263  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.11858236230909824 q value 0.31371885538101196  reward : -1\n",
            "game #num:  14724\n",
            "action not avaliable action<0,8> 3 , satae [0, 0, -1, 1, 0, -1, 0, 1, 0], mask [True, True, False, False, True, False, True, False, True]\n",
            "action not avaliable action<0,8> 2 , satae [0, 0, -1, 1, 0, -1, 0, 1, 0], mask [True, True, False, False, True, False, True, False, True]\n",
            "agent won  8016  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.12054163465897243 q value 0.3142415334781011  reward : 1\n",
            "game #num:  14725\n",
            "action not avaliable action<0,8> 6 , satae [0, 0, 0, 0, 0, 0, -1, 1, 0], mask [True, True, True, True, True, True, False, False, True]\n",
            "mcts won  5264  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.12556226998567582 q value 0.31381016969680786  reward : -1\n",
            "game #num:  14726\n",
            "action not avaliable action<0,8> 7 , satae [0, 0, 0, 0, 0, 0, 0, -1, 0], mask [True, True, True, True, True, True, True, False, True]\n",
            "action not avaliable action<0,8> 5 , satae [-1, -1, 0, 0, 1, -1, 1, -1, 1], mask [False, False, True, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 0 , satae [-1, -1, 0, 0, 1, -1, 1, -1, 1], mask [False, False, True, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 4 , satae [-1, -1, 0, 0, 1, -1, 1, -1, 1], mask [False, False, True, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 4 , satae [-1, -1, 0, 0, 1, -1, 1, -1, 1], mask [False, False, True, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [-1, -1, 0, 0, 1, -1, 1, -1, 1], mask [False, False, True, True, False, False, False, False, False]\n",
            "agent won  8017  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.11955365017056466 q value 0.31221369802951815  reward : 1\n",
            "game #num:  14727\n",
            "action not avaliable action<0,8> 6 , satae [0, 0, 0, 0, 1, 1, -1, 0, -1], mask [True, True, True, True, False, False, False, True, False]\n",
            "action not avaliable action<0,8> 5 , satae [0, 0, 0, 0, 1, 1, -1, 0, -1], mask [True, True, True, True, False, False, False, True, False]\n",
            "action not avaliable action<0,8> 8 , satae [-1, 0, 1, 0, 1, 1, -1, 0, -1], mask [False, True, False, True, False, False, False, True, False]\n",
            "agent won  8018  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.10320654937199183 q value 0.3120408696787698  reward : 1\n",
            "game #num:  14728\n",
            "action not avaliable action<0,8> 7 , satae [0, -1, 0, 0, 0, 0, 0, -1, 1], mask [True, False, True, True, True, True, True, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [0, -1, 0, 0, 0, 1, -1, -1, 1], mask [True, False, True, True, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 1 , satae [0, -1, 0, 0, 0, 1, -1, -1, 1], mask [True, False, True, True, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 5 , satae [0, -1, 0, 0, 0, 1, -1, -1, 1], mask [True, False, True, True, True, False, False, False, False]\n",
            "agent won  8019  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.12081539737326759 q value 0.31549968464033945  reward : 1\n",
            "game #num:  14729\n",
            "mcts won  5265  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.10664603114128113 q value 0.3178178668022156  reward : -1\n",
            "game #num:  14730\n",
            "action not avaliable action<0,8> 4 , satae [-1, 0, 0, 0, -1, 0, 1, 0, 0], mask [False, True, True, True, False, True, False, True, True]\n",
            "mcts won  5266  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.12299161590635777 q value 0.3189229592680931  reward : -1\n",
            "game #num:  14731\n",
            "action not avaliable action<0,8> 1 , satae [-1, 1, 0, 0, 0, 0, 0, 0, 0], mask [False, False, True, True, True, True, True, True, True]\n",
            "action not avaliable action<0,8> 0 , satae [-1, 1, -1, 1, 0, 0, -1, 0, 1], mask [False, False, False, False, True, True, False, True, False]\n",
            "action not avaliable action<0,8> 1 , satae [-1, 1, -1, 1, 0, 0, -1, 0, 1], mask [False, False, False, False, True, True, False, True, False]\n",
            "action not avaliable action<0,8> 3 , satae [-1, 1, -1, 1, 0, 0, -1, 0, 1], mask [False, False, False, False, True, True, False, True, False]\n",
            "action not avaliable action<0,8> 1 , satae [-1, 1, -1, 1, 0, 0, -1, 0, 1], mask [False, False, False, False, True, True, False, True, False]\n",
            "action not avaliable action<0,8> 3 , satae [-1, 1, -1, 1, 0, 0, -1, 0, 1], mask [False, False, False, False, True, True, False, True, False]\n",
            "action not avaliable action<0,8> 8 , satae [-1, 1, -1, 1, 0, 0, -1, 0, 1], mask [False, False, False, False, True, True, False, True, False]\n",
            "action not avaliable action<0,8> 3 , satae [-1, 1, -1, 1, 0, 0, -1, 0, 1], mask [False, False, False, False, True, True, False, True, False]\n",
            "action not avaliable action<0,8> 2 , satae [-1, 1, -1, 1, 0, 0, -1, 0, 1], mask [False, False, False, False, True, True, False, True, False]\n",
            "mcts won  5267  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.11108086258172989 q value 0.3224441844683427  reward : -1\n",
            "game #num:  14732\n",
            "action not avaliable action<0,8> 2 , satae [0, 0, -1, 0, 1, 0, 0, 0, 0], mask [True, True, False, True, False, True, True, True, True]\n",
            "action not avaliable action<0,8> 4 , satae [1, -1, -1, 0, 1, 0, 0, 0, 0], mask [False, False, False, True, False, True, True, True, True]\n",
            "action not avaliable action<0,8> 2 , satae [1, -1, -1, 0, 1, 0, 0, 0, 0], mask [False, False, False, True, False, True, True, True, True]\n",
            "action not avaliable action<0,8> 4 , satae [1, -1, -1, 0, 1, 0, 0, 0, 0], mask [False, False, False, True, False, True, True, True, True]\n",
            "action not avaliable action<0,8> 4 , satae [1, -1, -1, 0, 1, 0, 0, 0, 0], mask [False, False, False, True, False, True, True, True, True]\n",
            "action not avaliable action<0,8> 0 , satae [1, -1, -1, 0, 1, 0, 0, 0, 0], mask [False, False, False, True, False, True, True, True, True]\n",
            "action not avaliable action<0,8> 1 , satae [1, -1, -1, 0, 1, 0, -1, 1, 0], mask [False, False, False, True, False, True, False, False, True]\n",
            "action not avaliable action<0,8> 0 , satae [1, -1, -1, 0, 1, 0, -1, 1, 0], mask [False, False, False, True, False, True, False, False, True]\n",
            "action not avaliable action<0,8> 0 , satae [1, -1, -1, 0, 1, 0, -1, 1, 0], mask [False, False, False, True, False, True, False, False, True]\n",
            "action not avaliable action<0,8> 1 , satae [1, -1, -1, 0, 1, 0, -1, 1, 0], mask [False, False, False, True, False, True, False, False, True]\n",
            "agent won  8020  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.11048539355397224 q value 0.32578611586775097  reward : 1\n",
            "game #num:  14733\n",
            "action not avaliable action<0,8> 3 , satae [-1, 0, 1, 1, 1, -1, -1, -1, 1], mask [False, True, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 5 , satae [-1, 0, 1, 1, 1, -1, -1, -1, 1], mask [False, True, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 5 , satae [-1, 0, 1, 1, 1, -1, -1, -1, 1], mask [False, True, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [-1, 0, 1, 1, 1, -1, -1, -1, 1], mask [False, True, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 2 , satae [-1, 0, 1, 1, 1, -1, -1, -1, 1], mask [False, True, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 5 , satae [-1, 0, 1, 1, 1, -1, -1, -1, 1], mask [False, True, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [-1, 0, 1, 1, 1, -1, -1, -1, 1], mask [False, True, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 3 , satae [-1, 0, 1, 1, 1, -1, -1, -1, 1], mask [False, True, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 0 , satae [-1, 0, 1, 1, 1, -1, -1, -1, 1], mask [False, True, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [-1, 0, 1, 1, 1, -1, -1, -1, 1], mask [False, True, False, False, False, False, False, False, False]\n",
            "draw  1446  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "################################################################################################\n",
            "game loss:  0.11179069032271703 q value 0.3304507394631704  reward : 0\n",
            "game #num:  14734\n",
            "mcts won  5268  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.09150685369968414 q value 0.33156511187553406  reward : -1\n",
            "game #num:  14735\n",
            "action not avaliable action<0,8> 6 , satae [0, -1, 0, -1, 1, 0, 1, -1, 1], mask [True, False, True, False, False, True, False, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [0, -1, 0, -1, 1, 0, 1, -1, 1], mask [True, False, True, False, False, True, False, False, False]\n",
            "action not avaliable action<0,8> 5 , satae [-1, -1, 0, -1, 1, 1, 1, -1, 1], mask [False, False, True, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [-1, -1, 0, -1, 1, 1, 1, -1, 1], mask [False, False, True, False, False, False, False, False, False]\n",
            "agent won  8021  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.12261665281322268 q value 0.3312051163779365  reward : 1\n",
            "game #num:  14736\n",
            "action not avaliable action<0,8> 3 , satae [1, -1, -1, -1, 0, 1, 0, 0, 1], mask [False, False, False, False, True, False, True, True, False]\n",
            "action not avaliable action<0,8> 0 , satae [1, -1, -1, -1, 0, 1, 0, 0, 1], mask [False, False, False, False, True, False, True, True, False]\n",
            "action not avaliable action<0,8> 1 , satae [1, -1, -1, -1, 0, 1, 0, 0, 1], mask [False, False, False, False, True, False, True, True, False]\n",
            "action not avaliable action<0,8> 8 , satae [1, -1, -1, -1, 0, 1, 0, 0, 1], mask [False, False, False, False, True, False, True, True, False]\n",
            "action not avaliable action<0,8> 3 , satae [1, -1, -1, -1, 0, 1, -1, 1, 1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 2 , satae [1, -1, -1, -1, 0, 1, -1, 1, 1], mask [False, False, False, False, True, False, False, False, False]\n",
            "agent won  8022  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.10995715517889369 q value 0.32767118378119037  reward : 1\n",
            "game #num:  14737\n",
            "mcts won  5269  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.11137391813099384 q value 0.32604674249887466  reward : -1\n",
            "game #num:  14738\n",
            "action not avaliable action<0,8> 1 , satae [0, -1, 0, 1, 0, 0, 0, 0, 0], mask [True, False, True, False, True, True, True, True, True]\n",
            "action not avaliable action<0,8> 3 , satae [0, -1, 1, 1, -1, 1, -1, 0, 0], mask [True, False, False, False, False, False, False, True, True]\n",
            "agent won  8023  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.11183196554581325 q value 0.3260289927323659  reward : 1\n",
            "game #num:  14739\n",
            "action not avaliable action<0,8> 1 , satae [-1, 1, 0, -1, 0, 0, 0, 0, 0], mask [False, False, True, False, True, True, True, True, True]\n",
            "action not avaliable action<0,8> 7 , satae [-1, 1, 0, -1, 1, 0, 0, -1, 0], mask [False, False, True, False, False, True, True, False, True]\n",
            "action not avaliable action<0,8> 7 , satae [-1, 1, 0, -1, 1, 0, 0, -1, 0], mask [False, False, True, False, False, True, True, False, True]\n",
            "agent won  8024  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.12829729169607162 q value 0.32422779500484467  reward : 1\n",
            "game #num:  14740\n",
            "action not avaliable action<0,8> 7 , satae [0, 0, 0, 0, 1, 0, 0, -1, 0], mask [True, True, True, True, False, True, True, False, True]\n",
            "action not avaliable action<0,8> 7 , satae [0, 0, 1, -1, 1, 0, 0, -1, 0], mask [True, True, False, False, False, True, True, False, True]\n",
            "action not avaliable action<0,8> 7 , satae [0, 0, 1, -1, 1, 0, 0, -1, 0], mask [True, True, False, False, False, True, True, False, True]\n",
            "agent won  8025  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.11462881695479155 q value 0.3200754001736641  reward : 1\n",
            "game #num:  14741\n",
            "action not avaliable action<0,8> 1 , satae [0, 1, 0, -1, 0, 0, -1, 0, 0], mask [True, False, True, False, True, True, False, True, True]\n",
            "action not avaliable action<0,8> 6 , satae [0, 1, 0, -1, 0, 0, -1, 0, 0], mask [True, False, True, False, True, True, False, True, True]\n",
            "action not avaliable action<0,8> 2 , satae [1, 1, -1, -1, 0, 0, -1, 0, 0], mask [False, False, False, False, True, True, False, True, True]\n",
            "action not avaliable action<0,8> 1 , satae [1, 1, -1, -1, 0, 1, -1, 0, -1], mask [False, False, False, False, True, False, False, True, False]\n",
            "agent won  8026  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.12269530538469553 q value 0.3191228173673153  reward : 1\n",
            "game #num:  14742\n",
            "mcts won  5270  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.11192745715379715 q value 0.31865300983190536  reward : -1\n",
            "game #num:  14743\n",
            "action not avaliable action<0,8> 6 , satae [0, 0, 0, -1, 0, 0, 1, -1, 0], mask [True, True, True, False, True, True, False, False, True]\n",
            "action not avaliable action<0,8> 6 , satae [0, 0, 0, -1, 0, 0, 1, -1, 0], mask [True, True, True, False, True, True, False, False, True]\n",
            "action not avaliable action<0,8> 6 , satae [0, 0, 0, -1, 0, 0, 1, -1, 0], mask [True, True, True, False, True, True, False, False, True]\n",
            "action not avaliable action<0,8> 7 , satae [0, 0, 0, -1, 0, -1, 1, -1, 1], mask [True, True, True, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [0, -1, 0, -1, 1, -1, 1, -1, 1], mask [True, False, True, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 3 , satae [0, -1, 0, -1, 1, -1, 1, -1, 1], mask [True, False, True, False, False, False, False, False, False]\n",
            "agent won  8027  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.1146254763007164 q value 0.31818162798881533  reward : 1\n",
            "game #num:  14744\n",
            "action not avaliable action<0,8> 8 , satae [0, 0, 0, 1, 0, 0, 0, 0, -1], mask [True, True, True, False, True, True, True, True, False]\n",
            "action not avaliable action<0,8> 1 , satae [0, 1, 0, 1, 0, 0, -1, 0, -1], mask [True, False, True, False, True, True, False, True, False]\n",
            "action not avaliable action<0,8> 8 , satae [0, 1, 0, 1, 0, 0, -1, 0, -1], mask [True, False, True, False, True, True, False, True, False]\n",
            "action not avaliable action<0,8> 3 , satae [0, 1, 0, 1, 0, 0, -1, 0, -1], mask [True, False, True, False, True, True, False, True, False]\n",
            "action not avaliable action<0,8> 8 , satae [-1, 1, 0, 1, 1, 0, -1, 0, -1], mask [False, False, True, False, False, True, False, True, False]\n",
            "mcts won  5271  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.10502889586819543 q value 0.3165874977906545  reward : -1\n",
            "game #num:  14745\n",
            "action not avaliable action<0,8> 1 , satae [0, -1, -1, 1, 0, 0, -1, 1, 0], mask [True, False, False, False, True, True, False, False, True]\n",
            "action not avaliable action<0,8> 3 , satae [0, -1, -1, 1, 0, 0, -1, 1, 0], mask [True, False, False, False, True, True, False, False, True]\n",
            "action not avaliable action<0,8> 7 , satae [0, -1, -1, 1, 0, 0, -1, 1, 0], mask [True, False, False, False, True, True, False, False, True]\n",
            "agent won  8028  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.11110790818929672 q value 0.31622923413912457  reward : 1\n",
            "game #num:  14746\n",
            "action not avaliable action<0,8> 8 , satae [0, -1, 1, -1, 1, -1, -1, 1, 1], mask [True, False, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 2 , satae [0, -1, 1, -1, 1, -1, -1, 1, 1], mask [True, False, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [0, -1, 1, -1, 1, -1, -1, 1, 1], mask [True, False, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [0, -1, 1, -1, 1, -1, -1, 1, 1], mask [True, False, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 4 , satae [0, -1, 1, -1, 1, -1, -1, 1, 1], mask [True, False, False, False, False, False, False, False, False]\n",
            "agent won  8029  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.11651714816689492 q value 0.31628857254981996  reward : 1\n",
            "game #num:  14747\n",
            "action not avaliable action<0,8> 5 , satae [0, 0, 0, -1, 0, 1, -1, 0, 0], mask [True, True, True, False, True, False, False, True, True]\n",
            "action not avaliable action<0,8> 3 , satae [1, -1, 0, -1, 0, 1, -1, 1, -1], mask [False, False, True, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [1, -1, 0, -1, 0, 1, -1, 1, -1], mask [False, False, True, False, True, False, False, False, False]\n",
            "draw  1447  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0]\n",
            "################################################################################################\n",
            "game loss:  0.10636994455541883 q value 0.31571910636765615  reward : 0\n",
            "game #num:  14748\n",
            "agent won  8030  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.11198214069008827 q value 0.3162320554256439  reward : 1\n",
            "game #num:  14749\n",
            "action not avaliable action<0,8> 5 , satae [-1, 0, 0, 1, 0, -1, 0, 0, 0], mask [False, True, True, False, True, False, True, True, True]\n",
            "action not avaliable action<0,8> 2 , satae [-1, 0, 1, 1, -1, -1, 0, 0, 0], mask [False, True, False, False, False, False, True, True, True]\n",
            "action not avaliable action<0,8> 3 , satae [-1, 0, 1, 1, -1, -1, 0, 0, 0], mask [False, True, False, False, False, False, True, True, True]\n",
            "action not avaliable action<0,8> 3 , satae [-1, 0, 1, 1, -1, -1, 0, 0, 0], mask [False, True, False, False, False, False, True, True, True]\n",
            "action not avaliable action<0,8> 3 , satae [-1, 0, 1, 1, -1, -1, 0, 0, 0], mask [False, True, False, False, False, False, True, True, True]\n",
            "action not avaliable action<0,8> 5 , satae [-1, 0, 1, 1, -1, -1, 0, 0, 0], mask [False, True, False, False, False, False, True, True, True]\n",
            "action not avaliable action<0,8> 3 , satae [-1, 1, 1, 1, -1, -1, -1, 0, 0], mask [False, False, False, False, False, False, False, True, True]\n",
            "draw  1448  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "################################################################################################\n",
            "game loss:  0.11528916927901181 q value 0.3176057121970437  reward : 0\n",
            "game #num:  14750\n",
            "mcts won  5272  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.10981864854693413 q value 0.318818598985672  reward : -1\n",
            "game #num:  14751\n",
            "action not avaliable action<0,8> 3 , satae [1, 0, 0, -1, 0, 0, -1, -1, 1], mask [False, True, True, False, True, True, False, False, False]\n",
            "action not avaliable action<0,8> 1 , satae [1, 1, -1, -1, 0, 0, -1, -1, 1], mask [False, False, False, False, True, True, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [1, 1, -1, -1, 0, 0, -1, -1, 1], mask [False, False, False, False, True, True, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [1, 1, -1, -1, 0, 0, -1, -1, 1], mask [False, False, False, False, True, True, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [1, 1, -1, -1, 0, 0, -1, -1, 1], mask [False, False, False, False, True, True, False, False, False]\n",
            "action not avaliable action<0,8> 1 , satae [1, 1, -1, -1, 0, 0, -1, -1, 1], mask [False, False, False, False, True, True, False, False, False]\n",
            "mcts won  5273  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.11339117884635926 q value 0.31816546022892  reward : -1\n",
            "game #num:  14752\n",
            "mcts won  5274  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.11371106095612049 q value 0.3176717832684517  reward : -1\n",
            "game #num:  14753\n",
            "agent won  8031  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.1106645514567693 q value 0.3178245524565379  reward : 1\n",
            "game #num:  14754\n",
            "agent won  8032  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.10827473551034927 q value 0.3183433810869853  reward : 1\n",
            "game #num:  14755\n",
            "action not avaliable action<0,8> 7 , satae [0, 0, 0, 0, 0, 0, 0, -1, 0], mask [True, True, True, True, True, True, True, False, True]\n",
            "action not avaliable action<0,8> 7 , satae [0, 0, 0, 0, 0, 0, 0, -1, 0], mask [True, True, True, True, True, True, True, False, True]\n",
            "action not avaliable action<0,8> 2 , satae [1, 0, -1, 0, 0, -1, 1, -1, 0], mask [False, True, False, True, True, False, False, False, True]\n",
            "action not avaliable action<0,8> 6 , satae [1, 0, -1, 0, 0, -1, 1, -1, 0], mask [False, True, False, True, True, False, False, False, True]\n",
            "action not avaliable action<0,8> 0 , satae [1, 0, -1, 0, 0, -1, 1, -1, 0], mask [False, True, False, True, True, False, False, False, True]\n",
            "action not avaliable action<0,8> 2 , satae [1, 0, -1, 0, 0, -1, 1, -1, 0], mask [False, True, False, True, True, False, False, False, True]\n",
            "action not avaliable action<0,8> 6 , satae [1, 0, -1, 0, 0, -1, 1, -1, 0], mask [False, True, False, True, True, False, False, False, True]\n",
            "action not avaliable action<0,8> 6 , satae [1, 0, -1, 0, 0, -1, 1, -1, 0], mask [False, True, False, True, True, False, False, False, True]\n",
            "action not avaliable action<0,8> 7 , satae [1, 0, -1, 0, 0, -1, 1, -1, 0], mask [False, True, False, True, True, False, False, False, True]\n",
            "action not avaliable action<0,8> 5 , satae [1, 0, -1, 0, 0, -1, 1, -1, 0], mask [False, True, False, True, True, False, False, False, True]\n",
            "action not avaliable action<0,8> 6 , satae [1, 0, -1, 0, 0, -1, 1, -1, 0], mask [False, True, False, True, True, False, False, False, True]\n",
            "action not avaliable action<0,8> 6 , satae [1, -1, -1, 0, 0, -1, 1, -1, 1], mask [False, False, False, True, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 1 , satae [1, -1, -1, 0, 0, -1, 1, -1, 1], mask [False, False, False, True, True, False, False, False, False]\n",
            "agent won  8033  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.11515073565875783 q value 0.3189393913044649  reward : 1\n",
            "game #num:  14756\n",
            "action not avaliable action<0,8> 6 , satae [0, 1, 0, 0, 1, -1, -1, 0, 0], mask [True, False, True, True, False, False, False, True, True]\n",
            "action not avaliable action<0,8> 1 , satae [0, 1, 0, 0, 1, -1, -1, 0, 0], mask [True, False, True, True, False, False, False, True, True]\n",
            "action not avaliable action<0,8> 8 , satae [0, 1, -1, 0, 1, -1, -1, 0, 1], mask [True, False, False, True, False, False, False, True, False]\n",
            "action not avaliable action<0,8> 2 , satae [-1, 1, -1, 1, 1, -1, -1, 0, 1], mask [False, False, False, False, False, False, False, True, False]\n",
            "action not avaliable action<0,8> 1 , satae [-1, 1, -1, 1, 1, -1, -1, 0, 1], mask [False, False, False, False, False, False, False, True, False]\n",
            "action not avaliable action<0,8> 2 , satae [-1, 1, -1, 1, 1, -1, -1, 0, 1], mask [False, False, False, False, False, False, False, True, False]\n",
            "action not avaliable action<0,8> 8 , satae [-1, 1, -1, 1, 1, -1, -1, 0, 1], mask [False, False, False, False, False, False, False, True, False]\n",
            "action not avaliable action<0,8> 8 , satae [-1, 1, -1, 1, 1, -1, -1, 0, 1], mask [False, False, False, False, False, False, False, True, False]\n",
            "action not avaliable action<0,8> 6 , satae [-1, 1, -1, 1, 1, -1, -1, 0, 1], mask [False, False, False, False, False, False, False, True, False]\n",
            "action not avaliable action<0,8> 2 , satae [-1, 1, -1, 1, 1, -1, -1, 0, 1], mask [False, False, False, False, False, False, False, True, False]\n",
            "action not avaliable action<0,8> 6 , satae [-1, 1, -1, 1, 1, -1, -1, 0, 1], mask [False, False, False, False, False, False, False, True, False]\n",
            "action not avaliable action<0,8> 0 , satae [-1, 1, -1, 1, 1, -1, -1, 0, 1], mask [False, False, False, False, False, False, False, True, False]\n",
            "action not avaliable action<0,8> 5 , satae [-1, 1, -1, 1, 1, -1, -1, 0, 1], mask [False, False, False, False, False, False, False, True, False]\n",
            "action not avaliable action<0,8> 1 , satae [-1, 1, -1, 1, 1, -1, -1, 0, 1], mask [False, False, False, False, False, False, False, True, False]\n",
            "action not avaliable action<0,8> 2 , satae [-1, 1, -1, 1, 1, -1, -1, 0, 1], mask [False, False, False, False, False, False, False, True, False]\n",
            "action not avaliable action<0,8> 6 , satae [-1, 1, -1, 1, 1, -1, -1, 0, 1], mask [False, False, False, False, False, False, False, True, False]\n",
            "draw  1449  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "################################################################################################\n",
            "game loss:  0.11445617462907519 q value 0.3204709121159145  reward : 0\n",
            "game #num:  14757\n",
            "action not avaliable action<0,8> 3 , satae [0, 0, -1, -1, 0, 0, 0, 1, 1], mask [True, True, False, False, True, True, True, False, False]\n",
            "action not avaliable action<0,8> 3 , satae [0, 0, -1, -1, 1, 0, -1, 1, 1], mask [True, True, False, False, False, True, False, False, False]\n",
            "agent won  8034  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.10459457834561665 q value 0.3208060065905253  reward : 1\n",
            "game #num:  14758\n",
            "action not avaliable action<0,8> 0 , satae [1, 0, 1, 1, -1, -1, -1, -1, 0], mask [False, True, False, False, False, False, False, False, True]\n",
            "agent won  8035  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.11932974606752396 q value 0.3215928077697754  reward : 1\n",
            "game #num:  14759\n",
            "mcts won  5275  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.11509783752262592 q value 0.3205477148294449  reward : -1\n",
            "game #num:  14760\n",
            "action not avaliable action<0,8> 2 , satae [0, 0, 1, 0, 0, -1, -1, 0, 0], mask [True, True, False, True, True, False, False, True, True]\n",
            "mcts won  5276  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.11246880702674389 q value 0.31991009414196014  reward : -1\n",
            "game #num:  14761\n",
            "mcts won  5277  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.12671683977047601 q value 0.3193780581156413  reward : -1\n",
            "game #num:  14762\n",
            "action not avaliable action<0,8> 3 , satae [-1, 0, 0, 1, 0, 0, 0, 1, -1], mask [False, True, True, False, True, True, True, False, False]\n",
            "action not avaliable action<0,8> 3 , satae [-1, 0, 0, 1, 0, 0, 0, 1, -1], mask [False, True, True, False, True, True, True, False, False]\n",
            "action not avaliable action<0,8> 0 , satae [-1, 0, 0, 1, 0, 0, 0, 1, -1], mask [False, True, True, False, True, True, True, False, False]\n",
            "action not avaliable action<0,8> 0 , satae [-1, 0, 0, 1, 0, 0, 0, 1, -1], mask [False, True, True, False, True, True, True, False, False]\n",
            "agent won  8036  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.10511999484151602 q value 0.3190034255385399  reward : 1\n",
            "game #num:  14763\n",
            "action not avaliable action<0,8> 8 , satae [-1, 0, 1, 1, 1, 0, 0, -1, -1], mask [False, True, False, False, False, True, True, False, False]\n",
            "action not avaliable action<0,8> 0 , satae [-1, 0, 1, 1, 1, 0, 0, -1, -1], mask [False, True, False, False, False, True, True, False, False]\n",
            "action not avaliable action<0,8> 2 , satae [-1, 0, 1, 1, 1, 0, 0, -1, -1], mask [False, True, False, False, False, True, True, False, False]\n",
            "action not avaliable action<0,8> 3 , satae [-1, 0, 1, 1, 1, 0, 0, -1, -1], mask [False, True, False, False, False, True, True, False, False]\n",
            "action not avaliable action<0,8> 4 , satae [-1, 0, 1, 1, 1, 0, 0, -1, -1], mask [False, True, False, False, False, True, True, False, False]\n",
            "action not avaliable action<0,8> 3 , satae [-1, 0, 1, 1, 1, 0, 0, -1, -1], mask [False, True, False, False, False, True, True, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [-1, 0, 1, 1, 1, 0, 0, -1, -1], mask [False, True, False, False, False, True, True, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [-1, 0, 1, 1, 1, 0, 0, -1, -1], mask [False, True, False, False, False, True, True, False, False]\n",
            "mcts won  5278  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.10836861779292424 q value 0.31986592213312787  reward : -1\n",
            "game #num:  14764\n",
            "action not avaliable action<0,8> 6 , satae [0, -1, 0, 1, 0, -1, 1, -1, 1], mask [True, False, True, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [0, -1, 0, 1, 0, -1, 1, -1, 1], mask [True, False, True, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [0, -1, 0, 1, 0, -1, 1, -1, 1], mask [True, False, True, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [0, -1, 0, 1, 0, -1, 1, -1, 1], mask [True, False, True, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [0, -1, 0, 1, 0, -1, 1, -1, 1], mask [True, False, True, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [0, -1, 0, 1, 0, -1, 1, -1, 1], mask [True, False, True, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [-1, -1, 0, 1, 1, -1, 1, -1, 1], mask [False, False, True, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 5 , satae [-1, -1, 0, 1, 1, -1, 1, -1, 1], mask [False, False, True, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 4 , satae [-1, -1, 0, 1, 1, -1, 1, -1, 1], mask [False, False, True, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 5 , satae [-1, -1, 0, 1, 1, -1, 1, -1, 1], mask [False, False, True, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 5 , satae [-1, -1, 0, 1, 1, -1, 1, -1, 1], mask [False, False, True, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [-1, -1, 0, 1, 1, -1, 1, -1, 1], mask [False, False, True, False, False, False, False, False, False]\n",
            "agent won  8037  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.11096472994369619 q value 0.32011790836558623  reward : 1\n",
            "game #num:  14765\n",
            "action not avaliable action<0,8> 6 , satae [1, 0, -1, 0, 0, -1, 1, 0, 0], mask [False, True, False, True, True, False, False, True, True]\n",
            "action not avaliable action<0,8> 2 , satae [1, 0, -1, 0, 0, -1, 1, 0, 0], mask [False, True, False, True, True, False, False, True, True]\n",
            "action not avaliable action<0,8> 8 , satae [1, 0, -1, -1, 0, -1, 1, 0, 1], mask [False, True, False, False, True, False, False, True, False]\n",
            "action not avaliable action<0,8> 2 , satae [1, 0, -1, -1, 0, -1, 1, 0, 1], mask [False, True, False, False, True, False, False, True, False]\n",
            "action not avaliable action<0,8> 6 , satae [1, 0, -1, -1, 0, -1, 1, 0, 1], mask [False, True, False, False, True, False, False, True, False]\n",
            "action not avaliable action<0,8> 6 , satae [1, 0, -1, -1, 0, -1, 1, 0, 1], mask [False, True, False, False, True, False, False, True, False]\n",
            "action not avaliable action<0,8> 8 , satae [1, 0, -1, -1, 0, -1, 1, 0, 1], mask [False, True, False, False, True, False, False, True, False]\n",
            "action not avaliable action<0,8> 3 , satae [1, 0, -1, -1, 0, -1, 1, 0, 1], mask [False, True, False, False, True, False, False, True, False]\n",
            "action not avaliable action<0,8> 8 , satae [1, 0, -1, -1, 0, -1, 1, 0, 1], mask [False, True, False, False, True, False, False, True, False]\n",
            "action not avaliable action<0,8> 5 , satae [1, 0, -1, -1, 0, -1, 1, 0, 1], mask [False, True, False, False, True, False, False, True, False]\n",
            "action not avaliable action<0,8> 3 , satae [1, 1, -1, -1, 0, -1, 1, -1, 1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [1, 1, -1, -1, 0, -1, 1, -1, 1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [1, 1, -1, -1, 0, -1, 1, -1, 1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [1, 1, -1, -1, 0, -1, 1, -1, 1], mask [False, False, False, False, True, False, False, False, False]\n",
            "agent won  8038  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.11321118081870832 q value 0.32258492237643194  reward : 1\n",
            "game #num:  14766\n",
            "action not avaliable action<0,8> 5 , satae [0, 0, 0, 0, -1, 1, -1, 0, 0], mask [True, True, True, True, False, False, False, True, True]\n",
            "agent won  8039  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.09829194347063701 q value 0.3196263412634532  reward : 1\n",
            "game #num:  14767\n",
            "action not avaliable action<0,8> 1 , satae [0, -1, 0, 0, 1, 0, -1, 1, -1], mask [True, False, True, True, False, True, False, False, False]\n",
            "action not avaliable action<0,8> 0 , satae [1, -1, -1, 0, 1, 0, -1, 1, -1], mask [False, False, False, True, False, True, False, False, False]\n",
            "action not avaliable action<0,8> 1 , satae [1, -1, -1, 0, 1, 0, -1, 1, -1], mask [False, False, False, True, False, True, False, False, False]\n",
            "mcts won  5279  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.11784084673438754 q value 0.31946009397506714  reward : -1\n",
            "game #num:  14768\n",
            "action not avaliable action<0,8> 3 , satae [-1, 0, 0, 1, 0, 0, 0, -1, 0], mask [False, True, True, False, True, True, True, False, True]\n",
            "action not avaliable action<0,8> 7 , satae [-1, 0, 0, 1, 0, 0, 0, -1, 0], mask [False, True, True, False, True, True, True, False, True]\n",
            "draw  1450  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0]\n",
            "################################################################################################\n",
            "game loss:  0.10856131960948308 q value 0.3180561463038127  reward : 0\n",
            "game #num:  14769\n",
            "action not avaliable action<0,8> 7 , satae [-1, -1, 0, 0, 0, 0, 0, 1, 0], mask [False, False, True, True, True, True, True, False, True]\n",
            "action not avaliable action<0,8> 1 , satae [-1, -1, 0, 0, 0, 0, 0, 1, 0], mask [False, False, True, True, True, True, True, False, True]\n",
            "action not avaliable action<0,8> 7 , satae [-1, -1, 0, 0, 0, 0, 0, 1, 0], mask [False, False, True, True, True, True, True, False, True]\n",
            "mcts won  5280  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.11590691506862641 q value 0.31846542954444884  reward : -1\n",
            "game #num:  14770\n",
            "action not avaliable action<0,8> 6 , satae [-1, 0, 1, 0, 0, 0, -1, 1, -1], mask [False, True, False, True, True, True, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [-1, 0, 1, 0, 0, 0, -1, 1, -1], mask [False, True, False, True, True, True, False, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [-1, 0, 1, 0, 0, 0, -1, 1, -1], mask [False, True, False, True, True, True, False, False, False]\n",
            "mcts won  5281  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.11111916850010554 q value 0.318962961435318  reward : -1\n",
            "game #num:  14771\n",
            "action not avaliable action<0,8> 5 , satae [-1, 1, 1, -1, 0, -1, 0, 0, 1], mask [False, False, False, False, True, False, True, True, False]\n",
            "action not avaliable action<0,8> 1 , satae [-1, 1, 1, -1, 0, -1, 0, 0, 1], mask [False, False, False, False, True, False, True, True, False]\n",
            "action not avaliable action<0,8> 1 , satae [-1, 1, 1, -1, 0, -1, 0, 0, 1], mask [False, False, False, False, True, False, True, True, False]\n",
            "mcts won  5282  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.11618158859866005 q value 0.3188291575227465  reward : -1\n",
            "game #num:  14772\n",
            "mcts won  5283  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.11200170964002609 q value 0.3187052458524704  reward : -1\n",
            "game #num:  14773\n",
            "action not avaliable action<0,8> 4 , satae [0, 0, 0, 0, 1, -1, 0, 0, 0], mask [True, True, True, True, False, False, True, True, True]\n",
            "action not avaliable action<0,8> 4 , satae [0, 0, 0, -1, 1, -1, 0, 0, 1], mask [True, True, True, False, False, False, True, True, False]\n",
            "action not avaliable action<0,8> 6 , satae [0, 0, 0, -1, 1, -1, -1, 1, 1], mask [True, True, True, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 4 , satae [0, 0, 0, -1, 1, -1, -1, 1, 1], mask [True, True, True, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [0, 0, 0, -1, 1, -1, -1, 1, 1], mask [True, True, True, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 4 , satae [0, 0, 0, -1, 1, -1, -1, 1, 1], mask [True, True, True, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 4 , satae [0, 0, 0, -1, 1, -1, -1, 1, 1], mask [True, True, True, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [0, 0, 0, -1, 1, -1, -1, 1, 1], mask [True, True, True, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 4 , satae [0, 0, 0, -1, 1, -1, -1, 1, 1], mask [True, True, True, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [0, 0, 0, -1, 1, -1, -1, 1, 1], mask [True, True, True, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [0, 0, 0, -1, 1, -1, -1, 1, 1], mask [True, True, True, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 3 , satae [0, 0, 0, -1, 1, -1, -1, 1, 1], mask [True, True, True, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [0, 0, 0, -1, 1, -1, -1, 1, 1], mask [True, True, True, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 4 , satae [0, 0, 0, -1, 1, -1, -1, 1, 1], mask [True, True, True, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 4 , satae [0, 0, 0, -1, 1, -1, -1, 1, 1], mask [True, True, True, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 4 , satae [0, 0, 0, -1, 1, -1, -1, 1, 1], mask [True, True, True, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [0, 0, 0, -1, 1, -1, -1, 1, 1], mask [True, True, True, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [0, 0, 0, -1, 1, -1, -1, 1, 1], mask [True, True, True, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 4 , satae [0, 0, 0, -1, 1, -1, -1, 1, 1], mask [True, True, True, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 5 , satae [0, 0, 0, -1, 1, -1, -1, 1, 1], mask [True, True, True, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 3 , satae [0, 0, 0, -1, 1, -1, -1, 1, 1], mask [True, True, True, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 4 , satae [0, 0, 0, -1, 1, -1, -1, 1, 1], mask [True, True, True, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [0, 0, 0, -1, 1, -1, -1, 1, 1], mask [True, True, True, False, False, False, False, False, False]\n",
            "agent won  8040  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.11959637729106126 q value 0.31649878400343434  reward : 1\n",
            "game #num:  14774\n",
            "action not avaliable action<0,8> 4 , satae [-1, 0, -1, 1, 1, 0, 0, 1, -1], mask [False, True, False, False, False, True, True, False, False]\n",
            "mcts won  5284  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.11909169852733612 q value 0.31756685972213744  reward : -1\n",
            "game #num:  14775\n",
            "action not avaliable action<0,8> 5 , satae [-1, 0, 0, 0, 1, 1, -1, -1, 0], mask [False, True, True, True, False, False, False, False, True]\n",
            "action not avaliable action<0,8> 7 , satae [-1, 0, 0, 0, 1, 1, -1, -1, 0], mask [False, True, True, True, False, False, False, False, True]\n",
            "action not avaliable action<0,8> 5 , satae [-1, 0, 0, 0, 1, 1, -1, -1, 0], mask [False, True, True, True, False, False, False, False, True]\n",
            "action not avaliable action<0,8> 4 , satae [-1, 0, 0, 0, 1, 1, -1, -1, 0], mask [False, True, True, True, False, False, False, False, True]\n",
            "action not avaliable action<0,8> 0 , satae [-1, 0, 0, 0, 1, 1, -1, -1, 0], mask [False, True, True, True, False, False, False, False, True]\n",
            "action not avaliable action<0,8> 4 , satae [-1, 0, 0, 0, 1, 1, -1, -1, 0], mask [False, True, True, True, False, False, False, False, True]\n",
            "agent won  8041  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.11136241836680306 q value 0.31740544570816887  reward : 1\n",
            "game #num:  14776\n",
            "action not avaliable action<0,8> 4 , satae [-1, 0, 0, 0, 1, 0, 0, 0, 0], mask [False, True, True, True, False, True, True, True, True]\n",
            "action not avaliable action<0,8> 8 , satae [-1, 0, -1, -1, 1, 1, 1, 1, -1], mask [False, True, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 2 , satae [-1, 0, -1, -1, 1, 1, 1, 1, -1], mask [False, True, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [-1, 0, -1, -1, 1, 1, 1, 1, -1], mask [False, True, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [-1, 0, -1, -1, 1, 1, 1, 1, -1], mask [False, True, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [-1, 0, -1, -1, 1, 1, 1, 1, -1], mask [False, True, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 2 , satae [-1, 0, -1, -1, 1, 1, 1, 1, -1], mask [False, True, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 0 , satae [-1, 0, -1, -1, 1, 1, 1, 1, -1], mask [False, True, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 2 , satae [-1, 0, -1, -1, 1, 1, 1, 1, -1], mask [False, True, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [-1, 0, -1, -1, 1, 1, 1, 1, -1], mask [False, True, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 5 , satae [-1, 0, -1, -1, 1, 1, 1, 1, -1], mask [False, True, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [-1, 0, -1, -1, 1, 1, 1, 1, -1], mask [False, True, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 2 , satae [-1, 0, -1, -1, 1, 1, 1, 1, -1], mask [False, True, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 5 , satae [-1, 0, -1, -1, 1, 1, 1, 1, -1], mask [False, True, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 2 , satae [-1, 0, -1, -1, 1, 1, 1, 1, -1], mask [False, True, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [-1, 0, -1, -1, 1, 1, 1, 1, -1], mask [False, True, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 3 , satae [-1, 0, -1, -1, 1, 1, 1, 1, -1], mask [False, True, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 2 , satae [-1, 0, -1, -1, 1, 1, 1, 1, -1], mask [False, True, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 4 , satae [-1, 0, -1, -1, 1, 1, 1, 1, -1], mask [False, True, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [-1, 0, -1, -1, 1, 1, 1, 1, -1], mask [False, True, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 0 , satae [-1, 0, -1, -1, 1, 1, 1, 1, -1], mask [False, True, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [-1, 0, -1, -1, 1, 1, 1, 1, -1], mask [False, True, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 4 , satae [-1, 0, -1, -1, 1, 1, 1, 1, -1], mask [False, True, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 3 , satae [-1, 0, -1, -1, 1, 1, 1, 1, -1], mask [False, True, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [-1, 0, -1, -1, 1, 1, 1, 1, -1], mask [False, True, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 3 , satae [-1, 0, -1, -1, 1, 1, 1, 1, -1], mask [False, True, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [-1, 0, -1, -1, 1, 1, 1, 1, -1], mask [False, True, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 3 , satae [-1, 0, -1, -1, 1, 1, 1, 1, -1], mask [False, True, False, False, False, False, False, False, False]\n",
            "agent won  8042  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.10948278822682121 q value 0.3271742065747579  reward : 1\n",
            "game #num:  14777\n",
            "action not avaliable action<0,8> 6 , satae [0, -1, -1, 0, 0, 0, 1, 0, 1], mask [True, False, False, True, True, True, False, True, False]\n",
            "agent won  8043  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.10395509377121925 q value 0.32932138442993164  reward : 1\n",
            "game #num:  14778\n",
            "action not avaliable action<0,8> 4 , satae [-1, 1, 0, 0, 1, 0, 0, -1, 0], mask [False, False, True, True, False, True, True, False, True]\n",
            "action not avaliable action<0,8> 1 , satae [-1, 1, 0, 0, 1, 0, 0, -1, 0], mask [False, False, True, True, False, True, True, False, True]\n",
            "action not avaliable action<0,8> 1 , satae [-1, 1, 0, 0, 1, 0, 0, -1, 0], mask [False, False, True, True, False, True, True, False, True]\n",
            "action not avaliable action<0,8> 0 , satae [-1, 1, 0, 0, 1, 0, 0, -1, 0], mask [False, False, True, True, False, True, True, False, True]\n",
            "action not avaliable action<0,8> 1 , satae [-1, 1, 0, 0, 1, 0, 0, -1, 0], mask [False, False, True, True, False, True, True, False, True]\n",
            "action not avaliable action<0,8> 0 , satae [-1, 1, 0, 0, 1, 1, -1, -1, 0], mask [False, False, True, True, False, False, False, False, True]\n",
            "action not avaliable action<0,8> 0 , satae [-1, 1, -1, 0, 1, 1, -1, -1, 1], mask [False, False, False, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [-1, 1, -1, 0, 1, 1, -1, -1, 1], mask [False, False, False, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 4 , satae [-1, 1, -1, 0, 1, 1, -1, -1, 1], mask [False, False, False, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 5 , satae [-1, 1, -1, 0, 1, 1, -1, -1, 1], mask [False, False, False, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 5 , satae [-1, 1, -1, 0, 1, 1, -1, -1, 1], mask [False, False, False, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [-1, 1, -1, 0, 1, 1, -1, -1, 1], mask [False, False, False, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 0 , satae [-1, 1, -1, 0, 1, 1, -1, -1, 1], mask [False, False, False, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 2 , satae [-1, 1, -1, 0, 1, 1, -1, -1, 1], mask [False, False, False, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 0 , satae [-1, 1, -1, 0, 1, 1, -1, -1, 1], mask [False, False, False, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 5 , satae [-1, 1, -1, 0, 1, 1, -1, -1, 1], mask [False, False, False, True, False, False, False, False, False]\n",
            "agent won  8044  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.11343338234083992 q value 0.32596414004053387  reward : 1\n",
            "game #num:  14779\n",
            "action not avaliable action<0,8> 0 , satae [1, 0, -1, 0, 1, 0, 0, -1, -1], mask [False, True, False, True, False, True, True, False, False]\n",
            "agent won  8045  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.10445408150553703 q value 0.32363059371709824  reward : 1\n",
            "game #num:  14780\n",
            "action not avaliable action<0,8> 6 , satae [0, 1, 0, 0, 0, -1, 1, -1, -1], mask [True, False, True, True, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 3 , satae [-1, 1, 0, 1, 0, -1, 1, -1, -1], mask [False, False, True, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 0 , satae [-1, 1, 0, 1, 0, -1, 1, -1, -1], mask [False, False, True, False, True, False, False, False, False]\n",
            "mcts won  5285  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.11414400807448796 q value 0.32389925633158  reward : -1\n",
            "game #num:  14781\n",
            "action not avaliable action<0,8> 6 , satae [1, 1, -1, -1, 1, 0, -1, 0, -1], mask [False, False, False, False, False, True, False, True, False]\n",
            "action not avaliable action<0,8> 0 , satae [1, 1, -1, -1, 1, 0, -1, 0, -1], mask [False, False, False, False, False, True, False, True, False]\n",
            "action not avaliable action<0,8> 8 , satae [1, 1, -1, -1, 1, 0, -1, 0, -1], mask [False, False, False, False, False, True, False, True, False]\n",
            "action not avaliable action<0,8> 8 , satae [1, 1, -1, -1, 1, 0, -1, 0, -1], mask [False, False, False, False, False, True, False, True, False]\n",
            "action not avaliable action<0,8> 3 , satae [1, 1, -1, -1, 1, 0, -1, 0, -1], mask [False, False, False, False, False, True, False, True, False]\n",
            "action not avaliable action<0,8> 6 , satae [1, 1, -1, -1, 1, 0, -1, 0, -1], mask [False, False, False, False, False, True, False, True, False]\n",
            "agent won  8046  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.11025908142328263 q value 0.3245736092329025  reward : 1\n",
            "game #num:  14782\n",
            "action not avaliable action<0,8> 0 , satae [-1, 0, 1, 1, -1, 0, -1, -1, 1], mask [False, True, False, False, False, True, False, False, False]\n",
            "action not avaliable action<0,8> 4 , satae [-1, 0, 1, 1, -1, 0, -1, -1, 1], mask [False, True, False, False, False, True, False, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [-1, 0, 1, 1, -1, 0, -1, -1, 1], mask [False, True, False, False, False, True, False, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [-1, 0, 1, 1, -1, 0, -1, -1, 1], mask [False, True, False, False, False, True, False, False, False]\n",
            "action not avaliable action<0,8> 3 , satae [-1, 0, 1, 1, -1, 0, -1, -1, 1], mask [False, True, False, False, False, True, False, False, False]\n",
            "action not avaliable action<0,8> 0 , satae [-1, 0, 1, 1, -1, 0, -1, -1, 1], mask [False, True, False, False, False, True, False, False, False]\n",
            "action not avaliable action<0,8> 2 , satae [-1, 0, 1, 1, -1, 0, -1, -1, 1], mask [False, True, False, False, False, True, False, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [-1, 0, 1, 1, -1, 0, -1, -1, 1], mask [False, True, False, False, False, True, False, False, False]\n",
            "action not avaliable action<0,8> 0 , satae [-1, 0, 1, 1, -1, 0, -1, -1, 1], mask [False, True, False, False, False, True, False, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [-1, 0, 1, 1, -1, 0, -1, -1, 1], mask [False, True, False, False, False, True, False, False, False]\n",
            "action not avaliable action<0,8> 3 , satae [-1, 0, 1, 1, -1, 0, -1, -1, 1], mask [False, True, False, False, False, True, False, False, False]\n",
            "action not avaliable action<0,8> 3 , satae [-1, 0, 1, 1, -1, 0, -1, -1, 1], mask [False, True, False, False, False, True, False, False, False]\n",
            "draw  1451  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "################################################################################################\n",
            "game loss:  0.11533909430727363 q value 0.3260474484413862  reward : 0\n",
            "game #num:  14783\n",
            "mcts won  5286  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.100327434639136 q value 0.3224653402964274  reward : -1\n",
            "game #num:  14784\n",
            "action not avaliable action<0,8> 1 , satae [-1, -1, 0, 1, 1, -1, -1, 1, 0], mask [False, False, True, False, False, False, False, False, True]\n",
            "action not avaliable action<0,8> 6 , satae [-1, -1, 0, 1, 1, -1, -1, 1, 0], mask [False, False, True, False, False, False, False, False, True]\n",
            "agent won  8047  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.11345203469196956 q value 0.32038292785485584  reward : 1\n",
            "game #num:  14785\n",
            "action not avaliable action<0,8> 5 , satae [0, 0, 0, -1, 0, -1, 0, 1, 0], mask [True, True, True, False, True, False, True, False, True]\n",
            "action not avaliable action<0,8> 2 , satae [0, 0, 1, -1, 0, -1, -1, 1, 0], mask [True, True, False, False, True, False, False, False, True]\n",
            "mcts won  5287  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.11689527928829194 q value 0.31825334429740904  reward : -1\n",
            "game #num:  14786\n",
            "mcts won  5288  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.11693563312292099 q value 0.3168899118900299  reward : -1\n",
            "game #num:  14787\n",
            "action not avaliable action<0,8> 3 , satae [0, 0, 0, -1, 0, 0, 0, 0, 0], mask [True, True, True, False, True, True, True, True, True]\n",
            "action not avaliable action<0,8> 8 , satae [0, 0, 0, -1, 0, -1, 0, 0, 1], mask [True, True, True, False, True, False, True, True, False]\n",
            "action not avaliable action<0,8> 7 , satae [-1, -1, 0, -1, 1, -1, 0, 1, 1], mask [False, False, True, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 0 , satae [-1, -1, 0, -1, 1, -1, 0, 1, 1], mask [False, False, True, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 5 , satae [-1, -1, 0, -1, 1, -1, 0, 1, 1], mask [False, False, True, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [-1, -1, 0, -1, 1, -1, 0, 1, 1], mask [False, False, True, False, False, False, True, False, False]\n",
            "agent won  8048  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.1090331107378006 q value 0.316904553771019  reward : 1\n",
            "game #num:  14788\n",
            "action not avaliable action<0,8> 4 , satae [-1, 0, 0, 0, 1, 0, 0, 0, 0], mask [False, True, True, True, False, True, True, True, True]\n",
            "action not avaliable action<0,8> 4 , satae [-1, 0, 0, 0, 1, 0, 0, 0, 0], mask [False, True, True, True, False, True, True, True, True]\n",
            "action not avaliable action<0,8> 4 , satae [-1, 0, 0, -1, 1, 0, 0, 0, 1], mask [False, True, True, False, False, True, True, True, False]\n",
            "action not avaliable action<0,8> 5 , satae [-1, 0, -1, -1, 1, 1, 0, 0, 1], mask [False, True, False, False, False, False, True, True, False]\n",
            "agent won  8049  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.11248634848743677 q value 0.31707653030753136  reward : 1\n",
            "game #num:  14789\n",
            "action not avaliable action<0,8> 6 , satae [0, 0, 0, -1, 0, 1, -1, 0, 1], mask [True, True, True, False, True, False, False, True, False]\n",
            "action not avaliable action<0,8> 6 , satae [0, 1, 0, -1, -1, 1, -1, 0, 1], mask [True, False, True, False, False, False, False, True, False]\n",
            "agent won  8050  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.10687930881977081 q value 0.3191059281428655  reward : 1\n",
            "game #num:  14790\n",
            "action not avaliable action<0,8> 3 , satae [0, 1, 0, -1, 0, 0, 0, 0, 0], mask [True, False, True, False, True, True, True, True, True]\n",
            "action not avaliable action<0,8> 0 , satae [1, 1, 0, -1, 0, 0, -1, 1, -1], mask [False, False, True, False, True, True, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [1, 1, 0, -1, 0, 0, -1, 1, -1], mask [False, False, True, False, True, True, False, False, False]\n",
            "mcts won  5289  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.10800153123480934 q value 0.32210410492760794  reward : -1\n",
            "game #num:  14791\n",
            "action not avaliable action<0,8> 2 , satae [0, 0, 1, 1, 1, -1, 0, -1, -1], mask [True, True, False, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [0, 0, 1, 1, 1, -1, 0, -1, -1], mask [True, True, False, False, False, False, True, False, False]\n",
            "mcts won  5290  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.11379062756896019 q value 0.32467488944530487  reward : -1\n",
            "game #num:  14792\n",
            "action not avaliable action<0,8> 8 , satae [0, 1, 0, -1, -1, 0, 0, 1, -1], mask [True, False, True, False, False, True, True, False, False]\n",
            "agent won  8051  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.1224166788160801 q value 0.32517698407173157  reward : 1\n",
            "game #num:  14793\n",
            "action not avaliable action<0,8> 4 , satae [0, -1, 1, -1, 1, -1, -1, 0, 1], mask [True, False, False, False, False, False, False, True, False]\n",
            "action not avaliable action<0,8> 1 , satae [0, -1, 1, -1, 1, -1, -1, 0, 1], mask [True, False, False, False, False, False, False, True, False]\n",
            "action not avaliable action<0,8> 4 , satae [0, -1, 1, -1, 1, -1, -1, 0, 1], mask [True, False, False, False, False, False, False, True, False]\n",
            "action not avaliable action<0,8> 6 , satae [0, -1, 1, -1, 1, -1, -1, 0, 1], mask [True, False, False, False, False, False, False, True, False]\n",
            "action not avaliable action<0,8> 4 , satae [0, -1, 1, -1, 1, -1, -1, 0, 1], mask [True, False, False, False, False, False, False, True, False]\n",
            "action not avaliable action<0,8> 6 , satae [0, -1, 1, -1, 1, -1, -1, 0, 1], mask [True, False, False, False, False, False, False, True, False]\n",
            "action not avaliable action<0,8> 3 , satae [0, -1, 1, -1, 1, -1, -1, 0, 1], mask [True, False, False, False, False, False, False, True, False]\n",
            "action not avaliable action<0,8> 3 , satae [0, -1, 1, -1, 1, -1, -1, 0, 1], mask [True, False, False, False, False, False, False, True, False]\n",
            "action not avaliable action<0,8> 3 , satae [0, -1, 1, -1, 1, -1, -1, 0, 1], mask [True, False, False, False, False, False, False, True, False]\n",
            "mcts won  5291  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.10942900238128808 q value 0.32347026008826035  reward : -1\n",
            "game #num:  14794\n",
            "action not avaliable action<0,8> 0 , satae [-1, 0, 0, 0, 0, 0, 0, 0, 0], mask [False, True, True, True, True, True, True, True, True]\n",
            "action not avaliable action<0,8> 0 , satae [-1, 0, 0, 0, 0, 0, 0, 0, 0], mask [False, True, True, True, True, True, True, True, True]\n",
            "mcts won  5292  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.10378183722496033 q value 0.325167191028595  reward : -1\n",
            "game #num:  14795\n",
            "action not avaliable action<0,8> 4 , satae [-1, 0, 0, 0, 1, 0, 0, 0, -1], mask [False, True, True, True, False, True, True, True, False]\n",
            "action not avaliable action<0,8> 8 , satae [-1, -1, 0, 0, 1, 1, 0, 0, -1], mask [False, False, True, True, False, False, True, True, False]\n",
            "mcts won  5293  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.12199969465533893 q value 0.32873133818308514  reward : -1\n",
            "game #num:  14796\n",
            "action not avaliable action<0,8> 0 , satae [-1, 0, 0, 0, 0, 0, 0, 1, 0], mask [False, True, True, True, True, True, True, False, True]\n",
            "action not avaliable action<0,8> 0 , satae [-1, 0, 0, 0, 0, 0, 0, 1, 0], mask [False, True, True, True, True, True, True, False, True]\n",
            "agent won  8052  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.11002009063959121 q value 0.32872381806373596  reward : 1\n",
            "game #num:  14797\n",
            "action not avaliable action<0,8> 8 , satae [0, 0, 0, 0, 0, 0, 0, 0, -1], mask [True, True, True, True, True, True, True, True, False]\n",
            "action not avaliable action<0,8> 8 , satae [0, 0, 0, 0, 0, 0, 0, 0, -1], mask [True, True, True, True, True, True, True, True, False]\n",
            "action not avaliable action<0,8> 8 , satae [0, 0, 0, 0, 0, 0, 0, 0, -1], mask [True, True, True, True, True, True, True, True, False]\n",
            "action not avaliable action<0,8> 8 , satae [0, 0, 0, 0, 0, 0, 0, 0, -1], mask [True, True, True, True, True, True, True, True, False]\n",
            "action not avaliable action<0,8> 2 , satae [0, 0, -1, 1, -1, 1, 0, 0, -1], mask [True, True, False, False, False, False, True, True, False]\n",
            "action not avaliable action<0,8> 3 , satae [0, 0, -1, 1, -1, 1, 0, 0, -1], mask [True, True, False, False, False, False, True, True, False]\n",
            "agent won  8053  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.12035640105605125 q value 0.3252748757600784  reward : 1\n",
            "game #num:  14798\n",
            "action not avaliable action<0,8> 1 , satae [1, -1, 0, 0, 0, 0, 0, 0, 0], mask [False, False, True, True, True, True, True, True, True]\n",
            "action not avaliable action<0,8> 0 , satae [1, -1, 0, 0, -1, 0, 0, 0, 1], mask [False, False, True, True, False, True, True, True, False]\n",
            "action not avaliable action<0,8> 0 , satae [1, -1, 0, 0, -1, 0, 0, 0, 1], mask [False, False, True, True, False, True, True, True, False]\n",
            "action not avaliable action<0,8> 1 , satae [1, -1, -1, 0, -1, 0, 1, 0, 1], mask [False, False, False, True, False, True, False, True, False]\n",
            "agent won  8054  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.11940825171768665 q value 0.3203454054892063  reward : 1\n",
            "game #num:  14799\n",
            "mcts won  5294  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.11397198587656021 q value 0.31819161772727966  reward : -1\n",
            "game #num:  14800\n",
            "action not avaliable action<0,8> 0 , satae [1, 0, -1, 0, 0, -1, 0, 0, 0], mask [False, True, False, True, True, False, True, True, True]\n",
            "action not avaliable action<0,8> 0 , satae [1, 0, -1, -1, 0, -1, 0, 0, 1], mask [False, True, False, False, True, False, True, True, False]\n",
            "action not avaliable action<0,8> 8 , satae [1, 0, -1, -1, 0, -1, 0, 0, 1], mask [False, True, False, False, True, False, True, True, False]\n",
            "action not avaliable action<0,8> 3 , satae [1, 0, -1, -1, 0, -1, 0, 0, 1], mask [False, True, False, False, True, False, True, True, False]\n",
            "action not avaliable action<0,8> 2 , satae [1, 0, -1, -1, 0, -1, 0, 0, 1], mask [False, True, False, False, True, False, True, True, False]\n",
            "action not avaliable action<0,8> 3 , satae [1, 0, -1, -1, 0, -1, 0, 0, 1], mask [False, True, False, False, True, False, True, True, False]\n",
            "mcts won  5295  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.1135151700841056 q value 0.3160309460428026  reward : -1\n",
            "game #num:  14801\n",
            "action not avaliable action<0,8> 8 , satae [0, 0, 0, 0, 0, -1, 0, -1, 1], mask [True, True, True, True, True, False, True, False, False]\n",
            "action not avaliable action<0,8> 0 , satae [1, -1, 0, 0, 0, -1, 0, -1, 1], mask [False, False, True, True, True, False, True, False, False]\n",
            "action not avaliable action<0,8> 0 , satae [1, -1, 0, 0, 0, -1, 0, -1, 1], mask [False, False, True, True, True, False, True, False, False]\n",
            "mcts won  5296  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.11572794492046039 q value 0.31396416823069256  reward : -1\n",
            "game #num:  14802\n",
            "mcts won  5297  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.11914882808923721 q value 0.31339965760707855  reward : -1\n",
            "game #num:  14803\n",
            "action not avaliable action<0,8> 6 , satae [0, 0, 0, 0, 0, -1, 1, 1, -1], mask [True, True, True, True, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [0, 0, 0, 0, 0, -1, 1, 1, -1], mask [True, True, True, True, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [0, 0, 0, 0, 0, -1, 1, 1, -1], mask [True, True, True, True, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 0 , satae [-1, 0, 1, 0, 0, -1, 1, 1, -1], mask [False, True, False, True, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 5 , satae [-1, 0, 1, 0, 0, -1, 1, 1, -1], mask [False, True, False, True, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [-1, 0, 1, 0, 0, -1, 1, 1, -1], mask [False, True, False, True, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 0 , satae [-1, 0, 1, 0, 0, -1, 1, 1, -1], mask [False, True, False, True, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [-1, 0, 1, 0, 0, -1, 1, 1, -1], mask [False, True, False, True, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 5 , satae [-1, 0, 1, 0, 0, -1, 1, 1, -1], mask [False, True, False, True, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [-1, 0, 1, 0, 0, -1, 1, 1, -1], mask [False, True, False, True, True, False, False, False, False]\n",
            "agent won  8055  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.11018538155726024 q value 0.31251807297979084  reward : 1\n",
            "game #num:  14804\n",
            "action not avaliable action<0,8> 7 , satae [0, -1, 1, 0, 0, 0, 0, -1, 0], mask [True, False, False, True, True, True, True, False, True]\n",
            "mcts won  5298  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.11510081340869267 q value 0.3122008840243022  reward : -1\n",
            "game #num:  14805\n",
            "action not avaliable action<0,8> 1 , satae [0, 1, 0, 0, -1, 0, 0, -1, 0], mask [True, False, True, True, False, True, True, False, True]\n",
            "action not avaliable action<0,8> 1 , satae [0, 1, 0, 0, -1, 0, 0, -1, 0], mask [True, False, True, True, False, True, True, False, True]\n",
            "agent won  8056  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.09754457771778106 q value 0.3125786066055298  reward : 1\n",
            "game #num:  14806\n",
            "action not avaliable action<0,8> 1 , satae [1, -1, 0, 1, 0, -1, -1, 0, 0], mask [False, False, True, False, True, False, False, True, True]\n",
            "action not avaliable action<0,8> 1 , satae [1, -1, 0, 1, 0, -1, -1, 0, 0], mask [False, False, True, False, True, False, False, True, True]\n",
            "action not avaliable action<0,8> 2 , satae [1, -1, 1, 1, 0, -1, -1, -1, 0], mask [False, False, False, False, True, False, False, False, True]\n",
            "action not avaliable action<0,8> 3 , satae [1, -1, 1, 1, 0, -1, -1, -1, 0], mask [False, False, False, False, True, False, False, False, True]\n",
            "action not avaliable action<0,8> 6 , satae [1, -1, 1, 1, 0, -1, -1, -1, 0], mask [False, False, False, False, True, False, False, False, True]\n",
            "action not avaliable action<0,8> 1 , satae [1, -1, 1, 1, 0, -1, -1, -1, 0], mask [False, False, False, False, True, False, False, False, True]\n",
            "action not avaliable action<0,8> 7 , satae [1, -1, 1, 1, 0, -1, -1, -1, 0], mask [False, False, False, False, True, False, False, False, True]\n",
            "action not avaliable action<0,8> 6 , satae [1, -1, 1, 1, 0, -1, -1, -1, 0], mask [False, False, False, False, True, False, False, False, True]\n",
            "agent won  8057  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.10386953316628933 q value 0.3169414202372233  reward : 1\n",
            "game #num:  14807\n",
            "mcts won  5299  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.11634007096290588 q value 0.3214859863122304  reward : -1\n",
            "game #num:  14808\n",
            "action not avaliable action<0,8> 8 , satae [0, 0, 0, -1, 1, -1, 0, 1, -1], mask [True, True, True, False, False, False, True, False, False]\n",
            "mcts won  5300  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.1054898239672184 q value 0.32286644726991653  reward : -1\n",
            "game #num:  14809\n",
            "agent won  8058  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.11047547807296117 q value 0.3247129023075104  reward : 1\n",
            "game #num:  14810\n",
            "action not avaliable action<0,8> 5 , satae [0, 0, 0, -1, 1, -1, 0, 0, 0], mask [True, True, True, False, False, False, True, True, True]\n",
            "action not avaliable action<0,8> 3 , satae [0, 0, 0, -1, 1, -1, -1, 1, 0], mask [True, True, True, False, False, False, False, False, True]\n",
            "agent won  8059  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.11657854765653611 q value 0.3254275619983673  reward : 1\n",
            "game #num:  14811\n",
            "mcts won  5301  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.11169688031077385 q value 0.3259778171777725  reward : -1\n",
            "game #num:  14812\n",
            "action not avaliable action<0,8> 2 , satae [0, 0, 1, -1, 0, 0, -1, 1, 0], mask [True, True, False, False, True, True, False, False, True]\n",
            "action not avaliable action<0,8> 4 , satae [1, -1, 1, -1, 1, 0, -1, 1, -1], mask [False, False, False, False, False, True, False, False, False]\n",
            "action not avaliable action<0,8> 2 , satae [1, -1, 1, -1, 1, 0, -1, 1, -1], mask [False, False, False, False, False, True, False, False, False]\n",
            "draw  1452  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0]\n",
            "################################################################################################\n",
            "game loss:  0.10602748487144709 q value 0.3265243396162987  reward : 0\n",
            "game #num:  14813\n",
            "action not avaliable action<0,8> 6 , satae [0, -1, 0, 0, -1, -1, 1, 1, 0], mask [True, False, True, True, False, False, False, False, True]\n",
            "action not avaliable action<0,8> 7 , satae [0, -1, 0, 0, -1, -1, 1, 1, 0], mask [True, False, True, True, False, False, False, False, True]\n",
            "action not avaliable action<0,8> 6 , satae [1, -1, 0, 0, -1, -1, 1, 1, -1], mask [False, False, True, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 4 , satae [1, -1, 0, 0, -1, -1, 1, 1, -1], mask [False, False, True, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [1, -1, 0, 0, -1, -1, 1, 1, -1], mask [False, False, True, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [1, -1, 0, 0, -1, -1, 1, 1, -1], mask [False, False, True, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [1, -1, 0, 0, -1, -1, 1, 1, -1], mask [False, False, True, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 0 , satae [1, -1, 0, 0, -1, -1, 1, 1, -1], mask [False, False, True, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 4 , satae [1, -1, 0, 0, -1, -1, 1, 1, -1], mask [False, False, True, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 1 , satae [1, -1, 0, 0, -1, -1, 1, 1, -1], mask [False, False, True, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [1, -1, 0, 0, -1, -1, 1, 1, -1], mask [False, False, True, True, False, False, False, False, False]\n",
            "agent won  8060  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.11810247550408046 q value 0.3250008682409922  reward : 1\n",
            "game #num:  14814\n",
            "agent won  8061  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.10975632816553116 q value 0.31920780539512633  reward : 1\n",
            "game #num:  14815\n",
            "action not avaliable action<0,8> 6 , satae [-1, -1, 0, 1, 0, 0, 1, -1, 0], mask [False, False, True, False, True, True, False, False, True]\n",
            "action not avaliable action<0,8> 0 , satae [-1, -1, 0, 1, 0, 0, 1, -1, 0], mask [False, False, True, False, True, True, False, False, True]\n",
            "action not avaliable action<0,8> 7 , satae [-1, -1, 1, 1, 0, 0, 1, -1, -1], mask [False, False, False, False, True, True, False, False, False]\n",
            "action not avaliable action<0,8> 3 , satae [-1, -1, 1, 1, 0, 0, 1, -1, -1], mask [False, False, False, False, True, True, False, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [-1, -1, 1, 1, 0, 0, 1, -1, -1], mask [False, False, False, False, True, True, False, False, False]\n",
            "mcts won  5302  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.11605389664570491 q value 0.3149992028872172  reward : -1\n",
            "game #num:  14816\n",
            "agent won  8062  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.10440516223510106 q value 0.3142266273498535  reward : 1\n",
            "game #num:  14817\n",
            "action not avaliable action<0,8> 7 , satae [-1, 0, -1, 0, 0, 0, 0, 1, 0], mask [False, True, False, True, True, True, True, False, True]\n",
            "action not avaliable action<0,8> 0 , satae [-1, 1, -1, 0, -1, 0, 0, 1, 0], mask [False, False, False, True, False, True, True, False, True]\n",
            "action not avaliable action<0,8> 4 , satae [-1, 1, -1, -1, -1, 0, 1, 1, 0], mask [False, False, False, False, False, True, False, False, True]\n",
            "agent won  8063  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.11557907717568534 q value 0.31644452043942045  reward : 1\n",
            "game #num:  14818\n",
            "action not avaliable action<0,8> 6 , satae [0, 0, 0, -1, 0, 0, -1, 1, 0], mask [True, True, True, False, True, True, False, False, True]\n",
            "agent won  8064  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.12407498806715012 q value 0.31829509884119034  reward : 1\n",
            "game #num:  14819\n",
            "action not avaliable action<0,8> 5 , satae [-1, 0, 0, 0, 0, 1, 0, 0, 0], mask [False, True, True, True, True, False, True, True, True]\n",
            "action not avaliable action<0,8> 8 , satae [-1, 0, 0, 0, 0, 1, 0, 1, -1], mask [False, True, True, True, True, False, True, False, False]\n",
            "mcts won  5303  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.11693573296070099 q value 0.3179475724697113  reward : -1\n",
            "game #num:  14820\n",
            "action not avaliable action<0,8> 1 , satae [0, -1, 0, 1, 0, 0, 0, 0, 0], mask [True, False, True, False, True, True, True, True, True]\n",
            "action not avaliable action<0,8> 1 , satae [0, -1, 0, 1, 0, 0, 0, 0, 0], mask [True, False, True, False, True, True, True, True, True]\n",
            "agent won  8065  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.11413666481773059 q value 0.3161222040653229  reward : 1\n",
            "game #num:  14821\n",
            "action not avaliable action<0,8> 1 , satae [0, -1, 0, 0, 1, 0, 0, 0, 0], mask [True, False, True, True, False, True, True, True, True]\n",
            "action not avaliable action<0,8> 5 , satae [-1, -1, 1, 0, 1, 1, 0, 0, -1], mask [False, False, False, True, False, False, True, True, False]\n",
            "action not avaliable action<0,8> 1 , satae [-1, -1, 1, 0, 1, 1, 0, 0, -1], mask [False, False, False, True, False, False, True, True, False]\n",
            "action not avaliable action<0,8> 8 , satae [-1, -1, 1, 0, 1, 1, 0, 0, -1], mask [False, False, False, True, False, False, True, True, False]\n",
            "action not avaliable action<0,8> 8 , satae [-1, -1, 1, 0, 1, 1, 0, 0, -1], mask [False, False, False, True, False, False, True, True, False]\n",
            "mcts won  5304  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.11093887852297889 q value 0.3128196464644538  reward : -1\n",
            "game #num:  14822\n",
            "action not avaliable action<0,8> 7 , satae [0, 0, -1, 0, 0, 0, 0, 1, 0], mask [True, True, False, True, True, True, True, False, True]\n",
            "agent won  8066  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.0982909306883812 q value 0.3118741512298584  reward : 1\n",
            "game #num:  14823\n",
            "action not avaliable action<0,8> 8 , satae [0, 0, 0, 0, 0, 0, 0, 0, -1], mask [True, True, True, True, True, True, True, True, False]\n",
            "agent won  8067  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.12367748618125915 q value 0.31374292373657225  reward : 1\n",
            "game #num:  14824\n",
            "action not avaliable action<0,8> 2 , satae [0, 0, 1, 1, 0, -1, -1, 0, -1], mask [True, True, False, False, True, False, False, True, False]\n",
            "action not avaliable action<0,8> 2 , satae [0, 0, 1, 1, 0, -1, -1, 0, -1], mask [True, True, False, False, True, False, False, True, False]\n",
            "action not avaliable action<0,8> 3 , satae [0, 0, 1, 1, 0, -1, -1, 0, -1], mask [True, True, False, False, True, False, False, True, False]\n",
            "action not avaliable action<0,8> 8 , satae [-1, 0, 1, 1, 0, -1, -1, 1, -1], mask [False, True, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [-1, 0, 1, 1, 0, -1, -1, 1, -1], mask [False, True, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 3 , satae [-1, 0, 1, 1, 0, -1, -1, 1, -1], mask [False, True, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [-1, 0, 1, 1, 0, -1, -1, 1, -1], mask [False, True, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 5 , satae [-1, 0, 1, 1, 0, -1, -1, 1, -1], mask [False, True, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 3 , satae [-1, 0, 1, 1, 0, -1, -1, 1, -1], mask [False, True, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 3 , satae [-1, 0, 1, 1, 0, -1, -1, 1, -1], mask [False, True, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [-1, 0, 1, 1, 0, -1, -1, 1, -1], mask [False, True, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 3 , satae [-1, 0, 1, 1, 0, -1, -1, 1, -1], mask [False, True, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [-1, 0, 1, 1, 0, -1, -1, 1, -1], mask [False, True, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 2 , satae [-1, 0, 1, 1, 0, -1, -1, 1, -1], mask [False, True, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [-1, 0, 1, 1, 0, -1, -1, 1, -1], mask [False, True, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 3 , satae [-1, 0, 1, 1, 0, -1, -1, 1, -1], mask [False, True, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [-1, 0, 1, 1, 0, -1, -1, 1, -1], mask [False, True, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 3 , satae [-1, 0, 1, 1, 0, -1, -1, 1, -1], mask [False, True, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [-1, 0, 1, 1, 0, -1, -1, 1, -1], mask [False, True, False, False, True, False, False, False, False]\n",
            "agent won  8068  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.11286179041085036 q value 0.3189223525316819  reward : 1\n",
            "game #num:  14825\n",
            "action not avaliable action<0,8> 7 , satae [0, 0, 0, 0, 1, 0, 0, -1, 0], mask [True, True, True, True, False, True, True, False, True]\n",
            "action not avaliable action<0,8> 6 , satae [0, -1, 0, 0, 1, 0, 1, -1, 0], mask [True, False, True, True, False, True, False, False, True]\n",
            "action not avaliable action<0,8> 6 , satae [0, -1, 0, 0, 1, 0, 1, -1, 0], mask [True, False, True, True, False, True, False, False, True]\n",
            "action not avaliable action<0,8> 6 , satae [1, -1, 0, -1, 1, 0, 1, -1, 0], mask [False, False, True, False, False, True, False, False, True]\n",
            "action not avaliable action<0,8> 3 , satae [1, -1, 0, -1, 1, 0, 1, -1, 0], mask [False, False, True, False, False, True, False, False, True]\n",
            "action not avaliable action<0,8> 1 , satae [1, -1, 0, -1, 1, 0, 1, -1, 0], mask [False, False, True, False, False, True, False, False, True]\n",
            "agent won  8069  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.11007236018776893 q value 0.3275304287672043  reward : 1\n",
            "game #num:  14826\n",
            "action not avaliable action<0,8> 4 , satae [1, 0, 0, 0, -1, -1, 0, 0, 0], mask [False, True, True, True, False, False, True, True, True]\n",
            "action not avaliable action<0,8> 0 , satae [1, 0, 0, 0, -1, -1, 0, 0, 0], mask [False, True, True, True, False, False, True, True, True]\n",
            "action not avaliable action<0,8> 0 , satae [1, 0, 0, 0, -1, -1, 0, 0, 0], mask [False, True, True, True, False, False, True, True, True]\n",
            "action not avaliable action<0,8> 4 , satae [1, 0, 0, 0, -1, -1, 0, 0, 0], mask [False, True, True, True, False, False, True, True, True]\n",
            "action not avaliable action<0,8> 0 , satae [1, 0, 0, 0, -1, -1, 0, 0, 0], mask [False, True, True, True, False, False, True, True, True]\n",
            "action not avaliable action<0,8> 4 , satae [1, 0, 0, 0, -1, -1, 0, 0, 0], mask [False, True, True, True, False, False, True, True, True]\n",
            "action not avaliable action<0,8> 2 , satae [1, -1, 1, 0, -1, -1, 1, 0, -1], mask [False, False, False, True, False, False, False, True, False]\n",
            "action not avaliable action<0,8> 8 , satae [1, -1, 1, 0, -1, -1, 1, 0, -1], mask [False, False, False, True, False, False, False, True, False]\n",
            "action not avaliable action<0,8> 6 , satae [1, -1, 1, 0, -1, -1, 1, 0, -1], mask [False, False, False, True, False, False, False, True, False]\n",
            "agent won  8070  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.10893239825963974 q value 0.3286111561151651  reward : 1\n",
            "game #num:  14827\n",
            "action not avaliable action<0,8> 8 , satae [0, 0, 0, -1, 0, 0, 0, 1, -1], mask [True, True, True, False, True, True, True, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [0, 0, 0, -1, 0, 0, 0, 1, -1], mask [True, True, True, False, True, True, True, False, False]\n",
            "action not avaliable action<0,8> 3 , satae [0, 0, 0, -1, 0, 0, 0, 1, -1], mask [True, True, True, False, True, True, True, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [0, 0, 0, -1, 0, 0, 0, 1, -1], mask [True, True, True, False, True, True, True, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [0, 0, 0, -1, 0, 0, 0, 1, -1], mask [True, True, True, False, True, True, True, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [0, 0, 0, -1, 0, 0, 0, 1, -1], mask [True, True, True, False, True, True, True, False, False]\n",
            "mcts won  5305  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.11202010346783532 q value 0.32638821999231976  reward : -1\n",
            "game #num:  14828\n",
            "action not avaliable action<0,8> 6 , satae [1, -1, 1, 0, 0, -1, -1, 0, 0], mask [False, False, False, True, True, False, False, True, True]\n",
            "action not avaliable action<0,8> 7 , satae [1, -1, 1, -1, 0, -1, -1, 1, 0], mask [False, False, False, False, True, False, False, False, True]\n",
            "action not avaliable action<0,8> 7 , satae [1, -1, 1, -1, 0, -1, -1, 1, 0], mask [False, False, False, False, True, False, False, False, True]\n",
            "action not avaliable action<0,8> 2 , satae [1, -1, 1, -1, 0, -1, -1, 1, 0], mask [False, False, False, False, True, False, False, False, True]\n",
            "action not avaliable action<0,8> 6 , satae [1, -1, 1, -1, 0, -1, -1, 1, 0], mask [False, False, False, False, True, False, False, False, True]\n",
            "action not avaliable action<0,8> 3 , satae [1, -1, 1, -1, 0, -1, -1, 1, 0], mask [False, False, False, False, True, False, False, False, True]\n",
            "action not avaliable action<0,8> 0 , satae [1, -1, 1, -1, 0, -1, -1, 1, 0], mask [False, False, False, False, True, False, False, False, True]\n",
            "action not avaliable action<0,8> 6 , satae [1, -1, 1, -1, 0, -1, -1, 1, 0], mask [False, False, False, False, True, False, False, False, True]\n",
            "action not avaliable action<0,8> 7 , satae [1, -1, 1, -1, 0, -1, -1, 1, 0], mask [False, False, False, False, True, False, False, False, True]\n",
            "action not avaliable action<0,8> 5 , satae [1, -1, 1, -1, 0, -1, -1, 1, 0], mask [False, False, False, False, True, False, False, False, True]\n",
            "action not avaliable action<0,8> 5 , satae [1, -1, 1, -1, 0, -1, -1, 1, 0], mask [False, False, False, False, True, False, False, False, True]\n",
            "action not avaliable action<0,8> 2 , satae [1, -1, 1, -1, 0, -1, -1, 1, 0], mask [False, False, False, False, True, False, False, False, True]\n",
            "action not avaliable action<0,8> 7 , satae [1, -1, 1, -1, 0, -1, -1, 1, 0], mask [False, False, False, False, True, False, False, False, True]\n",
            "action not avaliable action<0,8> 0 , satae [1, -1, 1, -1, 0, -1, -1, 1, 0], mask [False, False, False, False, True, False, False, False, True]\n",
            "action not avaliable action<0,8> 7 , satae [1, -1, 1, -1, 0, -1, -1, 1, 0], mask [False, False, False, False, True, False, False, False, True]\n",
            "action not avaliable action<0,8> 6 , satae [1, -1, 1, -1, 0, -1, -1, 1, 0], mask [False, False, False, False, True, False, False, False, True]\n",
            "action not avaliable action<0,8> 6 , satae [1, -1, 1, -1, 0, -1, -1, 1, 0], mask [False, False, False, False, True, False, False, False, True]\n",
            "action not avaliable action<0,8> 5 , satae [1, -1, 1, -1, 0, -1, -1, 1, 0], mask [False, False, False, False, True, False, False, False, True]\n",
            "action not avaliable action<0,8> 2 , satae [1, -1, 1, -1, 0, -1, -1, 1, 0], mask [False, False, False, False, True, False, False, False, True]\n",
            "action not avaliable action<0,8> 1 , satae [1, -1, 1, -1, 0, -1, -1, 1, 0], mask [False, False, False, False, True, False, False, False, True]\n",
            "action not avaliable action<0,8> 2 , satae [1, -1, 1, -1, 0, -1, -1, 1, 0], mask [False, False, False, False, True, False, False, False, True]\n",
            "action not avaliable action<0,8> 0 , satae [1, -1, 1, -1, 0, -1, -1, 1, 0], mask [False, False, False, False, True, False, False, False, True]\n",
            "action not avaliable action<0,8> 1 , satae [1, -1, 1, -1, 0, -1, -1, 1, 0], mask [False, False, False, False, True, False, False, False, True]\n",
            "action not avaliable action<0,8> 2 , satae [1, -1, 1, -1, 0, -1, -1, 1, 0], mask [False, False, False, False, True, False, False, False, True]\n",
            "mcts won  5306  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.10683947508888585 q value 0.32392662657158716  reward : -1\n",
            "game #num:  14829\n",
            "agent won  8071  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.12036895751953125 q value 0.32483360916376114  reward : 1\n",
            "game #num:  14830\n",
            "action not avaliable action<0,8> 6 , satae [0, -1, 0, -1, 0, 0, 1, 1, 0], mask [True, False, True, False, True, True, False, False, True]\n",
            "action not avaliable action<0,8> 3 , satae [0, -1, 0, -1, 0, 0, 1, 1, 0], mask [True, False, True, False, True, True, False, False, True]\n",
            "action not avaliable action<0,8> 7 , satae [0, -1, 0, -1, 0, 0, 1, 1, 0], mask [True, False, True, False, True, True, False, False, True]\n",
            "action not avaliable action<0,8> 6 , satae [0, -1, 0, -1, 0, 0, 1, 1, 0], mask [True, False, True, False, True, True, False, False, True]\n",
            "action not avaliable action<0,8> 6 , satae [0, -1, 0, -1, 0, 0, 1, 1, 0], mask [True, False, True, False, True, True, False, False, True]\n",
            "mcts won  5307  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.11304274201393127 q value 0.3232007883489132  reward : -1\n",
            "game #num:  14831\n",
            "action not avaliable action<0,8> 3 , satae [0, -1, -1, 1, -1, 1, 1, 0, 0], mask [True, False, False, False, False, False, False, True, True]\n",
            "action not avaliable action<0,8> 6 , satae [0, -1, -1, 1, -1, 1, 1, 0, 0], mask [True, False, False, False, False, False, False, True, True]\n",
            "action not avaliable action<0,8> 2 , satae [0, -1, -1, 1, -1, 1, 1, 0, 0], mask [True, False, False, False, False, False, False, True, True]\n",
            "action not avaliable action<0,8> 5 , satae [0, -1, -1, 1, -1, 1, 1, 0, 0], mask [True, False, False, False, False, False, False, True, True]\n",
            "action not avaliable action<0,8> 1 , satae [0, -1, -1, 1, -1, 1, 1, 0, 0], mask [True, False, False, False, False, False, False, True, True]\n",
            "action not avaliable action<0,8> 6 , satae [0, -1, -1, 1, -1, 1, 1, 1, -1], mask [True, False, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 2 , satae [0, -1, -1, 1, -1, 1, 1, 1, -1], mask [True, False, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [0, -1, -1, 1, -1, 1, 1, 1, -1], mask [True, False, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 5 , satae [0, -1, -1, 1, -1, 1, 1, 1, -1], mask [True, False, False, False, False, False, False, False, False]\n",
            "agent won  8072  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.11098374107054301 q value 0.3248495267970221  reward : 1\n",
            "game #num:  14832\n",
            "action not avaliable action<0,8> 5 , satae [0, 0, -1, 1, 0, 1, -1, -1, 0], mask [True, True, False, False, True, False, False, False, True]\n",
            "mcts won  5308  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.12026306800544262 q value 0.32726404070854187  reward : -1\n",
            "game #num:  14833\n",
            "action not avaliable action<0,8> 6 , satae [0, 0, 0, 0, 1, 0, -1, 0, 0], mask [True, True, True, True, False, True, False, True, True]\n",
            "action not avaliable action<0,8> 7 , satae [1, 1, -1, 0, 1, 0, -1, -1, 0], mask [False, False, False, True, False, True, False, False, True]\n",
            "agent won  8073  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.11361472681164742 q value 0.3255498657623927  reward : 1\n",
            "game #num:  14834\n",
            "action not avaliable action<0,8> 7 , satae [0, 0, -1, 1, 0, 0, 0, -1, 0], mask [True, True, False, False, True, True, True, False, True]\n",
            "action not avaliable action<0,8> 5 , satae [-1, 0, -1, 1, 0, 1, 0, -1, 0], mask [False, True, False, False, True, False, True, False, True]\n",
            "action not avaliable action<0,8> 3 , satae [-1, 0, -1, 1, 0, 1, 0, -1, 0], mask [False, True, False, False, True, False, True, False, True]\n",
            "action not avaliable action<0,8> 5 , satae [-1, 0, -1, 1, 0, 1, 0, -1, 0], mask [False, True, False, False, True, False, True, False, True]\n",
            "agent won  8074  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.10567731410264969 q value 0.3222728797367641  reward : 1\n",
            "game #num:  14835\n",
            "action not avaliable action<0,8> 7 , satae [0, 0, 1, 0, 0, 0, 0, -1, 0], mask [True, True, False, True, True, True, True, False, True]\n",
            "action not avaliable action<0,8> 7 , satae [0, 0, 1, 0, 0, 0, 0, -1, 0], mask [True, True, False, True, True, True, True, False, True]\n",
            "action not avaliable action<0,8> 3 , satae [0, 0, 1, 1, 0, -1, 0, -1, 0], mask [True, True, False, False, True, False, True, False, True]\n",
            "action not avaliable action<0,8> 7 , satae [0, 0, 1, 1, 0, -1, 0, -1, 0], mask [True, True, False, False, True, False, True, False, True]\n",
            "action not avaliable action<0,8> 7 , satae [0, 0, 1, 1, 0, -1, 0, -1, 0], mask [True, True, False, False, True, False, True, False, True]\n",
            "action not avaliable action<0,8> 5 , satae [0, 0, 1, 1, 0, -1, 0, -1, 0], mask [True, True, False, False, True, False, True, False, True]\n",
            "action not avaliable action<0,8> 3 , satae [-1, 0, 1, 1, 0, -1, 0, -1, 1], mask [False, True, False, False, True, False, True, False, False]\n",
            "action not avaliable action<0,8> 5 , satae [-1, 0, 1, 1, 0, -1, 0, -1, 1], mask [False, True, False, False, True, False, True, False, False]\n",
            "action not avaliable action<0,8> 2 , satae [-1, 0, 1, 1, 0, -1, 0, -1, 1], mask [False, True, False, False, True, False, True, False, False]\n",
            "action not avaliable action<0,8> 2 , satae [-1, 0, 1, 1, 0, -1, 0, -1, 1], mask [False, True, False, False, True, False, True, False, False]\n",
            "action not avaliable action<0,8> 2 , satae [-1, 1, 1, 1, -1, -1, 0, -1, 1], mask [False, False, False, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 1 , satae [-1, 1, 1, 1, -1, -1, 0, -1, 1], mask [False, False, False, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [-1, 1, 1, 1, -1, -1, 0, -1, 1], mask [False, False, False, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 1 , satae [-1, 1, 1, 1, -1, -1, 0, -1, 1], mask [False, False, False, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [-1, 1, 1, 1, -1, -1, 0, -1, 1], mask [False, False, False, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [-1, 1, 1, 1, -1, -1, 0, -1, 1], mask [False, False, False, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 5 , satae [-1, 1, 1, 1, -1, -1, 0, -1, 1], mask [False, False, False, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 1 , satae [-1, 1, 1, 1, -1, -1, 0, -1, 1], mask [False, False, False, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 5 , satae [-1, 1, 1, 1, -1, -1, 0, -1, 1], mask [False, False, False, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 1 , satae [-1, 1, 1, 1, -1, -1, 0, -1, 1], mask [False, False, False, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 5 , satae [-1, 1, 1, 1, -1, -1, 0, -1, 1], mask [False, False, False, False, False, False, True, False, False]\n",
            "draw  1453  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "################################################################################################\n",
            "game loss:  0.11460364438020267 q value 0.3199127981295952  reward : 0\n",
            "game #num:  14836\n",
            "mcts won  5309  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.1125030666589737 q value 0.31696876883506775  reward : -1\n",
            "game #num:  14837\n",
            "action not avaliable action<0,8> 5 , satae [-1, 0, -1, 0, 0, 1, 0, -1, 1], mask [False, True, False, True, True, False, True, False, False]\n",
            "action not avaliable action<0,8> 5 , satae [-1, 0, -1, 0, 0, 1, 0, -1, 1], mask [False, True, False, True, True, False, True, False, False]\n",
            "action not avaliable action<0,8> 2 , satae [-1, 0, -1, 0, 0, 1, 0, -1, 1], mask [False, True, False, True, True, False, True, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [-1, 0, -1, 0, -1, 1, 1, -1, 1], mask [False, True, False, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [-1, 0, -1, 0, -1, 1, 1, -1, 1], mask [False, True, False, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [-1, 0, -1, 0, -1, 1, 1, -1, 1], mask [False, True, False, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 0 , satae [-1, 0, -1, 0, -1, 1, 1, -1, 1], mask [False, True, False, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [-1, 0, -1, 0, -1, 1, 1, -1, 1], mask [False, True, False, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [-1, 0, -1, 0, -1, 1, 1, -1, 1], mask [False, True, False, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 0 , satae [-1, 0, -1, 0, -1, 1, 1, -1, 1], mask [False, True, False, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 4 , satae [-1, 0, -1, 0, -1, 1, 1, -1, 1], mask [False, True, False, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [-1, 0, -1, 0, -1, 1, 1, -1, 1], mask [False, True, False, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [-1, 0, -1, 0, -1, 1, 1, -1, 1], mask [False, True, False, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [-1, 0, -1, 0, -1, 1, 1, -1, 1], mask [False, True, False, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [-1, 0, -1, 0, -1, 1, 1, -1, 1], mask [False, True, False, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 2 , satae [-1, 0, -1, 0, -1, 1, 1, -1, 1], mask [False, True, False, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [-1, 0, -1, 0, -1, 1, 1, -1, 1], mask [False, True, False, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 2 , satae [-1, 0, -1, 0, -1, 1, 1, -1, 1], mask [False, True, False, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [-1, 0, -1, 0, -1, 1, 1, -1, 1], mask [False, True, False, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [-1, 0, -1, 0, -1, 1, 1, -1, 1], mask [False, True, False, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 0 , satae [-1, 0, -1, 0, -1, 1, 1, -1, 1], mask [False, True, False, True, False, False, False, False, False]\n",
            "draw  1454  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "################################################################################################\n",
            "game loss:  0.11497850209474564 q value 0.3169366562366486  reward : 0\n",
            "game #num:  14838\n",
            "action not avaliable action<0,8> 8 , satae [0, 1, 1, 0, -1, 0, 0, 0, -1], mask [True, False, False, True, False, True, True, True, False]\n",
            "action not avaliable action<0,8> 4 , satae [0, 1, 1, 0, -1, 0, 0, 0, -1], mask [True, False, False, True, False, True, True, True, False]\n",
            "action not avaliable action<0,8> 4 , satae [0, 1, 1, 0, -1, 0, 0, 0, -1], mask [True, False, False, True, False, True, True, True, False]\n",
            "action not avaliable action<0,8> 2 , satae [0, 1, 1, 1, -1, -1, -1, 1, -1], mask [True, False, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 3 , satae [0, 1, 1, 1, -1, -1, -1, 1, -1], mask [True, False, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 2 , satae [0, 1, 1, 1, -1, -1, -1, 1, -1], mask [True, False, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [0, 1, 1, 1, -1, -1, -1, 1, -1], mask [True, False, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 2 , satae [0, 1, 1, 1, -1, -1, -1, 1, -1], mask [True, False, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 5 , satae [0, 1, 1, 1, -1, -1, -1, 1, -1], mask [True, False, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 4 , satae [0, 1, 1, 1, -1, -1, -1, 1, -1], mask [True, False, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [0, 1, 1, 1, -1, -1, -1, 1, -1], mask [True, False, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [0, 1, 1, 1, -1, -1, -1, 1, -1], mask [True, False, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 5 , satae [0, 1, 1, 1, -1, -1, -1, 1, -1], mask [True, False, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 4 , satae [0, 1, 1, 1, -1, -1, -1, 1, -1], mask [True, False, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 1 , satae [0, 1, 1, 1, -1, -1, -1, 1, -1], mask [True, False, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [0, 1, 1, 1, -1, -1, -1, 1, -1], mask [True, False, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [0, 1, 1, 1, -1, -1, -1, 1, -1], mask [True, False, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 1 , satae [0, 1, 1, 1, -1, -1, -1, 1, -1], mask [True, False, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [0, 1, 1, 1, -1, -1, -1, 1, -1], mask [True, False, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 4 , satae [0, 1, 1, 1, -1, -1, -1, 1, -1], mask [True, False, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [0, 1, 1, 1, -1, -1, -1, 1, -1], mask [True, False, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 4 , satae [0, 1, 1, 1, -1, -1, -1, 1, -1], mask [True, False, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [0, 1, 1, 1, -1, -1, -1, 1, -1], mask [True, False, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 1 , satae [0, 1, 1, 1, -1, -1, -1, 1, -1], mask [True, False, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 1 , satae [0, 1, 1, 1, -1, -1, -1, 1, -1], mask [True, False, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [0, 1, 1, 1, -1, -1, -1, 1, -1], mask [True, False, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [0, 1, 1, 1, -1, -1, -1, 1, -1], mask [True, False, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 5 , satae [0, 1, 1, 1, -1, -1, -1, 1, -1], mask [True, False, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 2 , satae [0, 1, 1, 1, -1, -1, -1, 1, -1], mask [True, False, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 1 , satae [0, 1, 1, 1, -1, -1, -1, 1, -1], mask [True, False, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 3 , satae [0, 1, 1, 1, -1, -1, -1, 1, -1], mask [True, False, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [0, 1, 1, 1, -1, -1, -1, 1, -1], mask [True, False, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [0, 1, 1, 1, -1, -1, -1, 1, -1], mask [True, False, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 3 , satae [0, 1, 1, 1, -1, -1, -1, 1, -1], mask [True, False, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 2 , satae [0, 1, 1, 1, -1, -1, -1, 1, -1], mask [True, False, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 5 , satae [0, 1, 1, 1, -1, -1, -1, 1, -1], mask [True, False, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 4 , satae [0, 1, 1, 1, -1, -1, -1, 1, -1], mask [True, False, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 4 , satae [0, 1, 1, 1, -1, -1, -1, 1, -1], mask [True, False, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [0, 1, 1, 1, -1, -1, -1, 1, -1], mask [True, False, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 3 , satae [0, 1, 1, 1, -1, -1, -1, 1, -1], mask [True, False, False, False, False, False, False, False, False]\n",
            "agent won  8075  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.1123822776807679 q value 0.32046047581566706  reward : 1\n",
            "game #num:  14839\n",
            "mcts won  5310  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.12792755290865898 q value 0.32396700978279114  reward : -1\n",
            "game #num:  14840\n",
            "action not avaliable action<0,8> 1 , satae [1, 1, 0, -1, 0, 1, -1, 0, -1], mask [False, False, True, False, True, False, False, True, False]\n",
            "action not avaliable action<0,8> 3 , satae [1, 1, 0, -1, 0, 1, -1, 0, -1], mask [False, False, True, False, True, False, False, True, False]\n",
            "action not avaliable action<0,8> 1 , satae [1, 1, -1, -1, 0, 1, -1, 1, -1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 3 , satae [1, 1, -1, -1, 0, 1, -1, 1, -1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 0 , satae [1, 1, -1, -1, 0, 1, -1, 1, -1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 2 , satae [1, 1, -1, -1, 0, 1, -1, 1, -1], mask [False, False, False, False, True, False, False, False, False]\n",
            "agent won  8076  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.1121919100934809 q value 0.3231886381452734  reward : 1\n",
            "game #num:  14841\n",
            "action not avaliable action<0,8> 2 , satae [0, 0, -1, -1, 1, 1, 1, -1, -1], mask [True, True, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 5 , satae [0, 0, -1, -1, 1, 1, 1, -1, -1], mask [True, True, False, False, False, False, False, False, False]\n",
            "draw  1455  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0]\n",
            "################################################################################################\n",
            "game loss:  0.10344481344024341 q value 0.32230062286059064  reward : 0\n",
            "game #num:  14842\n",
            "action not avaliable action<0,8> 6 , satae [1, 0, 0, 0, -1, -1, 1, 1, -1], mask [False, True, True, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [1, 0, 0, 0, -1, -1, 1, 1, -1], mask [False, True, True, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [1, 0, 0, 0, -1, -1, 1, 1, -1], mask [False, True, True, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 4 , satae [1, 0, 0, 0, -1, -1, 1, 1, -1], mask [False, True, True, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 5 , satae [1, 0, 0, 0, -1, -1, 1, 1, -1], mask [False, True, True, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [1, 0, 0, 0, -1, -1, 1, 1, -1], mask [False, True, True, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [1, 0, 0, 0, -1, -1, 1, 1, -1], mask [False, True, True, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [1, 0, 0, 0, -1, -1, 1, 1, -1], mask [False, True, True, True, False, False, False, False, False]\n",
            "mcts won  5311  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.11070041668911774 q value 0.3267514407634735  reward : -1\n",
            "game #num:  14843\n",
            "action not avaliable action<0,8> 8 , satae [1, -1, 0, -1, 1, 1, 0, -1, -1], mask [False, False, True, False, False, False, True, False, False]\n",
            "agent won  8077  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.11083168536424637 q value 0.3287722408771515  reward : 1\n",
            "game #num:  14844\n",
            "action not avaliable action<0,8> 0 , satae [-1, 1, -1, -1, -1, 0, 0, 1, 1], mask [False, False, False, False, False, True, True, False, False]\n",
            "action not avaliable action<0,8> 3 , satae [-1, 1, -1, -1, -1, 0, 0, 1, 1], mask [False, False, False, False, False, True, True, False, False]\n",
            "mcts won  5312  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.11424473052223523 q value 0.32648491362730664  reward : -1\n",
            "game #num:  14845\n",
            "action not avaliable action<0,8> 3 , satae [0, 0, -1, 1, 0, 1, 0, -1, -1], mask [True, True, False, False, True, False, True, False, False]\n",
            "mcts won  5313  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.11642523854970932 q value 0.32361626625061035  reward : -1\n",
            "game #num:  14846\n",
            "action not avaliable action<0,8> 5 , satae [0, 0, 0, -1, 0, 1, 0, 0, 0], mask [True, True, True, False, True, False, True, True, True]\n",
            "action not avaliable action<0,8> 3 , satae [1, 0, 0, -1, -1, 1, -1, 0, 1], mask [False, True, True, False, False, False, False, True, False]\n",
            "action not avaliable action<0,8> 3 , satae [1, 0, 0, -1, -1, 1, -1, 0, 1], mask [False, True, True, False, False, False, False, True, False]\n",
            "action not avaliable action<0,8> 5 , satae [1, 0, 0, -1, -1, 1, -1, 0, 1], mask [False, True, True, False, False, False, False, True, False]\n",
            "action not avaliable action<0,8> 0 , satae [1, 0, 0, -1, -1, 1, -1, 0, 1], mask [False, True, True, False, False, False, False, True, False]\n",
            "agent won  8078  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.10498959736691581 q value 0.3217155701584286  reward : 1\n",
            "game #num:  14847\n",
            "action not avaliable action<0,8> 0 , satae [-1, 0, 0, 0, 0, -1, 0, 0, 1], mask [False, True, True, True, True, False, True, True, False]\n",
            "action not avaliable action<0,8> 8 , satae [-1, 1, -1, 1, -1, -1, 0, 0, 1], mask [False, False, False, False, False, False, True, True, False]\n",
            "draw  1456  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0]\n",
            "################################################################################################\n",
            "game loss:  0.13136781752109528 q value 0.3219049374262492  reward : 0\n",
            "game #num:  14848\n",
            "action not avaliable action<0,8> 0 , satae [-1, -1, 1, 0, 0, -1, -1, 1, 1], mask [False, False, False, True, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [-1, -1, 1, 0, 0, -1, -1, 1, 1], mask [False, False, False, True, True, False, False, False, False]\n",
            "agent won  8079  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.1049444464345773 q value 0.3210236330827077  reward : 1\n",
            "game #num:  14849\n",
            "action not avaliable action<0,8> 4 , satae [0, -1, 0, 0, -1, 0, 1, 0, 0], mask [True, False, True, True, False, True, False, True, True]\n",
            "mcts won  5314  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.12093485891819 q value 0.3200720176100731  reward : -1\n",
            "game #num:  14850\n",
            "mcts won  5315  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.10404512286186218 q value 0.3185069113969803  reward : -1\n",
            "game #num:  14851\n",
            "action not avaliable action<0,8> 7 , satae [0, 0, 1, 1, 0, 0, -1, -1, 0], mask [True, True, False, False, True, True, False, False, True]\n",
            "action not avaliable action<0,8> 3 , satae [0, 0, 1, 1, 0, 0, -1, -1, 0], mask [True, True, False, False, True, True, False, False, True]\n",
            "mcts won  5316  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.12492103278636932 q value 0.3172113597393036  reward : -1\n",
            "game #num:  14852\n",
            "action not avaliable action<0,8> 1 , satae [0, -1, 0, -1, 0, 1, 0, 0, 1], mask [True, False, True, False, True, False, True, True, False]\n",
            "action not avaliable action<0,8> 3 , satae [0, -1, 0, -1, 0, 1, 0, 0, 1], mask [True, False, True, False, True, False, True, True, False]\n",
            "action not avaliable action<0,8> 3 , satae [1, -1, 0, -1, 0, 1, -1, 0, 1], mask [False, False, True, False, True, False, False, True, False]\n",
            "action not avaliable action<0,8> 4 , satae [1, -1, 0, -1, -1, 1, -1, 1, 1], mask [False, False, True, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 5 , satae [1, -1, 0, -1, -1, 1, -1, 1, 1], mask [False, False, True, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 0 , satae [1, -1, 0, -1, -1, 1, -1, 1, 1], mask [False, False, True, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 0 , satae [1, -1, 0, -1, -1, 1, -1, 1, 1], mask [False, False, True, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [1, -1, 0, -1, -1, 1, -1, 1, 1], mask [False, False, True, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 3 , satae [1, -1, 0, -1, -1, 1, -1, 1, 1], mask [False, False, True, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [1, -1, 0, -1, -1, 1, -1, 1, 1], mask [False, False, True, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [1, -1, 0, -1, -1, 1, -1, 1, 1], mask [False, False, True, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 0 , satae [1, -1, 0, -1, -1, 1, -1, 1, 1], mask [False, False, True, False, False, False, False, False, False]\n",
            "agent won  8080  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.12353921813123367 q value 0.31515338140375476  reward : 1\n",
            "game #num:  14853\n",
            "action not avaliable action<0,8> 2 , satae [0, 0, -1, 0, 1, 0, 0, 0, 0], mask [True, True, False, True, False, True, True, True, True]\n",
            "action not avaliable action<0,8> 1 , satae [0, -1, -1, 0, 1, 1, 1, -1, 0], mask [True, False, False, True, False, False, False, False, True]\n",
            "action not avaliable action<0,8> 2 , satae [0, -1, -1, 0, 1, 1, 1, -1, 0], mask [True, False, False, True, False, False, False, False, True]\n",
            "action not avaliable action<0,8> 7 , satae [0, -1, -1, 0, 1, 1, 1, -1, 0], mask [True, False, False, True, False, False, False, False, True]\n",
            "action not avaliable action<0,8> 1 , satae [1, -1, -1, -1, 1, 1, 1, -1, 0], mask [False, False, False, False, False, False, False, False, True]\n",
            "action not avaliable action<0,8> 4 , satae [1, -1, -1, -1, 1, 1, 1, -1, 0], mask [False, False, False, False, False, False, False, False, True]\n",
            "action not avaliable action<0,8> 0 , satae [1, -1, -1, -1, 1, 1, 1, -1, 0], mask [False, False, False, False, False, False, False, False, True]\n",
            "draw  1457  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "################################################################################################\n",
            "game loss:  0.11678183699647586 q value 0.3119032308459282  reward : 0\n",
            "game #num:  14854\n",
            "action not avaliable action<0,8> 4 , satae [0, -1, 0, 0, 1, 0, 0, 0, 0], mask [True, False, True, True, False, True, True, True, True]\n",
            "action not avaliable action<0,8> 6 , satae [1, -1, -1, 0, 1, 0, 1, 0, -1], mask [False, False, False, True, False, True, False, True, False]\n",
            "action not avaliable action<0,8> 0 , satae [1, -1, -1, 0, 1, 0, 1, 0, -1], mask [False, False, False, True, False, True, False, True, False]\n",
            "action not avaliable action<0,8> 2 , satae [1, -1, -1, 0, 1, 0, 1, 0, -1], mask [False, False, False, True, False, True, False, True, False]\n",
            "action not avaliable action<0,8> 8 , satae [1, -1, -1, 0, 1, 0, 1, 0, -1], mask [False, False, False, True, False, True, False, True, False]\n",
            "action not avaliable action<0,8> 6 , satae [1, -1, -1, 0, 1, 0, 1, 0, -1], mask [False, False, False, True, False, True, False, True, False]\n",
            "action not avaliable action<0,8> 2 , satae [1, -1, -1, 0, 1, 0, 1, 0, -1], mask [False, False, False, True, False, True, False, True, False]\n",
            "action not avaliable action<0,8> 8 , satae [1, -1, -1, -1, 1, 0, 1, 1, -1], mask [False, False, False, False, False, True, False, False, False]\n",
            "action not avaliable action<0,8> 4 , satae [1, -1, -1, -1, 1, 0, 1, 1, -1], mask [False, False, False, False, False, True, False, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [1, -1, -1, -1, 1, 0, 1, 1, -1], mask [False, False, False, False, False, True, False, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [1, -1, -1, -1, 1, 0, 1, 1, -1], mask [False, False, False, False, False, True, False, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [1, -1, -1, -1, 1, 0, 1, 1, -1], mask [False, False, False, False, False, True, False, False, False]\n",
            "action not avaliable action<0,8> 1 , satae [1, -1, -1, -1, 1, 0, 1, 1, -1], mask [False, False, False, False, False, True, False, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [1, -1, -1, -1, 1, 0, 1, 1, -1], mask [False, False, False, False, False, True, False, False, False]\n",
            "action not avaliable action<0,8> 3 , satae [1, -1, -1, -1, 1, 0, 1, 1, -1], mask [False, False, False, False, False, True, False, False, False]\n",
            "action not avaliable action<0,8> 0 , satae [1, -1, -1, -1, 1, 0, 1, 1, -1], mask [False, False, False, False, False, True, False, False, False]\n",
            "draw  1458  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "################################################################################################\n",
            "game loss:  0.11414265313318797 q value 0.31475148172605605  reward : 0\n",
            "game #num:  14855\n",
            "action not avaliable action<0,8> 2 , satae [-1, -1, 1, -1, 0, 0, 1, 0, 0], mask [False, False, False, False, True, True, False, True, True]\n",
            "action not avaliable action<0,8> 6 , satae [-1, -1, 1, -1, 0, 0, 1, 0, 0], mask [False, False, False, False, True, True, False, True, True]\n",
            "action not avaliable action<0,8> 6 , satae [-1, -1, 1, -1, 0, 0, 1, 0, 0], mask [False, False, False, False, True, True, False, True, True]\n",
            "action not avaliable action<0,8> 6 , satae [-1, -1, 1, -1, 0, 0, 1, 0, 0], mask [False, False, False, False, True, True, False, True, True]\n",
            "action not avaliable action<0,8> 6 , satae [-1, -1, 1, -1, 0, 0, 1, 0, 0], mask [False, False, False, False, True, True, False, True, True]\n",
            "action not avaliable action<0,8> 6 , satae [-1, -1, 1, -1, 0, 0, 1, 0, 0], mask [False, False, False, False, True, True, False, True, True]\n",
            "mcts won  5317  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.11194568458530638 q value 0.31980035371250576  reward : -1\n",
            "game #num:  14856\n",
            "agent won  8081  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.11801818013191223 q value 0.32167935371398926  reward : 1\n",
            "game #num:  14857\n",
            "action not avaliable action<0,8> 1 , satae [0, 1, 0, 0, 0, -1, -1, 0, 0], mask [True, False, True, True, True, False, False, True, True]\n",
            "action not avaliable action<0,8> 1 , satae [1, 1, -1, 0, 0, -1, -1, 0, 0], mask [False, False, False, True, True, False, False, True, True]\n",
            "action not avaliable action<0,8> 1 , satae [1, 1, -1, 0, 0, -1, -1, 0, 0], mask [False, False, False, True, True, False, False, True, True]\n",
            "action not avaliable action<0,8> 6 , satae [1, 1, -1, 0, 0, -1, -1, 0, 0], mask [False, False, False, True, True, False, False, True, True]\n",
            "mcts won  5318  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.10593282857111522 q value 0.3238807107721056  reward : -1\n",
            "game #num:  14858\n",
            "action not avaliable action<0,8> 8 , satae [0, -1, 1, 0, 1, -1, 0, -1, 1], mask [True, False, False, True, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 4 , satae [0, -1, 1, 0, 1, -1, 0, -1, 1], mask [True, False, False, True, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 2 , satae [0, -1, 1, 0, 1, -1, 0, -1, 1], mask [True, False, False, True, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 1 , satae [0, -1, 1, 0, 1, -1, 0, -1, 1], mask [True, False, False, True, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 1 , satae [0, -1, 1, 0, 1, -1, 0, -1, 1], mask [True, False, False, True, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [0, -1, 1, 0, 1, -1, 0, -1, 1], mask [True, False, False, True, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 2 , satae [0, -1, 1, 0, 1, -1, 0, -1, 1], mask [True, False, False, True, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 4 , satae [0, -1, 1, 0, 1, -1, 0, -1, 1], mask [True, False, False, True, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 4 , satae [0, -1, 1, 0, 1, -1, 0, -1, 1], mask [True, False, False, True, False, False, True, False, False]\n",
            "agent won  8082  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.1079823116843517 q value 0.32810455331435573  reward : 1\n",
            "game #num:  14859\n",
            "action not avaliable action<0,8> 3 , satae [0, 0, 0, 1, 0, 0, 0, 0, -1], mask [True, True, True, False, True, True, True, True, False]\n",
            "action not avaliable action<0,8> 8 , satae [0, 0, 0, 1, 0, 1, -1, 0, -1], mask [True, True, True, False, True, False, False, True, False]\n",
            "action not avaliable action<0,8> 8 , satae [0, -1, 1, 1, -1, 1, -1, 1, -1], mask [True, False, False, False, False, False, False, False, False]\n",
            "agent won  8083  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.10684814862906933 q value 0.32818322256207466  reward : 1\n",
            "game #num:  14860\n",
            "mcts won  5319  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.1124580055475235 q value 0.3281461000442505  reward : -1\n",
            "game #num:  14861\n",
            "agent won  8084  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.10541530698537827 q value 0.3282148241996765  reward : 1\n",
            "game #num:  14862\n",
            "agent won  8085  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.10443522781133652 q value 0.3281487226486206  reward : 1\n",
            "game #num:  14863\n",
            "action not avaliable action<0,8> 4 , satae [0, 0, 0, -1, 1, 0, 0, 0, 0], mask [True, True, True, False, False, True, True, True, True]\n",
            "action not avaliable action<0,8> 3 , satae [0, 0, 0, -1, 1, 0, 0, 0, 0], mask [True, True, True, False, False, True, True, True, True]\n",
            "action not avaliable action<0,8> 4 , satae [0, 0, 0, -1, 1, 0, 0, 0, 0], mask [True, True, True, False, False, True, True, True, True]\n",
            "agent won  8086  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.11358828097581863 q value 0.3289248262132917  reward : 1\n",
            "game #num:  14864\n",
            "action not avaliable action<0,8> 8 , satae [0, 0, 0, 0, 0, 0, 0, 0, -1], mask [True, True, True, True, True, True, True, True, False]\n",
            "action not avaliable action<0,8> 8 , satae [0, 0, 0, 0, 0, 0, 0, 0, -1], mask [True, True, True, True, True, True, True, True, False]\n",
            "action not avaliable action<0,8> 8 , satae [0, 0, 0, 0, 0, 0, 0, 0, -1], mask [True, True, True, True, True, True, True, True, False]\n",
            "agent won  8087  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.11299824863672256 q value 0.3288258969783783  reward : 1\n",
            "game #num:  14865\n",
            "action not avaliable action<0,8> 1 , satae [1, -1, 0, 0, 0, 0, 0, -1, 0], mask [False, False, True, True, True, True, True, False, True]\n",
            "mcts won  5320  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.10869407157103221 q value 0.3272499640782674  reward : -1\n",
            "game #num:  14866\n",
            "action not avaliable action<0,8> 2 , satae [1, 0, -1, 0, 1, 0, 0, -1, 0], mask [False, True, False, True, False, True, True, False, True]\n",
            "agent won  8088  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.1076738566160202 q value 0.3261893928050995  reward : 1\n",
            "game #num:  14867\n",
            "action not avaliable action<0,8> 1 , satae [0, 1, 0, -1, 0, 0, -1, -1, 1], mask [True, False, True, False, True, True, False, False, False]\n",
            "action not avaliable action<0,8> 1 , satae [0, 1, 0, -1, 0, 0, -1, -1, 1], mask [True, False, True, False, True, True, False, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [0, 1, 0, -1, 0, 0, -1, -1, 1], mask [True, False, True, False, True, True, False, False, False]\n",
            "action not avaliable action<0,8> 1 , satae [0, 1, 0, -1, 0, 0, -1, -1, 1], mask [True, False, True, False, True, True, False, False, False]\n",
            "agent won  8089  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.11078592389822006 q value 0.32549163699150085  reward : 1\n",
            "game #num:  14868\n",
            "agent won  8090  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.11058786697685719 q value 0.32381510734558105  reward : 1\n",
            "game #num:  14869\n",
            "action not avaliable action<0,8> 0 , satae [1, 0, 0, -1, 0, 1, 0, 0, -1], mask [False, True, True, False, True, False, True, True, False]\n",
            "action not avaliable action<0,8> 5 , satae [1, 0, 0, -1, 0, 1, 0, 0, -1], mask [False, True, True, False, True, False, True, True, False]\n",
            "action not avaliable action<0,8> 5 , satae [1, 1, 0, -1, 0, 1, 0, -1, -1], mask [False, False, True, False, True, False, True, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [1, 1, -1, -1, 1, 1, 0, -1, -1], mask [False, False, False, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 5 , satae [1, 1, -1, -1, 1, 1, 0, -1, -1], mask [False, False, False, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 2 , satae [1, 1, -1, -1, 1, 1, 0, -1, -1], mask [False, False, False, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 3 , satae [1, 1, -1, -1, 1, 1, 0, -1, -1], mask [False, False, False, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [1, 1, -1, -1, 1, 1, 0, -1, -1], mask [False, False, False, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 1 , satae [1, 1, -1, -1, 1, 1, 0, -1, -1], mask [False, False, False, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [1, 1, -1, -1, 1, 1, 0, -1, -1], mask [False, False, False, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [1, 1, -1, -1, 1, 1, 0, -1, -1], mask [False, False, False, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 1 , satae [1, 1, -1, -1, 1, 1, 0, -1, -1], mask [False, False, False, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 2 , satae [1, 1, -1, -1, 1, 1, 0, -1, -1], mask [False, False, False, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [1, 1, -1, -1, 1, 1, 0, -1, -1], mask [False, False, False, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 3 , satae [1, 1, -1, -1, 1, 1, 0, -1, -1], mask [False, False, False, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [1, 1, -1, -1, 1, 1, 0, -1, -1], mask [False, False, False, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 5 , satae [1, 1, -1, -1, 1, 1, 0, -1, -1], mask [False, False, False, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [1, 1, -1, -1, 1, 1, 0, -1, -1], mask [False, False, False, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 1 , satae [1, 1, -1, -1, 1, 1, 0, -1, -1], mask [False, False, False, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [1, 1, -1, -1, 1, 1, 0, -1, -1], mask [False, False, False, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [1, 1, -1, -1, 1, 1, 0, -1, -1], mask [False, False, False, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 4 , satae [1, 1, -1, -1, 1, 1, 0, -1, -1], mask [False, False, False, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 3 , satae [1, 1, -1, -1, 1, 1, 0, -1, -1], mask [False, False, False, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [1, 1, -1, -1, 1, 1, 0, -1, -1], mask [False, False, False, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [1, 1, -1, -1, 1, 1, 0, -1, -1], mask [False, False, False, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 5 , satae [1, 1, -1, -1, 1, 1, 0, -1, -1], mask [False, False, False, False, False, False, True, False, False]\n",
            "agent won  8091  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.11122123728836736 q value 0.3208892758815519  reward : 1\n",
            "game #num:  14870\n",
            "action not avaliable action<0,8> 7 , satae [0, 0, 1, 0, -1, -1, -1, 1, 0], mask [True, True, False, True, False, False, False, False, True]\n",
            "mcts won  5321  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.1107777152210474 q value 0.32392071932554245  reward : -1\n",
            "game #num:  14871\n",
            "action not avaliable action<0,8> 5 , satae [0, -1, 0, -1, 0, 1, -1, 1, 0], mask [True, False, True, False, True, False, False, False, True]\n",
            "action not avaliable action<0,8> 7 , satae [0, -1, -1, -1, 1, 1, -1, 1, 0], mask [True, False, False, False, False, False, False, False, True]\n",
            "action not avaliable action<0,8> 6 , satae [0, -1, -1, -1, 1, 1, -1, 1, 0], mask [True, False, False, False, False, False, False, False, True]\n",
            "action not avaliable action<0,8> 2 , satae [0, -1, -1, -1, 1, 1, -1, 1, 0], mask [True, False, False, False, False, False, False, False, True]\n",
            "action not avaliable action<0,8> 5 , satae [0, -1, -1, -1, 1, 1, -1, 1, 0], mask [True, False, False, False, False, False, False, False, True]\n",
            "action not avaliable action<0,8> 4 , satae [0, -1, -1, -1, 1, 1, -1, 1, 0], mask [True, False, False, False, False, False, False, False, True]\n",
            "action not avaliable action<0,8> 7 , satae [0, -1, -1, -1, 1, 1, -1, 1, 0], mask [True, False, False, False, False, False, False, False, True]\n",
            "action not avaliable action<0,8> 6 , satae [0, -1, -1, -1, 1, 1, -1, 1, 0], mask [True, False, False, False, False, False, False, False, True]\n",
            "action not avaliable action<0,8> 5 , satae [0, -1, -1, -1, 1, 1, -1, 1, 0], mask [True, False, False, False, False, False, False, False, True]\n",
            "mcts won  5322  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.11216038121626927 q value 0.3244602336333348  reward : -1\n",
            "game #num:  14872\n",
            "action not avaliable action<0,8> 8 , satae [-1, 0, 0, -1, 0, 0, 0, 1, 1], mask [False, True, True, False, True, True, True, False, False]\n",
            "action not avaliable action<0,8> 3 , satae [-1, 0, 0, -1, 0, 0, 0, 1, 1], mask [False, True, True, False, True, True, True, False, False]\n",
            "agent won  8092  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.11426994651556015 q value 0.32245033979415894  reward : 1\n",
            "game #num:  14873\n",
            "action not avaliable action<0,8> 3 , satae [0, -1, 1, -1, -1, 1, 0, 0, 0], mask [True, False, False, False, False, False, True, True, True]\n",
            "action not avaliable action<0,8> 6 , satae [0, -1, 1, -1, -1, 1, 1, 0, -1], mask [True, False, False, False, False, False, False, True, False]\n",
            "action not avaliable action<0,8> 8 , satae [0, -1, 1, -1, -1, 1, 1, 0, -1], mask [True, False, False, False, False, False, False, True, False]\n",
            "action not avaliable action<0,8> 4 , satae [0, -1, 1, -1, -1, 1, 1, 0, -1], mask [True, False, False, False, False, False, False, True, False]\n",
            "action not avaliable action<0,8> 8 , satae [0, -1, 1, -1, -1, 1, 1, 0, -1], mask [True, False, False, False, False, False, False, True, False]\n",
            "action not avaliable action<0,8> 4 , satae [0, -1, 1, -1, -1, 1, 1, 0, -1], mask [True, False, False, False, False, False, False, True, False]\n",
            "action not avaliable action<0,8> 1 , satae [0, -1, 1, -1, -1, 1, 1, 0, -1], mask [True, False, False, False, False, False, False, True, False]\n",
            "action not avaliable action<0,8> 1 , satae [0, -1, 1, -1, -1, 1, 1, 0, -1], mask [True, False, False, False, False, False, False, True, False]\n",
            "agent won  8093  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.11766886586944263 q value 0.31923720488945645  reward : 1\n",
            "game #num:  14874\n",
            "action not avaliable action<0,8> 8 , satae [1, 0, -1, 0, 1, 1, -1, 0, -1], mask [False, True, False, True, False, False, False, True, False]\n",
            "action not avaliable action<0,8> 0 , satae [1, 0, -1, 0, 1, 1, -1, 0, -1], mask [False, True, False, True, False, False, False, True, False]\n",
            "action not avaliable action<0,8> 7 , satae [1, 0, -1, -1, 1, 1, -1, 1, -1], mask [False, True, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [1, 0, -1, -1, 1, 1, -1, 1, -1], mask [False, True, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [1, 0, -1, -1, 1, 1, -1, 1, -1], mask [False, True, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [1, 0, -1, -1, 1, 1, -1, 1, -1], mask [False, True, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 0 , satae [1, 0, -1, -1, 1, 1, -1, 1, -1], mask [False, True, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 2 , satae [1, 0, -1, -1, 1, 1, -1, 1, -1], mask [False, True, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 2 , satae [1, 0, -1, -1, 1, 1, -1, 1, -1], mask [False, True, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 5 , satae [1, 0, -1, -1, 1, 1, -1, 1, -1], mask [False, True, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [1, 0, -1, -1, 1, 1, -1, 1, -1], mask [False, True, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [1, 0, -1, -1, 1, 1, -1, 1, -1], mask [False, True, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [1, 0, -1, -1, 1, 1, -1, 1, -1], mask [False, True, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [1, 0, -1, -1, 1, 1, -1, 1, -1], mask [False, True, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 0 , satae [1, 0, -1, -1, 1, 1, -1, 1, -1], mask [False, True, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 4 , satae [1, 0, -1, -1, 1, 1, -1, 1, -1], mask [False, True, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 0 , satae [1, 0, -1, -1, 1, 1, -1, 1, -1], mask [False, True, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [1, 0, -1, -1, 1, 1, -1, 1, -1], mask [False, True, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 0 , satae [1, 0, -1, -1, 1, 1, -1, 1, -1], mask [False, True, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 4 , satae [1, 0, -1, -1, 1, 1, -1, 1, -1], mask [False, True, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [1, 0, -1, -1, 1, 1, -1, 1, -1], mask [False, True, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [1, 0, -1, -1, 1, 1, -1, 1, -1], mask [False, True, False, False, False, False, False, False, False]\n",
            "agent won  8094  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.11404664869661685 q value 0.316549101361522  reward : 1\n",
            "game #num:  14875\n",
            "action not avaliable action<0,8> 3 , satae [0, 0, 0, -1, 0, 0, 0, 1, 0], mask [True, True, True, False, True, True, True, False, True]\n",
            "action not avaliable action<0,8> 5 , satae [0, 0, 0, -1, -1, 1, 0, 1, 0], mask [True, True, True, False, False, False, True, False, True]\n",
            "agent won  8095  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.11761221289634705 q value 0.3180391738812129  reward : 1\n",
            "game #num:  14876\n",
            "action not avaliable action<0,8> 3 , satae [0, 0, 0, -1, 0, 0, 0, 0, 0], mask [True, True, True, False, True, True, True, True, True]\n",
            "mcts won  5323  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.11029749177396297 q value 0.3165854960680008  reward : -1\n",
            "game #num:  14877\n",
            "action not avaliable action<0,8> 7 , satae [0, -1, 0, -1, 0, 1, -1, 1, 0], mask [True, False, True, False, True, False, False, False, True]\n",
            "action not avaliable action<0,8> 3 , satae [0, -1, 0, -1, 0, 1, -1, 1, 0], mask [True, False, True, False, True, False, False, False, True]\n",
            "action not avaliable action<0,8> 7 , satae [0, -1, 0, -1, 0, 1, -1, 1, 0], mask [True, False, True, False, True, False, False, False, True]\n",
            "action not avaliable action<0,8> 7 , satae [0, -1, 1, -1, 0, 1, -1, 1, -1], mask [True, False, False, False, True, False, False, False, False]\n",
            "mcts won  5324  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.11385603342205286 q value 0.3165813609957695  reward : -1\n",
            "game #num:  14878\n",
            "mcts won  5325  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.10099846124649048 q value 0.3161683678627014  reward : -1\n",
            "game #num:  14879\n",
            "action not avaliable action<0,8> 1 , satae [1, 1, -1, 1, -1, -1, 0, -1, 1], mask [False, False, False, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 1 , satae [1, 1, -1, 1, -1, -1, 0, -1, 1], mask [False, False, False, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 0 , satae [1, 1, -1, 1, -1, -1, 0, -1, 1], mask [False, False, False, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 3 , satae [1, 1, -1, 1, -1, -1, 0, -1, 1], mask [False, False, False, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 0 , satae [1, 1, -1, 1, -1, -1, 0, -1, 1], mask [False, False, False, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 0 , satae [1, 1, -1, 1, -1, -1, 0, -1, 1], mask [False, False, False, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 1 , satae [1, 1, -1, 1, -1, -1, 0, -1, 1], mask [False, False, False, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 4 , satae [1, 1, -1, 1, -1, -1, 0, -1, 1], mask [False, False, False, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [1, 1, -1, 1, -1, -1, 0, -1, 1], mask [False, False, False, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 5 , satae [1, 1, -1, 1, -1, -1, 0, -1, 1], mask [False, False, False, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 3 , satae [1, 1, -1, 1, -1, -1, 0, -1, 1], mask [False, False, False, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 1 , satae [1, 1, -1, 1, -1, -1, 0, -1, 1], mask [False, False, False, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 5 , satae [1, 1, -1, 1, -1, -1, 0, -1, 1], mask [False, False, False, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 1 , satae [1, 1, -1, 1, -1, -1, 0, -1, 1], mask [False, False, False, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 2 , satae [1, 1, -1, 1, -1, -1, 0, -1, 1], mask [False, False, False, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 3 , satae [1, 1, -1, 1, -1, -1, 0, -1, 1], mask [False, False, False, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 5 , satae [1, 1, -1, 1, -1, -1, 0, -1, 1], mask [False, False, False, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [1, 1, -1, 1, -1, -1, 0, -1, 1], mask [False, False, False, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 1 , satae [1, 1, -1, 1, -1, -1, 0, -1, 1], mask [False, False, False, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 0 , satae [1, 1, -1, 1, -1, -1, 0, -1, 1], mask [False, False, False, False, False, False, True, False, False]\n",
            "agent won  8096  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.11318404078483582 q value 0.31880839347839357  reward : 1\n",
            "game #num:  14880\n",
            "action not avaliable action<0,8> 5 , satae [0, 0, -1, 0, 1, -1, 0, 0, 0], mask [True, True, False, True, False, False, True, True, True]\n",
            "action not avaliable action<0,8> 2 , satae [0, 0, -1, 0, 1, -1, 0, 0, 0], mask [True, True, False, True, False, False, True, True, True]\n",
            "action not avaliable action<0,8> 5 , satae [0, 0, -1, 0, 1, -1, 0, 0, 0], mask [True, True, False, True, False, False, True, True, True]\n",
            "agent won  8097  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.11239305138587952 q value 0.322776597738266  reward : 1\n",
            "game #num:  14881\n",
            "action not avaliable action<0,8> 7 , satae [0, 0, 1, -1, 0, 1, 0, -1, 0], mask [True, True, False, False, True, False, True, False, True]\n",
            "action not avaliable action<0,8> 3 , satae [0, 0, 1, -1, 0, 1, 0, -1, 0], mask [True, True, False, False, True, False, True, False, True]\n",
            "action not avaliable action<0,8> 2 , satae [0, 0, 1, -1, 0, 1, 0, -1, 0], mask [True, True, False, False, True, False, True, False, True]\n",
            "action not avaliable action<0,8> 7 , satae [0, 0, 1, -1, 0, 1, 0, -1, 0], mask [True, True, False, False, True, False, True, False, True]\n",
            "action not avaliable action<0,8> 3 , satae [0, 0, 1, -1, 0, 1, 0, -1, 0], mask [True, True, False, False, True, False, True, False, True]\n",
            "action not avaliable action<0,8> 7 , satae [0, 0, 1, -1, 0, 1, 0, -1, 0], mask [True, True, False, False, True, False, True, False, True]\n",
            "agent won  8098  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.11343871222601996 q value 0.3205043607287937  reward : 1\n",
            "game #num:  14882\n",
            "action not avaliable action<0,8> 5 , satae [0, -1, -1, -1, 0, 1, 0, 0, 1], mask [True, False, False, False, True, False, True, True, False]\n",
            "action not avaliable action<0,8> 1 , satae [0, -1, -1, -1, 1, 1, -1, 0, 1], mask [True, False, False, False, False, False, False, True, False]\n",
            "action not avaliable action<0,8> 3 , satae [0, -1, -1, -1, 1, 1, -1, 0, 1], mask [True, False, False, False, False, False, False, True, False]\n",
            "action not avaliable action<0,8> 3 , satae [0, -1, -1, -1, 1, 1, -1, 0, 1], mask [True, False, False, False, False, False, False, True, False]\n",
            "agent won  8099  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.11886990442872047 q value 0.317649032920599  reward : 1\n",
            "game #num:  14883\n",
            "action not avaliable action<0,8> 5 , satae [-1, 0, 1, 0, -1, 1, -1, 0, 0], mask [False, True, False, True, False, False, False, True, True]\n",
            "action not avaliable action<0,8> 5 , satae [-1, 1, 1, 0, -1, 1, -1, -1, 0], mask [False, False, False, True, False, False, False, False, True]\n",
            "action not avaliable action<0,8> 0 , satae [-1, 1, 1, 0, -1, 1, -1, -1, 0], mask [False, False, False, True, False, False, False, False, True]\n",
            "mcts won  5326  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.11731370006288801 q value 0.3166653513908386  reward : -1\n",
            "game #num:  14884\n",
            "action not avaliable action<0,8> 8 , satae [0, 0, 0, 1, 0, 0, 0, 0, -1], mask [True, True, True, False, True, True, True, True, False]\n",
            "action not avaliable action<0,8> 3 , satae [0, 0, 0, 1, 0, 0, 0, 0, -1], mask [True, True, True, False, True, True, True, True, False]\n",
            "action not avaliable action<0,8> 0 , satae [-1, -1, 1, 1, 0, 0, 0, 1, -1], mask [False, False, False, False, True, True, True, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [-1, -1, 1, 1, 0, -1, 1, 1, -1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 3 , satae [-1, -1, 1, 1, 0, -1, 1, 1, -1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [-1, -1, 1, 1, 0, -1, 1, 1, -1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [-1, -1, 1, 1, 0, -1, 1, 1, -1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 2 , satae [-1, -1, 1, 1, 0, -1, 1, 1, -1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 3 , satae [-1, -1, 1, 1, 0, -1, 1, 1, -1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 3 , satae [-1, -1, 1, 1, 0, -1, 1, 1, -1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 5 , satae [-1, -1, 1, 1, 0, -1, 1, 1, -1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 5 , satae [-1, -1, 1, 1, 0, -1, 1, 1, -1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [-1, -1, 1, 1, 0, -1, 1, 1, -1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [-1, -1, 1, 1, 0, -1, 1, 1, -1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 5 , satae [-1, -1, 1, 1, 0, -1, 1, 1, -1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [-1, -1, 1, 1, 0, -1, 1, 1, -1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [-1, -1, 1, 1, 0, -1, 1, 1, -1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [-1, -1, 1, 1, 0, -1, 1, 1, -1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 3 , satae [-1, -1, 1, 1, 0, -1, 1, 1, -1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 5 , satae [-1, -1, 1, 1, 0, -1, 1, 1, -1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [-1, -1, 1, 1, 0, -1, 1, 1, -1], mask [False, False, False, False, True, False, False, False, False]\n",
            "agent won  8100  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.10897632659627841 q value 0.3206499975461226  reward : 1\n",
            "game #num:  14885\n",
            "action not avaliable action<0,8> 3 , satae [-1, 0, 0, 1, 0, 0, 0, -1, 0], mask [False, True, True, False, True, True, True, False, True]\n",
            "action not avaliable action<0,8> 3 , satae [-1, 0, 0, 1, 0, 0, 0, -1, 0], mask [False, True, True, False, True, True, True, False, True]\n",
            "action not avaliable action<0,8> 3 , satae [-1, 0, 0, 1, 0, 0, 0, -1, 0], mask [False, True, True, False, True, True, True, False, True]\n",
            "action not avaliable action<0,8> 2 , satae [-1, 1, -1, 1, -1, 0, 1, -1, 0], mask [False, False, False, False, False, True, False, False, True]\n",
            "action not avaliable action<0,8> 3 , satae [-1, 1, -1, 1, -1, 0, 1, -1, 0], mask [False, False, False, False, False, True, False, False, True]\n",
            "action not avaliable action<0,8> 6 , satae [-1, 1, -1, 1, -1, 0, 1, -1, 0], mask [False, False, False, False, False, True, False, False, True]\n",
            "agent won  8101  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.11342845186591148 q value 0.3291588485240936  reward : 1\n",
            "game #num:  14886\n",
            "mcts won  5327  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.11373403668403625 q value 0.32832998037338257  reward : -1\n",
            "game #num:  14887\n",
            "action not avaliable action<0,8> 7 , satae [0, 0, -1, 1, 0, 1, 0, -1, 0], mask [True, True, False, False, True, False, True, False, True]\n",
            "mcts won  5328  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.11592144072055817 q value 0.3266208112239838  reward : -1\n",
            "game #num:  14888\n",
            "action not avaliable action<0,8> 7 , satae [0, 0, 0, 0, 0, 1, 0, -1, 0], mask [True, True, True, True, True, False, True, False, True]\n",
            "action not avaliable action<0,8> 7 , satae [0, 0, 0, 0, 0, 1, 0, -1, 0], mask [True, True, True, True, True, False, True, False, True]\n",
            "action not avaliable action<0,8> 7 , satae [0, 0, 0, 0, 0, 1, 0, -1, 0], mask [True, True, True, True, True, False, True, False, True]\n",
            "action not avaliable action<0,8> 2 , satae [0, -1, -1, 0, 0, 1, 1, -1, 1], mask [True, False, False, True, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 5 , satae [0, -1, -1, 0, 0, 1, 1, -1, 1], mask [True, False, False, True, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 2 , satae [0, -1, -1, 0, 0, 1, 1, -1, 1], mask [True, False, False, True, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [0, -1, -1, 0, 0, 1, 1, -1, 1], mask [True, False, False, True, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 5 , satae [1, -1, -1, -1, 0, 1, 1, -1, 1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 1 , satae [1, -1, -1, -1, 0, 1, 1, -1, 1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [1, -1, -1, -1, 0, 1, 1, -1, 1], mask [False, False, False, False, True, False, False, False, False]\n",
            "agent won  8102  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.11633304605881373 q value 0.3215216179688772  reward : 1\n",
            "game #num:  14889\n",
            "action not avaliable action<0,8> 7 , satae [1, 0, -1, 0, 0, 0, 0, 1, -1], mask [False, True, False, True, True, True, True, False, False]\n",
            "action not avaliable action<0,8> 3 , satae [1, 0, -1, 1, -1, 0, 0, 1, -1], mask [False, True, False, False, False, True, True, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [1, 0, -1, 1, -1, 0, 0, 1, -1], mask [False, True, False, False, False, True, True, False, False]\n",
            "action not avaliable action<0,8> 2 , satae [1, 0, -1, 1, -1, 0, 0, 1, -1], mask [False, True, False, False, False, True, True, False, False]\n",
            "action not avaliable action<0,8> 2 , satae [1, 0, -1, 1, -1, 0, 0, 1, -1], mask [False, True, False, False, False, True, True, False, False]\n",
            "action not avaliable action<0,8> 0 , satae [1, 0, -1, 1, -1, 0, 0, 1, -1], mask [False, True, False, False, False, True, True, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [1, 0, -1, 1, -1, 0, 0, 1, -1], mask [False, True, False, False, False, True, True, False, False]\n",
            "action not avaliable action<0,8> 4 , satae [1, 0, -1, 1, -1, 0, 0, 1, -1], mask [False, True, False, False, False, True, True, False, False]\n",
            "action not avaliable action<0,8> 2 , satae [1, 0, -1, 1, -1, 0, 0, 1, -1], mask [False, True, False, False, False, True, True, False, False]\n",
            "action not avaliable action<0,8> 0 , satae [1, 0, -1, 1, -1, 0, 0, 1, -1], mask [False, True, False, False, False, True, True, False, False]\n",
            "action not avaliable action<0,8> 0 , satae [1, 0, -1, 1, -1, 0, 0, 1, -1], mask [False, True, False, False, False, True, True, False, False]\n",
            "mcts won  5329  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.1116391360759735 q value 0.3198292851448059  reward : -1\n",
            "game #num:  14890\n",
            "agent won  8103  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.12738405913114548 q value 0.32332266867160797  reward : 1\n",
            "game #num:  14891\n",
            "action not avaliable action<0,8> 2 , satae [1, 0, 1, 0, 0, -1, 0, -1, -1], mask [False, True, False, True, True, False, True, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [1, 0, 1, 1, -1, -1, 0, -1, -1], mask [False, True, False, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [1, 0, 1, 1, -1, -1, 0, -1, -1], mask [False, True, False, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 3 , satae [1, 0, 1, 1, -1, -1, 0, -1, -1], mask [False, True, False, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 3 , satae [1, 0, 1, 1, -1, -1, 0, -1, -1], mask [False, True, False, False, False, False, True, False, False]\n",
            "agent won  8104  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.11809611899985208 q value 0.32301565011342365  reward : 1\n",
            "game #num:  14892\n",
            "action not avaliable action<0,8> 3 , satae [0, 0, -1, 1, -1, 0, 1, 0, 0], mask [True, True, False, False, False, True, False, True, True]\n",
            "action not avaliable action<0,8> 1 , satae [-1, 1, -1, 1, -1, 0, 1, 0, 0], mask [False, False, False, False, False, True, False, True, True]\n",
            "draw  1459  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0]\n",
            "################################################################################################\n",
            "game loss:  0.11231381339686257 q value 0.31893748896462576  reward : 0\n",
            "game #num:  14893\n",
            "action not avaliable action<0,8> 1 , satae [-1, -1, 0, 1, -1, -1, 1, 1, 0], mask [False, False, True, False, False, False, False, False, True]\n",
            "mcts won  5330  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.12149512618780137 q value 0.31520532369613646  reward : -1\n",
            "game #num:  14894\n",
            "mcts won  5331  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.11459752668937047 q value 0.31301675240198773  reward : -1\n",
            "game #num:  14895\n",
            "action not avaliable action<0,8> 6 , satae [1, 0, -1, 0, 0, -1, 1, 0, 0], mask [False, True, False, True, True, False, False, True, True]\n",
            "mcts won  5332  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.11248292215168476 q value 0.3116781935095787  reward : -1\n",
            "game #num:  14896\n",
            "action not avaliable action<0,8> 2 , satae [0, 0, -1, 0, 0, 0, 0, 0, 0], mask [True, True, False, True, True, True, True, True, True]\n",
            "action not avaliable action<0,8> 7 , satae [1, 1, -1, 0, 0, -1, 0, -1, 0], mask [False, False, False, True, True, False, True, False, True]\n",
            "action not avaliable action<0,8> 2 , satae [1, 1, -1, 0, -1, -1, 0, -1, 1], mask [False, False, False, True, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 2 , satae [1, 1, -1, 0, -1, -1, 0, -1, 1], mask [False, False, False, True, False, False, True, False, False]\n",
            "mcts won  5333  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.105982999317348 q value 0.31001969054341316  reward : -1\n",
            "game #num:  14897\n",
            "action not avaliable action<0,8> 5 , satae [0, 1, 1, 0, -1, -1, 0, 0, -1], mask [True, False, False, True, False, False, True, True, False]\n",
            "action not avaliable action<0,8> 2 , satae [0, 1, 1, 0, -1, -1, 0, 0, -1], mask [True, False, False, True, False, False, True, True, False]\n",
            "action not avaliable action<0,8> 1 , satae [0, 1, 1, 0, -1, -1, 0, 0, -1], mask [True, False, False, True, False, False, True, True, False]\n",
            "action not avaliable action<0,8> 2 , satae [0, 1, 1, 0, -1, -1, 0, 0, -1], mask [True, False, False, True, False, False, True, True, False]\n",
            "mcts won  5334  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.1093311458826065 q value 0.31273079344204496  reward : -1\n",
            "game #num:  14898\n",
            "action not avaliable action<0,8> 7 , satae [0, 0, 1, -1, 1, 0, 0, -1, 0], mask [True, True, False, False, False, True, True, False, True]\n",
            "action not avaliable action<0,8> 8 , satae [0, 0, 1, -1, 1, -1, 0, -1, 1], mask [True, True, False, False, False, False, True, False, False]\n",
            "agent won  8105  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.11607618009050687 q value 0.3174186795949936  reward : 1\n",
            "game #num:  14899\n",
            "action not avaliable action<0,8> 8 , satae [-1, 0, 0, 0, 1, 0, 0, 0, -1], mask [False, True, True, True, False, True, True, True, False]\n",
            "action not avaliable action<0,8> 4 , satae [-1, 0, 0, 1, 1, -1, 0, 0, -1], mask [False, True, True, False, False, False, True, True, False]\n",
            "agent won  8106  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.11080137342214584 q value 0.3204705536365509  reward : 1\n",
            "game #num:  14900\n",
            "action not avaliable action<0,8> 3 , satae [-1, 0, -1, 1, 0, 0, 0, 0, 0], mask [False, True, False, False, True, True, True, True, True]\n",
            "action not avaliable action<0,8> 5 , satae [-1, 0, -1, 1, 0, 1, 0, -1, 0], mask [False, True, False, False, True, False, True, False, True]\n",
            "action not avaliable action<0,8> 3 , satae [-1, 0, -1, 1, 0, 1, 0, -1, 0], mask [False, True, False, False, True, False, True, False, True]\n",
            "action not avaliable action<0,8> 0 , satae [-1, 0, -1, 1, 0, 1, 0, -1, 0], mask [False, True, False, False, True, False, True, False, True]\n",
            "action not avaliable action<0,8> 5 , satae [-1, 0, -1, 1, 0, 1, -1, -1, 1], mask [False, True, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 5 , satae [-1, 0, -1, 1, 0, 1, -1, -1, 1], mask [False, True, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 5 , satae [-1, 0, -1, 1, 0, 1, -1, -1, 1], mask [False, True, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [-1, 0, -1, 1, 0, 1, -1, -1, 1], mask [False, True, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [-1, 0, -1, 1, 0, 1, -1, -1, 1], mask [False, True, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 3 , satae [-1, 0, -1, 1, 0, 1, -1, -1, 1], mask [False, True, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [-1, 0, -1, 1, 0, 1, -1, -1, 1], mask [False, True, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 5 , satae [-1, 0, -1, 1, 0, 1, -1, -1, 1], mask [False, True, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 3 , satae [-1, 0, -1, 1, 0, 1, -1, -1, 1], mask [False, True, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 5 , satae [-1, 0, -1, 1, 0, 1, -1, -1, 1], mask [False, True, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 5 , satae [-1, 0, -1, 1, 0, 1, -1, -1, 1], mask [False, True, False, False, True, False, False, False, False]\n",
            "agent won  8107  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.11002270132303238 q value 0.32351458072662354  reward : 1\n",
            "game #num:  14901\n",
            "action not avaliable action<0,8> 8 , satae [-1, 1, -1, 0, -1, -1, 1, 0, 1], mask [False, False, False, True, False, False, False, True, False]\n",
            "action not avaliable action<0,8> 6 , satae [-1, 1, -1, 0, -1, -1, 1, 0, 1], mask [False, False, False, True, False, False, False, True, False]\n",
            "action not avaliable action<0,8> 6 , satae [-1, 1, -1, 0, -1, -1, 1, 0, 1], mask [False, False, False, True, False, False, False, True, False]\n",
            "agent won  8108  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.10731384796755654 q value 0.32584803444998606  reward : 1\n",
            "game #num:  14902\n",
            "action not avaliable action<0,8> 5 , satae [-1, -1, 1, -1, 0, -1, 1, 0, 1], mask [False, False, False, False, True, False, False, True, False]\n",
            "agent won  8109  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.10377697497606278 q value 0.32674399614334104  reward : 1\n",
            "game #num:  14903\n",
            "agent won  8110  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.10978891452153523 q value 0.3270711998144786  reward : 1\n",
            "game #num:  14904\n",
            "action not avaliable action<0,8> 5 , satae [0, 0, 0, -1, -1, 1, 0, 0, 0], mask [True, True, True, False, False, False, True, True, True]\n",
            "action not avaliable action<0,8> 5 , satae [0, 0, 0, -1, -1, 1, 0, 0, 0], mask [True, True, True, False, False, False, True, True, True]\n",
            "action not avaliable action<0,8> 7 , satae [0, 0, -1, -1, -1, 1, 0, 1, 0], mask [True, True, False, False, False, False, True, False, True]\n",
            "action not avaliable action<0,8> 5 , satae [0, -1, -1, -1, -1, 1, 0, 1, 1], mask [True, False, False, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 3 , satae [0, -1, -1, -1, -1, 1, 0, 1, 1], mask [True, False, False, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 1 , satae [0, -1, -1, -1, -1, 1, 0, 1, 1], mask [True, False, False, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 1 , satae [0, -1, -1, -1, -1, 1, 0, 1, 1], mask [True, False, False, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 1 , satae [0, -1, -1, -1, -1, 1, 0, 1, 1], mask [True, False, False, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 3 , satae [0, -1, -1, -1, -1, 1, 0, 1, 1], mask [True, False, False, False, False, False, True, False, False]\n",
            "mcts won  5335  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.12080785517509167 q value 0.3254244144146259  reward : -1\n",
            "game #num:  14905\n",
            "action not avaliable action<0,8> 3 , satae [-1, 0, 1, -1, 0, 0, 0, 0, 0], mask [False, True, False, False, True, True, True, True, True]\n",
            "action not avaliable action<0,8> 6 , satae [-1, 0, 1, -1, 0, 0, 1, -1, 0], mask [False, True, False, False, True, True, False, False, True]\n",
            "action not avaliable action<0,8> 7 , satae [-1, 0, 1, -1, 0, 0, 1, -1, 0], mask [False, True, False, False, True, True, False, False, True]\n",
            "action not avaliable action<0,8> 7 , satae [-1, 0, 1, -1, 0, 0, 1, -1, 0], mask [False, True, False, False, True, True, False, False, True]\n",
            "agent won  8111  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.11709811817854643 q value 0.3225993514060974  reward : 1\n",
            "game #num:  14906\n",
            "agent won  8112  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.12934139122565588 q value 0.32138439019521076  reward : 1\n",
            "game #num:  14907\n",
            "action not avaliable action<0,8> 7 , satae [1, -1, 0, 0, 0, 0, -1, 1, 0], mask [False, False, True, True, True, True, False, False, True]\n",
            "action not avaliable action<0,8> 8 , satae [1, -1, 0, 0, 0, -1, -1, 1, 1], mask [False, False, True, True, True, False, False, False, False]\n",
            "agent won  8113  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.11167209222912788 q value 0.3189207414786021  reward : 1\n",
            "game #num:  14908\n",
            "action not avaliable action<0,8> 7 , satae [1, 0, -1, -1, 0, 0, 1, -1, 1], mask [False, True, False, False, True, True, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [1, 1, -1, -1, 0, -1, 1, -1, 1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [1, 1, -1, -1, 0, -1, 1, -1, 1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [1, 1, -1, -1, 0, -1, 1, -1, 1], mask [False, False, False, False, True, False, False, False, False]\n",
            "agent won  8114  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.10855913327799903 q value 0.3156037959787581  reward : 1\n",
            "game #num:  14909\n",
            "action not avaliable action<0,8> 8 , satae [1, 0, 0, -1, 0, 1, 0, -1, -1], mask [False, True, True, False, True, False, True, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [1, 0, 0, -1, -1, 1, 1, -1, -1], mask [False, True, True, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 0 , satae [1, 0, 0, -1, -1, 1, 1, -1, -1], mask [False, True, True, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [1, 0, 0, -1, -1, 1, 1, -1, -1], mask [False, True, True, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 4 , satae [1, 0, 0, -1, -1, 1, 1, -1, -1], mask [False, True, True, False, False, False, False, False, False]\n",
            "mcts won  5336  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.11551670067840153 q value 0.31580236223008895  reward : -1\n",
            "game #num:  14910\n",
            "action not avaliable action<0,8> 4 , satae [0, -1, 1, 0, -1, 0, 0, 0, 0], mask [True, False, False, True, False, True, True, True, True]\n",
            "mcts won  5337  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.1059640496969223 q value 0.31625179449717206  reward : -1\n",
            "game #num:  14911\n",
            "action not avaliable action<0,8> 1 , satae [0, -1, 0, 0, 0, 0, 0, 0, 0], mask [True, False, True, True, True, True, True, True, True]\n",
            "action not avaliable action<0,8> 1 , satae [0, -1, 0, 0, 0, -1, 0, 1, 0], mask [True, False, True, True, True, False, True, False, True]\n",
            "action not avaliable action<0,8> 7 , satae [0, -1, 0, 0, 0, -1, 0, 1, 0], mask [True, False, True, True, True, False, True, False, True]\n",
            "action not avaliable action<0,8> 7 , satae [0, -1, 0, 0, 0, -1, 0, 1, 0], mask [True, False, True, True, True, False, True, False, True]\n",
            "action not avaliable action<0,8> 5 , satae [0, -1, 0, 0, 0, -1, 0, 1, 0], mask [True, False, True, True, True, False, True, False, True]\n",
            "action not avaliable action<0,8> 0 , satae [1, -1, 0, 0, -1, -1, -1, 1, 1], mask [False, False, True, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 1 , satae [1, -1, 0, 0, -1, -1, -1, 1, 1], mask [False, False, True, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [1, -1, 0, 0, -1, -1, -1, 1, 1], mask [False, False, True, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 0 , satae [1, -1, 0, 0, -1, -1, -1, 1, 1], mask [False, False, True, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [1, -1, 0, 0, -1, -1, -1, 1, 1], mask [False, False, True, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 5 , satae [1, -1, 0, 0, -1, -1, -1, 1, 1], mask [False, False, True, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 4 , satae [1, -1, 0, 0, -1, -1, -1, 1, 1], mask [False, False, True, True, False, False, False, False, False]\n",
            "mcts won  5338  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.10729673877358437 q value 0.32093617506325245  reward : -1\n",
            "game #num:  14912\n",
            "action not avaliable action<0,8> 8 , satae [-1, 0, 0, 0, 1, -1, 0, 1, -1], mask [False, True, True, True, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [-1, 0, 0, 0, 1, -1, 0, 1, -1], mask [False, True, True, True, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [-1, 0, 0, 0, 1, -1, 0, 1, -1], mask [False, True, True, True, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [-1, 0, 0, 0, 1, -1, 0, 1, -1], mask [False, True, True, True, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [-1, 0, 0, 0, 1, -1, 0, 1, -1], mask [False, True, True, True, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [-1, 0, 0, -1, 1, -1, 1, 1, -1], mask [False, True, True, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [-1, 0, 0, -1, 1, -1, 1, 1, -1], mask [False, True, True, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [-1, 0, 0, -1, 1, -1, 1, 1, -1], mask [False, True, True, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [-1, 0, 0, -1, 1, -1, 1, 1, -1], mask [False, True, True, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [-1, 0, 0, -1, 1, -1, 1, 1, -1], mask [False, True, True, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [-1, 0, 0, -1, 1, -1, 1, 1, -1], mask [False, True, True, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 4 , satae [-1, 0, 0, -1, 1, -1, 1, 1, -1], mask [False, True, True, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 5 , satae [-1, 0, 0, -1, 1, -1, 1, 1, -1], mask [False, True, True, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 5 , satae [-1, 0, 0, -1, 1, -1, 1, 1, -1], mask [False, True, True, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 4 , satae [-1, 0, 0, -1, 1, -1, 1, 1, -1], mask [False, True, True, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [-1, 0, 0, -1, 1, -1, 1, 1, -1], mask [False, True, True, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 0 , satae [-1, 0, 0, -1, 1, -1, 1, 1, -1], mask [False, True, True, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 4 , satae [-1, 0, 0, -1, 1, -1, 1, 1, -1], mask [False, True, True, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [-1, 0, 0, -1, 1, -1, 1, 1, -1], mask [False, True, True, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [-1, 0, 0, -1, 1, -1, 1, 1, -1], mask [False, True, True, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 0 , satae [-1, 0, 0, -1, 1, -1, 1, 1, -1], mask [False, True, True, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [-1, 0, 0, -1, 1, -1, 1, 1, -1], mask [False, True, True, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 4 , satae [-1, 0, 0, -1, 1, -1, 1, 1, -1], mask [False, True, True, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [-1, 0, 0, -1, 1, -1, 1, 1, -1], mask [False, True, True, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 3 , satae [-1, 0, 0, -1, 1, -1, 1, 1, -1], mask [False, True, True, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [-1, 0, 0, -1, 1, -1, 1, 1, -1], mask [False, True, True, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [-1, 0, 0, -1, 1, -1, 1, 1, -1], mask [False, True, True, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [-1, 0, 0, -1, 1, -1, 1, 1, -1], mask [False, True, True, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 4 , satae [-1, 0, 0, -1, 1, -1, 1, 1, -1], mask [False, True, True, False, False, False, False, False, False]\n",
            "agent won  8115  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.11383481955889499 q value 0.32267011295665393  reward : 1\n",
            "game #num:  14913\n",
            "action not avaliable action<0,8> 8 , satae [0, 0, -1, 0, 0, -1, 0, 0, 1], mask [True, True, False, True, True, False, True, True, False]\n",
            "action not avaliable action<0,8> 5 , satae [-1, 1, -1, 0, 0, -1, 1, -1, 1], mask [False, False, False, True, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [-1, 1, -1, 0, 0, -1, 1, -1, 1], mask [False, False, False, True, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 2 , satae [-1, 1, -1, 0, 0, -1, 1, -1, 1], mask [False, False, False, True, True, False, False, False, False]\n",
            "draw  1460  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0]\n",
            "################################################################################################\n",
            "game loss:  0.11592157371342182 q value 0.3193599544465542  reward : 0\n",
            "game #num:  14914\n",
            "action not avaliable action<0,8> 0 , satae [1, -1, -1, 0, 0, 0, 1, 0, 0], mask [False, False, False, True, True, True, False, True, True]\n",
            "action not avaliable action<0,8> 6 , satae [1, -1, -1, 0, 0, 0, 1, 0, 0], mask [False, False, False, True, True, True, False, True, True]\n",
            "action not avaliable action<0,8> 6 , satae [1, -1, -1, 0, 0, 0, 1, 0, 0], mask [False, False, False, True, True, True, False, True, True]\n",
            "mcts won  5339  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.11723619078596433 q value 0.31889980534712475  reward : -1\n",
            "game #num:  14915\n",
            "action not avaliable action<0,8> 7 , satae [0, 0, 1, 0, 0, 0, 0, -1, 0], mask [True, True, False, True, True, True, True, False, True]\n",
            "action not avaliable action<0,8> 2 , satae [0, 0, 1, 0, 0, 0, 0, -1, 0], mask [True, True, False, True, True, True, True, False, True]\n",
            "action not avaliable action<0,8> 7 , satae [0, 0, 1, 0, 0, 0, 0, -1, 0], mask [True, True, False, True, True, True, True, False, True]\n",
            "action not avaliable action<0,8> 7 , satae [0, 0, 1, 0, 0, 0, 0, -1, 0], mask [True, True, False, True, True, True, True, False, True]\n",
            "action not avaliable action<0,8> 1 , satae [0, 1, 1, 0, -1, 0, 0, -1, 0], mask [True, False, False, True, False, True, True, False, True]\n",
            "action not avaliable action<0,8> 3 , satae [0, 1, 1, 1, -1, -1, 0, -1, 0], mask [True, False, False, False, False, False, True, False, True]\n",
            "mcts won  5340  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.11489902809262276 q value 0.31709652841091157  reward : -1\n",
            "game #num:  14916\n",
            "action not avaliable action<0,8> 4 , satae [0, 0, 0, -1, 1, 0, -1, 1, 0], mask [True, True, True, False, False, True, False, False, True]\n",
            "agent won  8116  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.1162367220968008 q value 0.3163275569677353  reward : 1\n",
            "game #num:  14917\n",
            "action not avaliable action<0,8> 0 , satae [-1, -1, 0, 1, -1, 1, 0, 0, 0], mask [False, False, True, False, False, False, True, True, True]\n",
            "action not avaliable action<0,8> 5 , satae [-1, -1, 0, 1, -1, 1, 0, 0, 0], mask [False, False, True, False, False, False, True, True, True]\n",
            "action not avaliable action<0,8> 3 , satae [-1, -1, 0, 1, -1, 1, 0, 0, 0], mask [False, False, True, False, False, False, True, True, True]\n",
            "action not avaliable action<0,8> 3 , satae [-1, -1, 0, 1, -1, 1, 0, 0, 0], mask [False, False, True, False, False, False, True, True, True]\n",
            "mcts won  5341  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.10899250102894646 q value 0.31766450830868315  reward : -1\n",
            "game #num:  14918\n",
            "action not avaliable action<0,8> 3 , satae [0, 0, 0, -1, 1, 0, 0, 0, 0], mask [True, True, True, False, False, True, True, True, True]\n",
            "action not avaliable action<0,8> 3 , satae [0, 1, 0, -1, 1, 0, -1, 0, 0], mask [True, False, True, False, False, True, False, True, True]\n",
            "action not avaliable action<0,8> 1 , satae [0, 1, 0, -1, 1, 0, -1, 0, 0], mask [True, False, True, False, False, True, False, True, True]\n",
            "action not avaliable action<0,8> 1 , satae [0, 1, 0, -1, 1, 0, -1, 0, 0], mask [True, False, True, False, False, True, False, True, True]\n",
            "agent won  8117  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.10884859878569841 q value 0.3199329972267151  reward : 1\n",
            "game #num:  14919\n",
            "action not avaliable action<0,8> 1 , satae [1, 1, 0, 0, 0, -1, -1, 1, -1], mask [False, False, True, True, True, False, False, False, False]\n",
            "agent won  8118  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.10469950735569 q value 0.32198787927627565  reward : 1\n",
            "game #num:  14920\n",
            "action not avaliable action<0,8> 4 , satae [0, 0, -1, 0, 1, 0, 0, -1, 0], mask [True, True, False, True, False, True, True, False, True]\n",
            "action not avaliable action<0,8> 4 , satae [-1, 0, -1, 0, 1, 0, 1, -1, 0], mask [False, True, False, True, False, True, False, False, True]\n",
            "action not avaliable action<0,8> 0 , satae [-1, 0, -1, 1, 1, 0, 1, -1, -1], mask [False, True, False, False, False, True, False, False, False]\n",
            "action not avaliable action<0,8> 3 , satae [-1, 0, -1, 1, 1, 0, 1, -1, -1], mask [False, True, False, False, False, True, False, False, False]\n",
            "action not avaliable action<0,8> 2 , satae [-1, 0, -1, 1, 1, 0, 1, -1, -1], mask [False, True, False, False, False, True, False, False, False]\n",
            "action not avaliable action<0,8> 2 , satae [-1, 0, -1, 1, 1, 0, 1, -1, -1], mask [False, True, False, False, False, True, False, False, False]\n",
            "action not avaliable action<0,8> 3 , satae [-1, 0, -1, 1, 1, 0, 1, -1, -1], mask [False, True, False, False, False, True, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [-1, 0, -1, 1, 1, 0, 1, -1, -1], mask [False, True, False, False, False, True, False, False, False]\n",
            "action not avaliable action<0,8> 0 , satae [-1, 0, -1, 1, 1, 0, 1, -1, -1], mask [False, True, False, False, False, True, False, False, False]\n",
            "mcts won  5342  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.11214550126057404 q value 0.3244037009202517  reward : -1\n",
            "game #num:  14921\n",
            "action not avaliable action<0,8> 6 , satae [0, -1, 0, 0, 1, -1, 1, 1, -1], mask [True, False, True, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [0, -1, 0, 0, 1, -1, 1, 1, -1], mask [True, False, True, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [0, -1, 0, 0, 1, -1, 1, 1, -1], mask [True, False, True, True, False, False, False, False, False]\n",
            "mcts won  5343  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.11083267629146576 q value 0.3256001089300428  reward : -1\n",
            "game #num:  14922\n",
            "action not avaliable action<0,8> 4 , satae [-1, 0, -1, 0, 1, -1, 0, 1, 1], mask [False, True, False, True, False, False, True, False, False]\n",
            "mcts won  5344  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.11019903719425202 q value 0.3257958829402924  reward : -1\n",
            "game #num:  14923\n",
            "action not avaliable action<0,8> 7 , satae [1, 0, -1, 0, 0, -1, 0, 1, 0], mask [False, True, False, True, True, False, True, False, True]\n",
            "action not avaliable action<0,8> 7 , satae [1, 0, -1, 1, -1, -1, 0, 1, 0], mask [False, True, False, False, False, False, True, False, True]\n",
            "action not avaliable action<0,8> 0 , satae [1, 0, -1, 1, -1, -1, 0, 1, 0], mask [False, True, False, False, False, False, True, False, True]\n",
            "action not avaliable action<0,8> 0 , satae [1, 0, -1, 1, -1, -1, 0, 1, 0], mask [False, True, False, False, False, False, True, False, True]\n",
            "action not avaliable action<0,8> 0 , satae [1, 0, -1, 1, -1, -1, 0, 1, 0], mask [False, True, False, False, False, False, True, False, True]\n",
            "action not avaliable action<0,8> 1 , satae [1, -1, -1, 1, -1, -1, 0, 1, 1], mask [False, False, False, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 1 , satae [1, -1, -1, 1, -1, -1, 0, 1, 1], mask [False, False, False, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 5 , satae [1, -1, -1, 1, -1, -1, 0, 1, 1], mask [False, False, False, False, False, False, True, False, False]\n",
            "agent won  8119  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.12180979664509113 q value 0.32343802543786854  reward : 1\n",
            "game #num:  14924\n",
            "action not avaliable action<0,8> 7 , satae [1, 0, 0, 0, 0, -1, 0, -1, 0], mask [False, True, True, True, True, False, True, False, True]\n",
            "action not avaliable action<0,8> 7 , satae [1, 0, 0, 0, 0, -1, 0, -1, 0], mask [False, True, True, True, True, False, True, False, True]\n",
            "action not avaliable action<0,8> 0 , satae [1, 0, 0, 0, 0, -1, 0, -1, 0], mask [False, True, True, True, True, False, True, False, True]\n",
            "action not avaliable action<0,8> 1 , satae [1, 1, 0, 0, 0, -1, -1, -1, 0], mask [False, False, True, True, True, False, False, False, True]\n",
            "agent won  8120  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.11008171311446599 q value 0.31745641997882296  reward : 1\n",
            "game #num:  14925\n",
            "action not avaliable action<0,8> 5 , satae [1, 1, -1, 0, 0, -1, 0, -1, 1], mask [False, False, False, True, True, False, True, False, False]\n",
            "action not avaliable action<0,8> 2 , satae [1, 1, -1, 1, 0, -1, -1, -1, 1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 5 , satae [1, 1, -1, 1, 0, -1, -1, -1, 1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 5 , satae [1, 1, -1, 1, 0, -1, -1, -1, 1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 0 , satae [1, 1, -1, 1, 0, -1, -1, -1, 1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 1 , satae [1, 1, -1, 1, 0, -1, -1, -1, 1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 1 , satae [1, 1, -1, 1, 0, -1, -1, -1, 1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [1, 1, -1, 1, 0, -1, -1, -1, 1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 2 , satae [1, 1, -1, 1, 0, -1, -1, -1, 1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 5 , satae [1, 1, -1, 1, 0, -1, -1, -1, 1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 1 , satae [1, 1, -1, 1, 0, -1, -1, -1, 1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 5 , satae [1, 1, -1, 1, 0, -1, -1, -1, 1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [1, 1, -1, 1, 0, -1, -1, -1, 1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 1 , satae [1, 1, -1, 1, 0, -1, -1, -1, 1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [1, 1, -1, 1, 0, -1, -1, -1, 1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 5 , satae [1, 1, -1, 1, 0, -1, -1, -1, 1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [1, 1, -1, 1, 0, -1, -1, -1, 1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [1, 1, -1, 1, 0, -1, -1, -1, 1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 5 , satae [1, 1, -1, 1, 0, -1, -1, -1, 1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 1 , satae [1, 1, -1, 1, 0, -1, -1, -1, 1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 0 , satae [1, 1, -1, 1, 0, -1, -1, -1, 1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 0 , satae [1, 1, -1, 1, 0, -1, -1, -1, 1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [1, 1, -1, 1, 0, -1, -1, -1, 1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 3 , satae [1, 1, -1, 1, 0, -1, -1, -1, 1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [1, 1, -1, 1, 0, -1, -1, -1, 1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 1 , satae [1, 1, -1, 1, 0, -1, -1, -1, 1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 1 , satae [1, 1, -1, 1, 0, -1, -1, -1, 1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 1 , satae [1, 1, -1, 1, 0, -1, -1, -1, 1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [1, 1, -1, 1, 0, -1, -1, -1, 1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 2 , satae [1, 1, -1, 1, 0, -1, -1, -1, 1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [1, 1, -1, 1, 0, -1, -1, -1, 1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 2 , satae [1, 1, -1, 1, 0, -1, -1, -1, 1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 1 , satae [1, 1, -1, 1, 0, -1, -1, -1, 1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [1, 1, -1, 1, 0, -1, -1, -1, 1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 5 , satae [1, 1, -1, 1, 0, -1, -1, -1, 1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 3 , satae [1, 1, -1, 1, 0, -1, -1, -1, 1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 5 , satae [1, 1, -1, 1, 0, -1, -1, -1, 1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [1, 1, -1, 1, 0, -1, -1, -1, 1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 1 , satae [1, 1, -1, 1, 0, -1, -1, -1, 1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 1 , satae [1, 1, -1, 1, 0, -1, -1, -1, 1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 2 , satae [1, 1, -1, 1, 0, -1, -1, -1, 1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 5 , satae [1, 1, -1, 1, 0, -1, -1, -1, 1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 1 , satae [1, 1, -1, 1, 0, -1, -1, -1, 1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [1, 1, -1, 1, 0, -1, -1, -1, 1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 5 , satae [1, 1, -1, 1, 0, -1, -1, -1, 1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 3 , satae [1, 1, -1, 1, 0, -1, -1, -1, 1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 2 , satae [1, 1, -1, 1, 0, -1, -1, -1, 1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [1, 1, -1, 1, 0, -1, -1, -1, 1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [1, 1, -1, 1, 0, -1, -1, -1, 1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 2 , satae [1, 1, -1, 1, 0, -1, -1, -1, 1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 1 , satae [1, 1, -1, 1, 0, -1, -1, -1, 1], mask [False, False, False, False, True, False, False, False, False]\n",
            "agent won  8121  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.1143103392262544 q value 0.3163432308605739  reward : 1\n",
            "game #num:  14926\n",
            "agent won  8122  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.1189980407555898 q value 0.3177563746770223  reward : 1\n",
            "game #num:  14927\n",
            "action not avaliable action<0,8> 3 , satae [-1, 0, -1, 1, -1, 0, 1, 1, 0], mask [False, True, False, False, False, True, False, False, True]\n",
            "action not avaliable action<0,8> 2 , satae [-1, 0, -1, 1, -1, 0, 1, 1, 0], mask [False, True, False, False, False, True, False, False, True]\n",
            "action not avaliable action<0,8> 6 , satae [-1, 0, -1, 1, -1, 0, 1, 1, 0], mask [False, True, False, False, False, True, False, False, True]\n",
            "action not avaliable action<0,8> 6 , satae [-1, 0, -1, 1, -1, 0, 1, 1, 0], mask [False, True, False, False, False, True, False, False, True]\n",
            "action not avaliable action<0,8> 0 , satae [-1, 0, -1, 1, -1, 0, 1, 1, 0], mask [False, True, False, False, False, True, False, False, True]\n",
            "mcts won  5345  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.11024890343348186 q value 0.31672580043474835  reward : -1\n",
            "game #num:  14928\n",
            "action not avaliable action<0,8> 8 , satae [0, 0, 0, 0, 0, 0, 0, 0, -1], mask [True, True, True, True, True, True, True, True, False]\n",
            "action not avaliable action<0,8> 8 , satae [0, 0, 0, 1, 0, -1, 0, 0, -1], mask [True, True, True, False, True, False, True, True, False]\n",
            "action not avaliable action<0,8> 5 , satae [0, 0, 0, 1, 0, -1, 0, 0, -1], mask [True, True, True, False, True, False, True, True, False]\n",
            "action not avaliable action<0,8> 8 , satae [0, 0, 0, 1, 0, -1, 0, 0, -1], mask [True, True, True, False, True, False, True, True, False]\n",
            "action not avaliable action<0,8> 8 , satae [0, 0, 0, 1, 0, -1, 0, 0, -1], mask [True, True, True, False, True, False, True, True, False]\n",
            "action not avaliable action<0,8> 8 , satae [0, 0, 0, 1, 0, -1, 0, 0, -1], mask [True, True, True, False, True, False, True, True, False]\n",
            "mcts won  5346  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.11256902292370796 q value 0.3192775845527649  reward : -1\n",
            "game #num:  14929\n",
            "action not avaliable action<0,8> 7 , satae [1, -1, -1, -1, 1, 0, 1, 1, -1], mask [False, False, False, False, False, True, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [1, -1, -1, -1, 1, 0, 1, 1, -1], mask [False, False, False, False, False, True, False, False, False]\n",
            "action not avaliable action<0,8> 4 , satae [1, -1, -1, -1, 1, 0, 1, 1, -1], mask [False, False, False, False, False, True, False, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [1, -1, -1, -1, 1, 0, 1, 1, -1], mask [False, False, False, False, False, True, False, False, False]\n",
            "action not avaliable action<0,8> 0 , satae [1, -1, -1, -1, 1, 0, 1, 1, -1], mask [False, False, False, False, False, True, False, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [1, -1, -1, -1, 1, 0, 1, 1, -1], mask [False, False, False, False, False, True, False, False, False]\n",
            "action not avaliable action<0,8> 4 , satae [1, -1, -1, -1, 1, 0, 1, 1, -1], mask [False, False, False, False, False, True, False, False, False]\n",
            "action not avaliable action<0,8> 3 , satae [1, -1, -1, -1, 1, 0, 1, 1, -1], mask [False, False, False, False, False, True, False, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [1, -1, -1, -1, 1, 0, 1, 1, -1], mask [False, False, False, False, False, True, False, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [1, -1, -1, -1, 1, 0, 1, 1, -1], mask [False, False, False, False, False, True, False, False, False]\n",
            "action not avaliable action<0,8> 0 , satae [1, -1, -1, -1, 1, 0, 1, 1, -1], mask [False, False, False, False, False, True, False, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [1, -1, -1, -1, 1, 0, 1, 1, -1], mask [False, False, False, False, False, True, False, False, False]\n",
            "action not avaliable action<0,8> 0 , satae [1, -1, -1, -1, 1, 0, 1, 1, -1], mask [False, False, False, False, False, True, False, False, False]\n",
            "action not avaliable action<0,8> 3 , satae [1, -1, -1, -1, 1, 0, 1, 1, -1], mask [False, False, False, False, False, True, False, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [1, -1, -1, -1, 1, 0, 1, 1, -1], mask [False, False, False, False, False, True, False, False, False]\n",
            "action not avaliable action<0,8> 3 , satae [1, -1, -1, -1, 1, 0, 1, 1, -1], mask [False, False, False, False, False, True, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [1, -1, -1, -1, 1, 0, 1, 1, -1], mask [False, False, False, False, False, True, False, False, False]\n",
            "action not avaliable action<0,8> 4 , satae [1, -1, -1, -1, 1, 0, 1, 1, -1], mask [False, False, False, False, False, True, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [1, -1, -1, -1, 1, 0, 1, 1, -1], mask [False, False, False, False, False, True, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [1, -1, -1, -1, 1, 0, 1, 1, -1], mask [False, False, False, False, False, True, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [1, -1, -1, -1, 1, 0, 1, 1, -1], mask [False, False, False, False, False, True, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [1, -1, -1, -1, 1, 0, 1, 1, -1], mask [False, False, False, False, False, True, False, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [1, -1, -1, -1, 1, 0, 1, 1, -1], mask [False, False, False, False, False, True, False, False, False]\n",
            "action not avaliable action<0,8> 3 , satae [1, -1, -1, -1, 1, 0, 1, 1, -1], mask [False, False, False, False, False, True, False, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [1, -1, -1, -1, 1, 0, 1, 1, -1], mask [False, False, False, False, False, True, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [1, -1, -1, -1, 1, 0, 1, 1, -1], mask [False, False, False, False, False, True, False, False, False]\n",
            "action not avaliable action<0,8> 2 , satae [1, -1, -1, -1, 1, 0, 1, 1, -1], mask [False, False, False, False, False, True, False, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [1, -1, -1, -1, 1, 0, 1, 1, -1], mask [False, False, False, False, False, True, False, False, False]\n",
            "action not avaliable action<0,8> 0 , satae [1, -1, -1, -1, 1, 0, 1, 1, -1], mask [False, False, False, False, False, True, False, False, False]\n",
            "action not avaliable action<0,8> 0 , satae [1, -1, -1, -1, 1, 0, 1, 1, -1], mask [False, False, False, False, False, True, False, False, False]\n",
            "action not avaliable action<0,8> 2 , satae [1, -1, -1, -1, 1, 0, 1, 1, -1], mask [False, False, False, False, False, True, False, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [1, -1, -1, -1, 1, 0, 1, 1, -1], mask [False, False, False, False, False, True, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [1, -1, -1, -1, 1, 0, 1, 1, -1], mask [False, False, False, False, False, True, False, False, False]\n",
            "action not avaliable action<0,8> 2 , satae [1, -1, -1, -1, 1, 0, 1, 1, -1], mask [False, False, False, False, False, True, False, False, False]\n",
            "action not avaliable action<0,8> 2 , satae [1, -1, -1, -1, 1, 0, 1, 1, -1], mask [False, False, False, False, False, True, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [1, -1, -1, -1, 1, 0, 1, 1, -1], mask [False, False, False, False, False, True, False, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [1, -1, -1, -1, 1, 0, 1, 1, -1], mask [False, False, False, False, False, True, False, False, False]\n",
            "draw  1461  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "################################################################################################\n",
            "game loss:  0.11400812403077171 q value 0.3251610107365109  reward : 0\n",
            "game #num:  14930\n",
            "action not avaliable action<0,8> 7 , satae [-1, 1, 0, -1, 0, 1, 0, -1, 0], mask [False, False, True, False, True, False, True, False, True]\n",
            "action not avaliable action<0,8> 0 , satae [-1, 1, 1, -1, 0, 1, 0, -1, -1], mask [False, False, False, False, True, False, True, False, False]\n",
            "action not avaliable action<0,8> 3 , satae [-1, 1, 1, -1, 0, 1, 0, -1, -1], mask [False, False, False, False, True, False, True, False, False]\n",
            "action not avaliable action<0,8> 3 , satae [-1, 1, 1, -1, 0, 1, 0, -1, -1], mask [False, False, False, False, True, False, True, False, False]\n",
            "agent won  8123  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.1177360424771905 q value 0.31914467737078667  reward : 1\n",
            "game #num:  14931\n",
            "action not avaliable action<0,8> 6 , satae [-1, 1, 0, 1, -1, -1, 1, -1, 1], mask [False, False, True, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 0 , satae [-1, 1, 0, 1, -1, -1, 1, -1, 1], mask [False, False, True, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 1 , satae [-1, 1, 0, 1, -1, -1, 1, -1, 1], mask [False, False, True, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [-1, 1, 0, 1, -1, -1, 1, -1, 1], mask [False, False, True, False, False, False, False, False, False]\n",
            "draw  1462  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "################################################################################################\n",
            "game loss:  0.11107638892200258 q value 0.31530218985345626  reward : 0\n",
            "game #num:  14932\n",
            "action not avaliable action<0,8> 4 , satae [-1, 0, -1, 1, 1, 0, 0, 0, 0], mask [False, True, False, False, False, True, True, True, True]\n",
            "mcts won  5347  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.10659384429454803 q value 0.31377398371696474  reward : -1\n",
            "game #num:  14933\n",
            "agent won  8124  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.112716194242239 q value 0.3143906891345978  reward : 1\n",
            "game #num:  14934\n",
            "action not avaliable action<0,8> 0 , satae [1, 1, -1, -1, 1, 0, 0, -1, -1], mask [False, False, False, False, False, True, True, False, False]\n",
            "action not avaliable action<0,8> 2 , satae [1, 1, -1, -1, 1, 0, 0, -1, -1], mask [False, False, False, False, False, True, True, False, False]\n",
            "action not avaliable action<0,8> 3 , satae [1, 1, -1, -1, 1, 0, 0, -1, -1], mask [False, False, False, False, False, True, True, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [1, 1, -1, -1, 1, 0, 0, -1, -1], mask [False, False, False, False, False, True, True, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [1, 1, -1, -1, 1, 0, 0, -1, -1], mask [False, False, False, False, False, True, True, False, False]\n",
            "mcts won  5348  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.12202367766035928 q value 0.3142947554588318  reward : -1\n",
            "game #num:  14935\n",
            "action not avaliable action<0,8> 1 , satae [-1, 1, -1, 1, 0, -1, -1, 1, 0], mask [False, False, False, False, True, False, False, False, True]\n",
            "action not avaliable action<0,8> 1 , satae [-1, 1, -1, 1, 0, -1, -1, 1, 0], mask [False, False, False, False, True, False, False, False, True]\n",
            "mcts won  5349  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.11576040213306744 q value 0.31393585602442425  reward : -1\n",
            "game #num:  14936\n",
            "action not avaliable action<0,8> 4 , satae [0, 1, -1, 0, -1, 0, 0, 0, 0], mask [True, False, False, True, False, True, True, True, True]\n",
            "action not avaliable action<0,8> 1 , satae [0, 1, -1, 1, -1, 0, 0, -1, 0], mask [True, False, False, False, False, True, True, False, True]\n",
            "action not avaliable action<0,8> 1 , satae [0, 1, -1, 1, -1, 0, 0, -1, 0], mask [True, False, False, False, False, True, True, False, True]\n",
            "action not avaliable action<0,8> 4 , satae [0, 1, -1, 1, -1, 0, 0, -1, 0], mask [True, False, False, False, False, True, True, False, True]\n",
            "action not avaliable action<0,8> 0 , satae [-1, 1, -1, 1, -1, 1, 0, -1, 0], mask [False, False, False, False, False, False, True, False, True]\n",
            "action not avaliable action<0,8> 3 , satae [-1, 1, -1, 1, -1, 1, 0, -1, 0], mask [False, False, False, False, False, False, True, False, True]\n",
            "mcts won  5350  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.12265869826078415 q value 0.31139186322689055  reward : -1\n",
            "game #num:  14937\n",
            "action not avaliable action<0,8> 6 , satae [0, -1, -1, 1, 0, -1, 1, 0, 0], mask [True, False, False, False, True, False, False, True, True]\n",
            "mcts won  5351  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.11391776241362095 q value 0.3103002533316612  reward : -1\n",
            "game #num:  14938\n",
            "agent won  8125  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.11415894329547882 q value 0.31078710158665973  reward : 1\n",
            "game #num:  14939\n",
            "action not avaliable action<0,8> 7 , satae [1, 0, -1, 1, 0, 1, 0, -1, -1], mask [False, True, False, False, True, False, True, False, False]\n",
            "action not avaliable action<0,8> 3 , satae [1, 0, -1, 1, 0, 1, 0, -1, -1], mask [False, True, False, False, True, False, True, False, False]\n",
            "action not avaliable action<0,8> 2 , satae [1, 0, -1, 1, 0, 1, 0, -1, -1], mask [False, True, False, False, True, False, True, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [1, 0, -1, 1, 0, 1, 0, -1, -1], mask [False, True, False, False, True, False, True, False, False]\n",
            "agent won  8126  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.1156626408919692 q value 0.31262683123350143  reward : 1\n",
            "game #num:  14940\n",
            "action not avaliable action<0,8> 4 , satae [0, -1, 0, 0, 1, 0, 0, 0, -1], mask [True, False, True, True, False, True, True, True, False]\n",
            "action not avaliable action<0,8> 0 , satae [1, -1, 0, 0, 1, 0, 0, -1, -1], mask [False, False, True, True, False, True, True, False, False]\n",
            "action not avaliable action<0,8> 1 , satae [1, -1, 0, 0, 1, 0, 0, -1, -1], mask [False, False, True, True, False, True, True, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [1, -1, 0, 0, 1, 0, 0, -1, -1], mask [False, False, True, True, False, True, True, False, False]\n",
            "mcts won  5352  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.10873565636575222 q value 0.31565963476896286  reward : -1\n",
            "game #num:  14941\n",
            "action not avaliable action<0,8> 2 , satae [-1, 1, 1, -1, 1, 0, 0, -1, 0], mask [False, False, False, False, False, True, True, False, True]\n",
            "action not avaliable action<0,8> 0 , satae [-1, 1, 1, -1, 1, 0, 0, -1, 0], mask [False, False, False, False, False, True, True, False, True]\n",
            "action not avaliable action<0,8> 4 , satae [-1, 1, 1, -1, 1, 0, 0, -1, 0], mask [False, False, False, False, False, True, True, False, True]\n",
            "action not avaliable action<0,8> 4 , satae [-1, 1, 1, -1, 1, 0, 0, -1, 0], mask [False, False, False, False, False, True, True, False, True]\n",
            "action not avaliable action<0,8> 3 , satae [-1, 1, 1, -1, 1, 0, 0, -1, 0], mask [False, False, False, False, False, True, True, False, True]\n",
            "action not avaliable action<0,8> 3 , satae [-1, 1, 1, -1, 1, 0, 0, -1, 0], mask [False, False, False, False, False, True, True, False, True]\n",
            "action not avaliable action<0,8> 3 , satae [-1, 1, 1, -1, 1, 0, 0, -1, 0], mask [False, False, False, False, False, True, True, False, True]\n",
            "action not avaliable action<0,8> 1 , satae [-1, 1, 1, -1, 1, 0, 0, -1, 0], mask [False, False, False, False, False, True, True, False, True]\n",
            "action not avaliable action<0,8> 1 , satae [-1, 1, 1, -1, 1, 0, 0, -1, 0], mask [False, False, False, False, False, True, True, False, True]\n",
            "action not avaliable action<0,8> 7 , satae [-1, 1, 1, -1, 1, 0, 0, -1, 0], mask [False, False, False, False, False, True, True, False, True]\n",
            "mcts won  5353  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.1038888618350029 q value 0.3218998738697597  reward : -1\n",
            "game #num:  14942\n",
            "action not avaliable action<0,8> 6 , satae [-1, 1, -1, 0, -1, -1, 1, 0, 1], mask [False, False, False, True, False, False, False, True, False]\n",
            "action not avaliable action<0,8> 2 , satae [-1, 1, -1, 0, -1, -1, 1, 0, 1], mask [False, False, False, True, False, False, False, True, False]\n",
            "action not avaliable action<0,8> 0 , satae [-1, 1, -1, 0, -1, -1, 1, 0, 1], mask [False, False, False, True, False, False, False, True, False]\n",
            "action not avaliable action<0,8> 8 , satae [-1, 1, -1, 0, -1, -1, 1, 0, 1], mask [False, False, False, True, False, False, False, True, False]\n",
            "action not avaliable action<0,8> 5 , satae [-1, 1, -1, 0, -1, -1, 1, 0, 1], mask [False, False, False, True, False, False, False, True, False]\n",
            "action not avaliable action<0,8> 5 , satae [-1, 1, -1, 0, -1, -1, 1, 0, 1], mask [False, False, False, True, False, False, False, True, False]\n",
            "action not avaliable action<0,8> 0 , satae [-1, 1, -1, 0, -1, -1, 1, 0, 1], mask [False, False, False, True, False, False, False, True, False]\n",
            "agent won  8127  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.11414791643619537 q value 0.32508718967437744  reward : 1\n",
            "game #num:  14943\n",
            "action not avaliable action<0,8> 8 , satae [0, -1, 0, 0, 0, 0, 0, 1, -1], mask [True, False, True, True, True, True, True, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [0, -1, 0, 0, 0, 0, 0, 1, -1], mask [True, False, True, True, True, True, True, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [0, -1, 0, 0, 0, 0, 0, 1, -1], mask [True, False, True, True, True, True, True, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [0, -1, 0, 0, 0, 0, 0, 1, -1], mask [True, False, True, True, True, True, True, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [0, -1, 0, 0, 0, 0, 0, 1, -1], mask [True, False, True, True, True, True, True, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [1, -1, 0, 0, 0, -1, 0, 1, -1], mask [False, False, True, True, True, False, True, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [1, -1, 0, 0, 0, -1, 0, 1, -1], mask [False, False, True, True, True, False, True, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [1, -1, 0, 0, 0, -1, 0, 1, -1], mask [False, False, True, True, True, False, True, False, False]\n",
            "action not avaliable action<0,8> 1 , satae [1, -1, 0, 0, 0, -1, 0, 1, -1], mask [False, False, True, True, True, False, True, False, False]\n",
            "action not avaliable action<0,8> 5 , satae [1, -1, 0, 1, 0, -1, -1, 1, -1], mask [False, False, True, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 0 , satae [1, -1, 0, 1, 0, -1, -1, 1, -1], mask [False, False, True, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [1, -1, 0, 1, 0, -1, -1, 1, -1], mask [False, False, True, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [1, -1, 0, 1, 0, -1, -1, 1, -1], mask [False, False, True, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [1, -1, 0, 1, 0, -1, -1, 1, -1], mask [False, False, True, False, True, False, False, False, False]\n",
            "draw  1463  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "################################################################################################\n",
            "game loss:  0.11635234496659702 q value 0.3235153655211131  reward : 0\n",
            "game #num:  14944\n",
            "action not avaliable action<0,8> 7 , satae [1, -1, 1, -1, 0, -1, -1, 1, 0], mask [False, False, False, False, True, False, False, False, True]\n",
            "draw  1464  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0]\n",
            "################################################################################################\n",
            "game loss:  0.11090232580900192 q value 0.3213710904121399  reward : 0\n",
            "game #num:  14945\n",
            "action not avaliable action<0,8> 5 , satae [0, 1, 0, 1, -1, -1, -1, 0, 0], mask [True, False, True, False, False, False, False, True, True]\n",
            "action not avaliable action<0,8> 1 , satae [0, 1, 0, 1, -1, -1, -1, 0, 0], mask [True, False, True, False, False, False, False, True, True]\n",
            "action not avaliable action<0,8> 6 , satae [0, 1, 0, 1, -1, -1, -1, 0, 0], mask [True, False, True, False, False, False, False, True, True]\n",
            "action not avaliable action<0,8> 3 , satae [0, 1, 0, 1, -1, -1, -1, 0, 0], mask [True, False, True, False, False, False, False, True, True]\n",
            "action not avaliable action<0,8> 1 , satae [0, 1, 0, 1, -1, -1, -1, 0, 0], mask [True, False, True, False, False, False, False, True, True]\n",
            "action not avaliable action<0,8> 3 , satae [0, 1, 0, 1, -1, -1, -1, 0, 0], mask [True, False, True, False, False, False, False, True, True]\n",
            "action not avaliable action<0,8> 3 , satae [0, 1, 0, 1, -1, -1, -1, 0, 0], mask [True, False, True, False, False, False, False, True, True]\n",
            "agent won  8128  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.10793591216206551 q value 0.3184948265552521  reward : 1\n",
            "game #num:  14946\n",
            "action not avaliable action<0,8> 0 , satae [-1, -1, 0, 0, 0, 0, 0, 0, 1], mask [False, False, True, True, True, True, True, True, False]\n",
            "action not avaliable action<0,8> 0 , satae [-1, -1, 0, 1, 0, -1, 0, 0, 1], mask [False, False, True, False, True, False, True, True, False]\n",
            "action not avaliable action<0,8> 1 , satae [-1, -1, 1, 1, 0, -1, 0, -1, 1], mask [False, False, False, False, True, False, True, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [-1, -1, 1, 1, 0, -1, 0, -1, 1], mask [False, False, False, False, True, False, True, False, False]\n",
            "action not avaliable action<0,8> 1 , satae [-1, -1, 1, 1, 0, -1, 0, -1, 1], mask [False, False, False, False, True, False, True, False, False]\n",
            "action not avaliable action<0,8> 5 , satae [-1, -1, 1, 1, 0, -1, 0, -1, 1], mask [False, False, False, False, True, False, True, False, False]\n",
            "action not avaliable action<0,8> 0 , satae [-1, -1, 1, 1, 0, -1, 0, -1, 1], mask [False, False, False, False, True, False, True, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [-1, -1, 1, 1, 0, -1, 0, -1, 1], mask [False, False, False, False, True, False, True, False, False]\n",
            "action not avaliable action<0,8> 2 , satae [-1, -1, 1, 1, 0, -1, 0, -1, 1], mask [False, False, False, False, True, False, True, False, False]\n",
            "action not avaliable action<0,8> 2 , satae [-1, -1, 1, 1, 0, -1, 0, -1, 1], mask [False, False, False, False, True, False, True, False, False]\n",
            "action not avaliable action<0,8> 0 , satae [-1, -1, 1, 1, 0, -1, 0, -1, 1], mask [False, False, False, False, True, False, True, False, False]\n",
            "action not avaliable action<0,8> 5 , satae [-1, -1, 1, 1, 0, -1, 0, -1, 1], mask [False, False, False, False, True, False, True, False, False]\n",
            "action not avaliable action<0,8> 3 , satae [-1, -1, 1, 1, 0, -1, 0, -1, 1], mask [False, False, False, False, True, False, True, False, False]\n",
            "draw  1465  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "################################################################################################\n",
            "game loss:  0.11396577472195905 q value 0.3169014243518605  reward : 0\n",
            "game #num:  14947\n",
            "action not avaliable action<0,8> 7 , satae [0, 0, -1, 1, -1, 0, 0, 1, 0], mask [True, True, False, False, False, True, True, False, True]\n",
            "action not avaliable action<0,8> 4 , satae [0, 0, -1, 1, -1, 0, 0, 1, 0], mask [True, True, False, False, False, True, True, False, True]\n",
            "mcts won  5354  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.10754751861095428 q value 0.3192014515399933  reward : -1\n",
            "game #num:  14948\n",
            "agent won  8129  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.10335865803062916 q value 0.31975051760673523  reward : 1\n",
            "game #num:  14949\n",
            "action not avaliable action<0,8> 5 , satae [0, 0, -1, -1, 0, 1, 0, 1, 0], mask [True, True, False, False, True, False, True, False, True]\n",
            "action not avaliable action<0,8> 2 , satae [0, 0, -1, -1, 0, 1, 0, 1, 0], mask [True, True, False, False, True, False, True, False, True]\n",
            "agent won  8130  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.11516241605083148 q value 0.3200228065252304  reward : 1\n",
            "game #num:  14950\n",
            "mcts won  5355  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.09921051561832428 q value 0.3213408788045247  reward : -1\n",
            "game #num:  14951\n",
            "action not avaliable action<0,8> 6 , satae [1, -1, 1, 0, 0, 0, -1, -1, 0], mask [False, False, False, True, True, True, False, False, True]\n",
            "mcts won  5356  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.10389488190412521 q value 0.32327864319086075  reward : -1\n",
            "game #num:  14952\n",
            "action not avaliable action<0,8> 0 , satae [-1, 1, 0, 0, 0, 0, 0, 0, -1], mask [False, False, True, True, True, True, True, True, False]\n",
            "action not avaliable action<0,8> 1 , satae [-1, 1, 0, -1, 0, 0, 1, 0, -1], mask [False, False, True, False, True, True, False, True, False]\n",
            "action not avaliable action<0,8> 6 , satae [-1, 1, 1, -1, 0, -1, 1, 0, -1], mask [False, False, False, False, True, False, False, True, False]\n",
            "action not avaliable action<0,8> 3 , satae [-1, 1, 1, -1, 0, -1, 1, 0, -1], mask [False, False, False, False, True, False, False, True, False]\n",
            "action not avaliable action<0,8> 6 , satae [-1, 1, 1, -1, 0, -1, 1, 0, -1], mask [False, False, False, False, True, False, False, True, False]\n",
            "action not avaliable action<0,8> 5 , satae [-1, 1, 1, -1, 0, -1, 1, 0, -1], mask [False, False, False, False, True, False, False, True, False]\n",
            "action not avaliable action<0,8> 5 , satae [-1, 1, 1, -1, 0, -1, 1, 0, -1], mask [False, False, False, False, True, False, False, True, False]\n",
            "action not avaliable action<0,8> 2 , satae [-1, 1, 1, -1, 0, -1, 1, 0, -1], mask [False, False, False, False, True, False, False, True, False]\n",
            "action not avaliable action<0,8> 0 , satae [-1, 1, 1, -1, 0, -1, 1, 0, -1], mask [False, False, False, False, True, False, False, True, False]\n",
            "action not avaliable action<0,8> 1 , satae [-1, 1, 1, -1, 0, -1, 1, 0, -1], mask [False, False, False, False, True, False, False, True, False]\n",
            "action not avaliable action<0,8> 6 , satae [-1, 1, 1, -1, 0, -1, 1, 0, -1], mask [False, False, False, False, True, False, False, True, False]\n",
            "action not avaliable action<0,8> 0 , satae [-1, 1, 1, -1, 0, -1, 1, 0, -1], mask [False, False, False, False, True, False, False, True, False]\n",
            "action not avaliable action<0,8> 1 , satae [-1, 1, 1, -1, 0, -1, 1, 0, -1], mask [False, False, False, False, True, False, False, True, False]\n",
            "action not avaliable action<0,8> 5 , satae [-1, 1, 1, -1, 0, -1, 1, 0, -1], mask [False, False, False, False, True, False, False, True, False]\n",
            "action not avaliable action<0,8> 2 , satae [-1, 1, 1, -1, 0, -1, 1, 0, -1], mask [False, False, False, False, True, False, False, True, False]\n",
            "agent won  8131  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.11316960383402674 q value 0.3223629578163749  reward : 1\n",
            "game #num:  14953\n",
            "action not avaliable action<0,8> 4 , satae [-1, 0, -1, 0, 1, 1, -1, 0, 0], mask [False, True, False, True, False, False, False, True, True]\n",
            "action not avaliable action<0,8> 5 , satae [-1, 0, -1, 0, 1, 1, -1, 0, 0], mask [False, True, False, True, False, False, False, True, True]\n",
            "agent won  8132  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.11248005628585815 q value 0.321288138628006  reward : 1\n",
            "game #num:  14954\n",
            "agent won  8133  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.10936268605291843 q value 0.3223412558436394  reward : 1\n",
            "game #num:  14955\n",
            "action not avaliable action<0,8> 4 , satae [0, 0, 0, 0, 1, -1, -1, 0, 0], mask [True, True, True, True, False, False, False, True, True]\n",
            "action not avaliable action<0,8> 0 , satae [-1, -1, 1, 1, 1, -1, -1, 0, 0], mask [False, False, False, False, False, False, False, True, True]\n",
            "action not avaliable action<0,8> 4 , satae [-1, -1, 1, 1, 1, -1, -1, 0, 0], mask [False, False, False, False, False, False, False, True, True]\n",
            "draw  1466  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0]\n",
            "################################################################################################\n",
            "game loss:  0.10965611785650253 q value 0.32147099716322763  reward : 0\n",
            "game #num:  14956\n",
            "action not avaliable action<0,8> 5 , satae [0, 1, 0, 0, 0, -1, 0, 0, 0], mask [True, False, True, True, True, False, True, True, True]\n",
            "action not avaliable action<0,8> 5 , satae [-1, 1, 0, 0, 0, -1, 1, 0, 0], mask [False, False, True, True, True, False, False, True, True]\n",
            "action not avaliable action<0,8> 6 , satae [-1, 1, 1, 0, 0, -1, 1, 0, -1], mask [False, False, False, True, True, False, False, True, False]\n",
            "action not avaliable action<0,8> 0 , satae [-1, 1, 1, 0, 0, -1, 1, 0, -1], mask [False, False, False, True, True, False, False, True, False]\n",
            "action not avaliable action<0,8> 1 , satae [-1, 1, 1, 0, 0, -1, 1, 0, -1], mask [False, False, False, True, True, False, False, True, False]\n",
            "action not avaliable action<0,8> 2 , satae [-1, 1, 1, 0, 0, -1, 1, 0, -1], mask [False, False, False, True, True, False, False, True, False]\n",
            "action not avaliable action<0,8> 1 , satae [-1, 1, 1, 0, 0, -1, 1, 0, -1], mask [False, False, False, True, True, False, False, True, False]\n",
            "action not avaliable action<0,8> 6 , satae [-1, 1, 1, 0, 0, -1, 1, 0, -1], mask [False, False, False, True, True, False, False, True, False]\n",
            "action not avaliable action<0,8> 2 , satae [-1, 1, 1, 0, 0, -1, 1, 0, -1], mask [False, False, False, True, True, False, False, True, False]\n",
            "action not avaliable action<0,8> 5 , satae [-1, 1, 1, 0, 0, -1, 1, 0, -1], mask [False, False, False, True, True, False, False, True, False]\n",
            "action not avaliable action<0,8> 6 , satae [-1, 1, 1, 0, 0, -1, 1, 0, -1], mask [False, False, False, True, True, False, False, True, False]\n",
            "action not avaliable action<0,8> 1 , satae [-1, 1, 1, 0, 0, -1, 1, 0, -1], mask [False, False, False, True, True, False, False, True, False]\n",
            "action not avaliable action<0,8> 2 , satae [-1, 1, 1, 0, 0, -1, 1, 0, -1], mask [False, False, False, True, True, False, False, True, False]\n",
            "mcts won  5357  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.10999292748815873 q value 0.3228484357104582  reward : -1\n",
            "game #num:  14957\n",
            "action not avaliable action<0,8> 4 , satae [0, 1, 0, -1, 1, -1, -1, 0, 0], mask [True, False, True, False, False, False, False, True, True]\n",
            "action not avaliable action<0,8> 4 , satae [0, 1, 0, -1, 1, -1, -1, 0, 0], mask [True, False, True, False, False, False, False, True, True]\n",
            "action not avaliable action<0,8> 8 , satae [0, 1, 1, -1, 1, -1, -1, 0, -1], mask [True, False, False, False, False, False, False, True, False]\n",
            "action not avaliable action<0,8> 1 , satae [0, 1, 1, -1, 1, -1, -1, 0, -1], mask [True, False, False, False, False, False, False, True, False]\n",
            "action not avaliable action<0,8> 1 , satae [0, 1, 1, -1, 1, -1, -1, 0, -1], mask [True, False, False, False, False, False, False, True, False]\n",
            "action not avaliable action<0,8> 1 , satae [0, 1, 1, -1, 1, -1, -1, 0, -1], mask [True, False, False, False, False, False, False, True, False]\n",
            "agent won  8134  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.10915480852127075 q value 0.32445969581604006  reward : 1\n",
            "game #num:  14958\n",
            "agent won  8135  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.11180855830510457 q value 0.3241274853547414  reward : 1\n",
            "game #num:  14959\n",
            "action not avaliable action<0,8> 1 , satae [-1, 1, -1, 0, 0, 0, -1, 0, 1], mask [False, False, False, True, True, True, False, True, False]\n",
            "action not avaliable action<0,8> 2 , satae [-1, 1, -1, 0, 0, 0, -1, 0, 1], mask [False, False, False, True, True, True, False, True, False]\n",
            "agent won  8136  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.10996228829026222 q value 0.32283959289391834  reward : 1\n",
            "game #num:  14960\n",
            "action not avaliable action<0,8> 6 , satae [-1, -1, 1, 0, 0, 0, 1, -1, 0], mask [False, False, False, True, True, True, False, False, True]\n",
            "action not avaliable action<0,8> 2 , satae [-1, -1, 1, 0, 0, 0, 1, -1, 0], mask [False, False, False, True, True, True, False, False, True]\n",
            "agent won  8137  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.11411700248718262 q value 0.3219177067279816  reward : 1\n",
            "game #num:  14961\n",
            "action not avaliable action<0,8> 7 , satae [0, 0, 0, 0, 0, 0, -1, 1, 0], mask [True, True, True, True, True, True, False, False, True]\n",
            "action not avaliable action<0,8> 6 , satae [0, 0, 0, 0, 0, 0, -1, 1, 0], mask [True, True, True, True, True, True, False, False, True]\n",
            "action not avaliable action<0,8> 2 , satae [-1, 0, 1, 1, -1, -1, -1, 1, 1], mask [False, True, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [-1, 0, 1, 1, -1, -1, -1, 1, 1], mask [False, True, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 3 , satae [-1, 0, 1, 1, -1, -1, -1, 1, 1], mask [False, True, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [-1, 0, 1, 1, -1, -1, -1, 1, 1], mask [False, True, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 3 , satae [-1, 0, 1, 1, -1, -1, -1, 1, 1], mask [False, True, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [-1, 0, 1, 1, -1, -1, -1, 1, 1], mask [False, True, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 2 , satae [-1, 0, 1, 1, -1, -1, -1, 1, 1], mask [False, True, False, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [-1, 0, 1, 1, -1, -1, -1, 1, 1], mask [False, True, False, False, False, False, False, False, False]\n",
            "draw  1467  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "################################################################################################\n",
            "game loss:  0.11532608419656754 q value 0.32073268095652263  reward : 0\n",
            "game #num:  14962\n",
            "mcts won  5358  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.12628122667471567 q value 0.31896700461705524  reward : -1\n",
            "game #num:  14963\n",
            "action not avaliable action<0,8> 8 , satae [-1, 0, 0, 1, 0, 0, 1, 0, -1], mask [False, True, True, False, True, True, False, True, False]\n",
            "action not avaliable action<0,8> 8 , satae [-1, 0, 0, 1, 0, 0, 1, 0, -1], mask [False, True, True, False, True, True, False, True, False]\n",
            "action not avaliable action<0,8> 3 , satae [-1, 1, 0, 1, 0, -1, 1, 0, -1], mask [False, False, True, False, True, False, False, True, False]\n",
            "action not avaliable action<0,8> 1 , satae [-1, 1, 0, 1, 0, -1, 1, 0, -1], mask [False, False, True, False, True, False, False, True, False]\n",
            "action not avaliable action<0,8> 5 , satae [-1, 1, 0, 1, 0, -1, 1, 0, -1], mask [False, False, True, False, True, False, False, True, False]\n",
            "action not avaliable action<0,8> 5 , satae [-1, 1, 0, 1, 0, -1, 1, 0, -1], mask [False, False, True, False, True, False, False, True, False]\n",
            "action not avaliable action<0,8> 6 , satae [-1, 1, 0, 1, 0, -1, 1, 0, -1], mask [False, False, True, False, True, False, False, True, False]\n",
            "action not avaliable action<0,8> 5 , satae [-1, 1, 0, 1, 0, -1, 1, 0, -1], mask [False, False, True, False, True, False, False, True, False]\n",
            "action not avaliable action<0,8> 1 , satae [-1, 1, 0, 1, 0, -1, 1, 0, -1], mask [False, False, True, False, True, False, False, True, False]\n",
            "action not avaliable action<0,8> 6 , satae [-1, 1, 0, 1, 0, -1, 1, 0, -1], mask [False, False, True, False, True, False, False, True, False]\n",
            "action not avaliable action<0,8> 3 , satae [-1, 1, 1, 1, 0, -1, 1, -1, -1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 0 , satae [-1, 1, 1, 1, 0, -1, 1, -1, -1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 0 , satae [-1, 1, 1, 1, 0, -1, 1, -1, -1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [-1, 1, 1, 1, 0, -1, 1, -1, -1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [-1, 1, 1, 1, 0, -1, 1, -1, -1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [-1, 1, 1, 1, 0, -1, 1, -1, -1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 2 , satae [-1, 1, 1, 1, 0, -1, 1, -1, -1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [-1, 1, 1, 1, 0, -1, 1, -1, -1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 2 , satae [-1, 1, 1, 1, 0, -1, 1, -1, -1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [-1, 1, 1, 1, 0, -1, 1, -1, -1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [-1, 1, 1, 1, 0, -1, 1, -1, -1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [-1, 1, 1, 1, 0, -1, 1, -1, -1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [-1, 1, 1, 1, 0, -1, 1, -1, -1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [-1, 1, 1, 1, 0, -1, 1, -1, -1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [-1, 1, 1, 1, 0, -1, 1, -1, -1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [-1, 1, 1, 1, 0, -1, 1, -1, -1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 2 , satae [-1, 1, 1, 1, 0, -1, 1, -1, -1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [-1, 1, 1, 1, 0, -1, 1, -1, -1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 1 , satae [-1, 1, 1, 1, 0, -1, 1, -1, -1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [-1, 1, 1, 1, 0, -1, 1, -1, -1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 0 , satae [-1, 1, 1, 1, 0, -1, 1, -1, -1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 3 , satae [-1, 1, 1, 1, 0, -1, 1, -1, -1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [-1, 1, 1, 1, 0, -1, 1, -1, -1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [-1, 1, 1, 1, 0, -1, 1, -1, -1], mask [False, False, False, False, True, False, False, False, False]\n",
            "agent won  8138  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.11370967825253804 q value 0.32163956608527744  reward : 1\n",
            "game #num:  14964\n",
            "action not avaliable action<0,8> 2 , satae [0, 1, 1, 0, -1, -1, 0, 0, 0], mask [True, False, False, True, False, False, True, True, True]\n",
            "action not avaliable action<0,8> 1 , satae [-1, 1, 1, 0, -1, -1, 0, 1, 0], mask [False, False, False, True, False, False, True, False, True]\n",
            "agent won  8139  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.11625726769367854 q value 0.3207698514064153  reward : 1\n",
            "game #num:  14965\n",
            "action not avaliable action<0,8> 7 , satae [0, 1, -1, 0, 0, 0, 0, -1, 0], mask [True, False, False, True, True, True, True, False, True]\n",
            "action not avaliable action<0,8> 1 , satae [0, 1, -1, 0, 0, 0, 0, -1, 0], mask [True, False, False, True, True, True, True, False, True]\n",
            "action not avaliable action<0,8> 6 , satae [0, 1, -1, -1, 0, 0, 1, -1, 0], mask [True, False, False, False, True, True, False, False, True]\n",
            "draw  1468  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0]\n",
            "################################################################################################\n",
            "game loss:  0.10878466495445796 q value 0.31768363288470675  reward : 0\n",
            "game #num:  14966\n",
            "action not avaliable action<0,8> 7 , satae [0, 0, 0, 0, -1, 1, 0, -1, 0], mask [True, True, True, True, False, False, True, False, True]\n",
            "mcts won  5359  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.1275823451578617 q value 0.31711167842149734  reward : -1\n",
            "game #num:  14967\n",
            "action not avaliable action<0,8> 7 , satae [-1, 1, 0, 0, 1, 0, 0, -1, -1], mask [False, False, True, True, False, True, True, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [-1, 1, 0, 1, 1, -1, 0, -1, -1], mask [False, False, True, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 1 , satae [-1, 1, 0, 1, 1, -1, 0, -1, -1], mask [False, False, True, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [-1, 1, 0, 1, 1, -1, 0, -1, -1], mask [False, False, True, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 5 , satae [-1, 1, 0, 1, 1, -1, 0, -1, -1], mask [False, False, True, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [-1, 1, 0, 1, 1, -1, 0, -1, -1], mask [False, False, True, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 5 , satae [-1, 1, 0, 1, 1, -1, 0, -1, -1], mask [False, False, True, False, False, False, True, False, False]\n",
            "mcts won  5360  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.11519004878672687 q value 0.31505192951722577  reward : -1\n",
            "game #num:  14968\n",
            "mcts won  5361  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.11530300974845886 q value 0.31187230348587036  reward : -1\n",
            "game #num:  14969\n",
            "action not avaliable action<0,8> 0 , satae [1, 0, 0, 0, 0, 0, 0, 0, -1], mask [False, True, True, True, True, True, True, True, False]\n",
            "action not avaliable action<0,8> 7 , satae [1, 0, 0, 0, 0, 0, 1, -1, -1], mask [False, True, True, True, True, True, False, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [1, -1, 0, 0, 0, 1, 1, -1, -1], mask [False, False, True, True, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 5 , satae [1, -1, 0, 0, 0, 1, 1, -1, -1], mask [False, False, True, True, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [1, -1, 0, 0, 0, 1, 1, -1, -1], mask [False, False, True, True, True, False, False, False, False]\n",
            "agent won  8140  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.11632237914535734 q value 0.3104499578475952  reward : 1\n",
            "game #num:  14970\n",
            "action not avaliable action<0,8> 2 , satae [-1, 0, 1, 0, 0, 0, 0, -1, 1], mask [False, True, False, True, True, True, True, False, False]\n",
            "mcts won  5362  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.11271310783922672 q value 0.308909609913826  reward : -1\n",
            "game #num:  14971\n",
            "action not avaliable action<0,8> 5 , satae [0, -1, 0, 0, 0, 1, 0, 0, 0], mask [True, False, True, True, True, False, True, True, True]\n",
            "action not avaliable action<0,8> 5 , satae [0, -1, 0, -1, 0, 1, 0, 1, 0], mask [True, False, True, False, True, False, True, False, True]\n",
            "action not avaliable action<0,8> 7 , satae [0, -1, 0, -1, 0, 1, 0, 1, 0], mask [True, False, True, False, True, False, True, False, True]\n",
            "action not avaliable action<0,8> 6 , satae [0, -1, -1, -1, 1, 1, 1, 1, -1], mask [True, False, False, False, False, False, False, False, False]\n",
            "agent won  8141  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.1164699685242441 q value 0.3076803419325087  reward : 1\n",
            "game #num:  14972\n",
            "action not avaliable action<0,8> 3 , satae [0, -1, 0, 1, 0, 0, 0, 0, 0], mask [True, False, True, False, True, True, True, True, True]\n",
            "action not avaliable action<0,8> 3 , satae [0, -1, 0, 1, 0, 0, 0, 0, 0], mask [True, False, True, False, True, True, True, True, True]\n",
            "action not avaliable action<0,8> 1 , satae [0, -1, 0, 1, 0, 0, 0, 0, 0], mask [True, False, True, False, True, True, True, True, True]\n",
            "action not avaliable action<0,8> 7 , satae [0, -1, 0, 1, 0, 1, 0, -1, 0], mask [True, False, True, False, True, False, True, False, True]\n",
            "agent won  8142  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.11769666416304451 q value 0.30637122477803913  reward : 1\n",
            "game #num:  14973\n",
            "action not avaliable action<0,8> 4 , satae [0, 1, 0, -1, 1, -1, 0, 0, -1], mask [True, False, True, False, False, False, True, True, False]\n",
            "action not avaliable action<0,8> 3 , satae [0, 1, 0, -1, 1, -1, 0, 0, -1], mask [True, False, True, False, False, False, True, True, False]\n",
            "mcts won  5363  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.11172359883785248 q value 0.3071407675743103  reward : -1\n",
            "game #num:  14974\n",
            "action not avaliable action<0,8> 4 , satae [-1, 1, 1, 0, -1, 0, 0, -1, 1], mask [False, False, False, True, False, True, True, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [-1, 1, 1, 1, -1, 0, -1, -1, 1], mask [False, False, False, False, False, True, False, False, False]\n",
            "action not avaliable action<0,8> 1 , satae [-1, 1, 1, 1, -1, 0, -1, -1, 1], mask [False, False, False, False, False, True, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [-1, 1, 1, 1, -1, 0, -1, -1, 1], mask [False, False, False, False, False, True, False, False, False]\n",
            "draw  1469  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "################################################################################################\n",
            "game loss:  0.11135848611593246 q value 0.3101209070947435  reward : 0\n",
            "game #num:  14975\n",
            "action not avaliable action<0,8> 7 , satae [0, 0, -1, 0, -1, 0, 0, 1, 0], mask [True, True, False, True, False, True, True, False, True]\n",
            "action not avaliable action<0,8> 7 , satae [0, 0, -1, 1, -1, -1, 0, 1, 0], mask [True, True, False, False, False, False, True, False, True]\n",
            "action not avaliable action<0,8> 2 , satae [0, 0, -1, 1, -1, -1, 0, 1, 0], mask [True, True, False, False, False, False, True, False, True]\n",
            "action not avaliable action<0,8> 3 , satae [0, 0, -1, 1, -1, -1, 0, 1, 0], mask [True, True, False, False, False, False, True, False, True]\n",
            "action not avaliable action<0,8> 2 , satae [0, 0, -1, 1, -1, -1, 0, 1, 0], mask [True, True, False, False, False, False, True, False, True]\n",
            "action not avaliable action<0,8> 8 , satae [0, -1, -1, 1, -1, -1, 0, 1, 1], mask [True, False, False, False, False, False, True, False, False]\n",
            "agent won  8143  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.11776117086410523 q value 0.31361517012119294  reward : 1\n",
            "game #num:  14976\n",
            "action not avaliable action<0,8> 0 , satae [-1, 0, 0, 0, 0, 1, -1, 0, 0], mask [False, True, True, True, True, False, False, True, True]\n",
            "action not avaliable action<0,8> 7 , satae [-1, 0, 1, 0, 0, 1, -1, -1, 0], mask [False, True, False, True, True, False, False, False, True]\n",
            "action not avaliable action<0,8> 7 , satae [-1, 0, 1, 0, 0, 1, -1, -1, 0], mask [False, True, False, True, True, False, False, False, True]\n",
            "action not avaliable action<0,8> 6 , satae [-1, 0, 1, 0, 0, 1, -1, -1, 0], mask [False, True, False, True, True, False, False, False, True]\n",
            "action not avaliable action<0,8> 7 , satae [-1, 0, 1, 0, 0, 1, -1, -1, 0], mask [False, True, False, True, True, False, False, False, True]\n",
            "action not avaliable action<0,8> 2 , satae [-1, 0, 1, 0, 0, 1, -1, -1, 0], mask [False, True, False, True, True, False, False, False, True]\n",
            "action not avaliable action<0,8> 5 , satae [-1, 0, 1, 0, 0, 1, -1, -1, 0], mask [False, True, False, True, True, False, False, False, True]\n",
            "agent won  8144  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.11084619015455247 q value 0.31527723371982574  reward : 1\n",
            "game #num:  14977\n",
            "action not avaliable action<0,8> 0 , satae [-1, 0, 0, -1, 1, -1, 0, 1, 0], mask [False, True, True, False, False, False, True, False, True]\n",
            "action not avaliable action<0,8> 0 , satae [-1, 0, 0, -1, 1, -1, 0, 1, 0], mask [False, True, True, False, False, False, True, False, True]\n",
            "agent won  8145  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.10977572202682495 q value 0.31669512391090393  reward : 1\n",
            "game #num:  14978\n",
            "action not avaliable action<0,8> 0 , satae [-1, 0, 0, 0, 1, 0, 0, 0, 0], mask [False, True, True, True, False, True, True, True, True]\n",
            "action not avaliable action<0,8> 5 , satae [-1, -1, 0, 0, 1, 1, -1, 1, 0], mask [False, False, True, True, False, False, False, False, True]\n",
            "agent won  8146  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.11340795209010442 q value 0.3184077839056651  reward : 1\n",
            "game #num:  14979\n",
            "action not avaliable action<0,8> 5 , satae [0, 0, 0, 0, 0, -1, 0, 0, 0], mask [True, True, True, True, True, False, True, True, True]\n",
            "action not avaliable action<0,8> 4 , satae [1, -1, -1, 1, 1, -1, -1, 0, 0], mask [False, False, False, False, False, False, False, True, True]\n",
            "action not avaliable action<0,8> 0 , satae [1, -1, -1, 1, 1, -1, -1, 0, 0], mask [False, False, False, False, False, False, False, True, True]\n",
            "action not avaliable action<0,8> 3 , satae [1, -1, -1, 1, 1, -1, -1, 0, 0], mask [False, False, False, False, False, False, False, True, True]\n",
            "action not avaliable action<0,8> 3 , satae [1, -1, -1, 1, 1, -1, -1, 0, 0], mask [False, False, False, False, False, False, False, True, True]\n",
            "action not avaliable action<0,8> 1 , satae [1, -1, -1, 1, 1, -1, -1, 0, 0], mask [False, False, False, False, False, False, False, True, True]\n",
            "action not avaliable action<0,8> 1 , satae [1, -1, -1, 1, 1, -1, -1, 0, 0], mask [False, False, False, False, False, False, False, True, True]\n",
            "action not avaliable action<0,8> 5 , satae [1, -1, -1, 1, 1, -1, -1, 0, 0], mask [False, False, False, False, False, False, False, True, True]\n",
            "action not avaliable action<0,8> 2 , satae [1, -1, -1, 1, 1, -1, -1, 0, 0], mask [False, False, False, False, False, False, False, True, True]\n",
            "action not avaliable action<0,8> 2 , satae [1, -1, -1, 1, 1, -1, -1, 0, 0], mask [False, False, False, False, False, False, False, True, True]\n",
            "action not avaliable action<0,8> 0 , satae [1, -1, -1, 1, 1, -1, -1, 0, 0], mask [False, False, False, False, False, False, False, True, True]\n",
            "action not avaliable action<0,8> 6 , satae [1, -1, -1, 1, 1, -1, -1, 0, 0], mask [False, False, False, False, False, False, False, True, True]\n",
            "mcts won  5364  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.11590353725478053 q value 0.3176016379147768  reward : -1\n",
            "game #num:  14980\n",
            "action not avaliable action<0,8> 8 , satae [0, 0, 0, 0, 0, 1, -1, -1, 1], mask [True, True, True, True, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [0, 0, 0, 0, 0, 1, -1, -1, 1], mask [True, True, True, True, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 4 , satae [0, 0, -1, 0, 1, 1, -1, -1, 1], mask [True, True, False, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 4 , satae [0, 0, -1, 0, 1, 1, -1, -1, 1], mask [True, True, False, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 4 , satae [0, 0, -1, 0, 1, 1, -1, -1, 1], mask [True, True, False, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [0, 0, -1, 0, 1, 1, -1, -1, 1], mask [True, True, False, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [-1, 1, -1, 0, 1, 1, -1, -1, 1], mask [False, False, False, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 1 , satae [-1, 1, -1, 0, 1, 1, -1, -1, 1], mask [False, False, False, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 1 , satae [-1, 1, -1, 0, 1, 1, -1, -1, 1], mask [False, False, False, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [-1, 1, -1, 0, 1, 1, -1, -1, 1], mask [False, False, False, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [-1, 1, -1, 0, 1, 1, -1, -1, 1], mask [False, False, False, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [-1, 1, -1, 0, 1, 1, -1, -1, 1], mask [False, False, False, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 1 , satae [-1, 1, -1, 0, 1, 1, -1, -1, 1], mask [False, False, False, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [-1, 1, -1, 0, 1, 1, -1, -1, 1], mask [False, False, False, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [-1, 1, -1, 0, 1, 1, -1, -1, 1], mask [False, False, False, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 1 , satae [-1, 1, -1, 0, 1, 1, -1, -1, 1], mask [False, False, False, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 1 , satae [-1, 1, -1, 0, 1, 1, -1, -1, 1], mask [False, False, False, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 5 , satae [-1, 1, -1, 0, 1, 1, -1, -1, 1], mask [False, False, False, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [-1, 1, -1, 0, 1, 1, -1, -1, 1], mask [False, False, False, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [-1, 1, -1, 0, 1, 1, -1, -1, 1], mask [False, False, False, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [-1, 1, -1, 0, 1, 1, -1, -1, 1], mask [False, False, False, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 5 , satae [-1, 1, -1, 0, 1, 1, -1, -1, 1], mask [False, False, False, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 4 , satae [-1, 1, -1, 0, 1, 1, -1, -1, 1], mask [False, False, False, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 1 , satae [-1, 1, -1, 0, 1, 1, -1, -1, 1], mask [False, False, False, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [-1, 1, -1, 0, 1, 1, -1, -1, 1], mask [False, False, False, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 4 , satae [-1, 1, -1, 0, 1, 1, -1, -1, 1], mask [False, False, False, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [-1, 1, -1, 0, 1, 1, -1, -1, 1], mask [False, False, False, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 4 , satae [-1, 1, -1, 0, 1, 1, -1, -1, 1], mask [False, False, False, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 1 , satae [-1, 1, -1, 0, 1, 1, -1, -1, 1], mask [False, False, False, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [-1, 1, -1, 0, 1, 1, -1, -1, 1], mask [False, False, False, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [-1, 1, -1, 0, 1, 1, -1, -1, 1], mask [False, False, False, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [-1, 1, -1, 0, 1, 1, -1, -1, 1], mask [False, False, False, True, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 1 , satae [-1, 1, -1, 0, 1, 1, -1, -1, 1], mask [False, False, False, True, False, False, False, False, False]\n",
            "agent won  8147  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.11598210860239833 q value 0.3206895472187745  reward : 1\n",
            "game #num:  14981\n",
            "agent won  8148  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.10310301184654236 q value 0.3156066983938217  reward : 1\n",
            "game #num:  14982\n",
            "action not avaliable action<0,8> 2 , satae [0, 1, -1, -1, 0, 1, -1, 0, 0], mask [True, False, False, False, True, False, False, True, True]\n",
            "action not avaliable action<0,8> 6 , satae [1, 1, -1, -1, 0, 1, -1, -1, 0], mask [False, False, False, False, True, False, False, False, True]\n",
            "mcts won  5365  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.10870501399040222 q value 0.3151029745737712  reward : -1\n",
            "game #num:  14983\n",
            "action not avaliable action<0,8> 6 , satae [-1, 0, 0, 0, -1, 1, -1, 0, 1], mask [False, True, True, True, False, False, False, True, False]\n",
            "mcts won  5366  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.11281136982142925 q value 0.3153534531593323  reward : -1\n",
            "game #num:  14984\n",
            "draw  1470  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0]\n",
            "################################################################################################\n",
            "game loss:  0.10891200043261051 q value 0.3159336969256401  reward : 0\n",
            "game #num:  14985\n",
            "action not avaliable action<0,8> 0 , satae [1, 0, 0, -1, 1, -1, 0, 0, 0], mask [False, True, True, False, False, False, True, True, True]\n",
            "action not avaliable action<0,8> 0 , satae [1, 0, 0, -1, 1, -1, 0, 0, 0], mask [False, True, True, False, False, False, True, True, True]\n",
            "action not avaliable action<0,8> 4 , satae [1, 0, 0, -1, 1, -1, 0, 0, 0], mask [False, True, True, False, False, False, True, True, True]\n",
            "action not avaliable action<0,8> 0 , satae [1, 0, 0, -1, 1, -1, 0, 0, 0], mask [False, True, True, False, False, False, True, True, True]\n",
            "agent won  8149  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.11395121179521084 q value 0.3177172504365444  reward : 1\n",
            "game #num:  14986\n",
            "agent won  8150  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.11760635673999786 q value 0.31869088610013324  reward : 1\n",
            "game #num:  14987\n",
            "action not avaliable action<0,8> 5 , satae [-1, 0, 1, -1, 1, -1, 0, -1, 1], mask [False, True, False, False, False, False, True, False, False]\n",
            "agent won  8151  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.11024196296930314 q value 0.3188817322254181  reward : 1\n",
            "game #num:  14988\n",
            "action not avaliable action<0,8> 2 , satae [0, 1, 1, -1, -1, 0, 0, 0, 0], mask [True, False, False, False, False, True, True, True, True]\n",
            "action not avaliable action<0,8> 1 , satae [0, 1, 1, -1, -1, 0, 0, 0, 0], mask [True, False, False, False, False, True, True, True, True]\n",
            "action not avaliable action<0,8> 2 , satae [0, 1, 1, -1, -1, 0, 0, 0, 0], mask [True, False, False, False, False, True, True, True, True]\n",
            "agent won  8152  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.12773510192831358 q value 0.31951719522476196  reward : 1\n",
            "game #num:  14989\n",
            "action not avaliable action<0,8> 0 , satae [-1, 1, 0, 1, 0, -1, 1, -1, 0], mask [False, False, True, False, True, False, False, False, True]\n",
            "action not avaliable action<0,8> 6 , satae [-1, 1, 0, 1, 0, -1, 1, -1, 0], mask [False, False, True, False, True, False, False, False, True]\n",
            "action not avaliable action<0,8> 0 , satae [-1, 1, 0, 1, 0, -1, 1, -1, 0], mask [False, False, True, False, True, False, False, False, True]\n",
            "action not avaliable action<0,8> 6 , satae [-1, 1, 0, 1, 0, -1, 1, -1, 0], mask [False, False, True, False, True, False, False, False, True]\n",
            "action not avaliable action<0,8> 1 , satae [-1, 1, 0, 1, 0, -1, 1, -1, 0], mask [False, False, True, False, True, False, False, False, True]\n",
            "action not avaliable action<0,8> 0 , satae [-1, 1, 0, 1, 0, -1, 1, -1, 0], mask [False, False, True, False, True, False, False, False, True]\n",
            "action not avaliable action<0,8> 7 , satae [-1, 1, 0, 1, 0, -1, 1, -1, 0], mask [False, False, True, False, True, False, False, False, True]\n",
            "action not avaliable action<0,8> 3 , satae [-1, 1, 0, 1, 0, -1, 1, -1, 0], mask [False, False, True, False, True, False, False, False, True]\n",
            "action not avaliable action<0,8> 5 , satae [-1, 1, 0, 1, 0, -1, 1, -1, 0], mask [False, False, True, False, True, False, False, False, True]\n",
            "action not avaliable action<0,8> 7 , satae [-1, 1, 0, 1, 0, -1, 1, -1, 0], mask [False, False, True, False, True, False, False, False, True]\n",
            "action not avaliable action<0,8> 1 , satae [-1, 1, 0, 1, 1, -1, 1, -1, -1], mask [False, False, True, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 5 , satae [-1, 1, 0, 1, 1, -1, 1, -1, -1], mask [False, False, True, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 3 , satae [-1, 1, 0, 1, 1, -1, 1, -1, -1], mask [False, False, True, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [-1, 1, 0, 1, 1, -1, 1, -1, -1], mask [False, False, True, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 1 , satae [-1, 1, 0, 1, 1, -1, 1, -1, -1], mask [False, False, True, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 0 , satae [-1, 1, 0, 1, 1, -1, 1, -1, -1], mask [False, False, True, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 5 , satae [-1, 1, 0, 1, 1, -1, 1, -1, -1], mask [False, False, True, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 1 , satae [-1, 1, 0, 1, 1, -1, 1, -1, -1], mask [False, False, True, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [-1, 1, 0, 1, 1, -1, 1, -1, -1], mask [False, False, True, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [-1, 1, 0, 1, 1, -1, 1, -1, -1], mask [False, False, True, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [-1, 1, 0, 1, 1, -1, 1, -1, -1], mask [False, False, True, False, False, False, False, False, False]\n",
            "action not avaliable action<0,8> 5 , satae [-1, 1, 0, 1, 1, -1, 1, -1, -1], mask [False, False, True, False, False, False, False, False, False]\n",
            "agent won  8153  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.11463211338829112 q value 0.31839662569540517  reward : 1\n",
            "game #num:  14990\n",
            "action not avaliable action<0,8> 0 , satae [-1, 0, 0, 0, 0, 0, 0, 0, 0], mask [False, True, True, True, True, True, True, True, True]\n",
            "action not avaliable action<0,8> 0 , satae [-1, -1, 0, 1, 0, 0, 1, -1, 0], mask [False, False, True, False, True, True, False, False, True]\n",
            "action not avaliable action<0,8> 0 , satae [-1, -1, 0, 1, 0, 0, 1, -1, 0], mask [False, False, True, False, True, True, False, False, True]\n",
            "action not avaliable action<0,8> 6 , satae [-1, -1, 0, 1, 0, 0, 1, -1, 0], mask [False, False, True, False, True, True, False, False, True]\n",
            "action not avaliable action<0,8> 7 , satae [-1, -1, 0, 1, 0, 0, 1, -1, 0], mask [False, False, True, False, True, True, False, False, True]\n",
            "agent won  8154  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.11742826458066702 q value 0.3196422643959522  reward : 1\n",
            "game #num:  14991\n",
            "action not avaliable action<0,8> 1 , satae [0, 1, -1, 0, 0, 0, -1, 0, 1], mask [True, False, False, True, True, True, False, True, False]\n",
            "action not avaliable action<0,8> 1 , satae [0, 1, -1, 0, 0, 0, -1, 0, 1], mask [True, False, False, True, True, True, False, True, False]\n",
            "action not avaliable action<0,8> 4 , satae [-1, 1, -1, 1, 1, -1, -1, 0, 1], mask [False, False, False, False, False, False, False, True, False]\n",
            "action not avaliable action<0,8> 2 , satae [-1, 1, -1, 1, 1, -1, -1, 0, 1], mask [False, False, False, False, False, False, False, True, False]\n",
            "action not avaliable action<0,8> 1 , satae [-1, 1, -1, 1, 1, -1, -1, 0, 1], mask [False, False, False, False, False, False, False, True, False]\n",
            "agent won  8155  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.1108395665884018 q value 0.31765970289707185  reward : 1\n",
            "game #num:  14992\n",
            "action not avaliable action<0,8> 1 , satae [0, 1, 0, -1, 0, -1, 0, 0, 0], mask [True, False, True, False, True, False, True, True, True]\n",
            "action not avaliable action<0,8> 1 , satae [0, 1, 0, -1, 0, -1, 0, 0, 0], mask [True, False, True, False, True, False, True, True, True]\n",
            "action not avaliable action<0,8> 5 , satae [0, 1, 0, -1, 1, -1, 0, -1, 0], mask [True, False, True, False, False, False, True, False, True]\n",
            "action not avaliable action<0,8> 1 , satae [0, 1, 1, -1, 1, -1, 0, -1, -1], mask [True, False, False, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [0, 1, 1, -1, 1, -1, 0, -1, -1], mask [True, False, False, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 5 , satae [0, 1, 1, -1, 1, -1, 0, -1, -1], mask [True, False, False, False, False, False, True, False, False]\n",
            "action not avaliable action<0,8> 3 , satae [0, 1, 1, -1, 1, -1, 0, -1, -1], mask [True, False, False, False, False, False, True, False, False]\n",
            "agent won  8156  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.11920571259476921 q value 0.3188038468360901  reward : 1\n",
            "game #num:  14993\n",
            "action not avaliable action<0,8> 4 , satae [1, 0, 0, 1, -1, 0, 0, -1, 0], mask [False, True, True, False, False, True, True, False, True]\n",
            "action not avaliable action<0,8> 7 , satae [1, 0, -1, 1, -1, 1, 0, -1, 0], mask [False, True, False, False, False, False, True, False, True]\n",
            "mcts won  5367  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, -1]\n",
            "################################################################################################\n",
            "game loss:  0.10891752441724141 q value 0.3210008194049199  reward : -1\n",
            "game #num:  14994\n",
            "action not avaliable action<0,8> 1 , satae [-1, 1, 0, 0, 0, 1, 0, -1, -1], mask [False, False, True, True, True, False, True, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [-1, 1, -1, 0, 0, 1, 1, -1, -1], mask [False, False, False, True, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 5 , satae [-1, 1, -1, 0, 0, 1, 1, -1, -1], mask [False, False, False, True, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [-1, 1, -1, 0, 0, 1, 1, -1, -1], mask [False, False, False, True, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [-1, 1, -1, 0, 0, 1, 1, -1, -1], mask [False, False, False, True, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [-1, 1, -1, 0, 0, 1, 1, -1, -1], mask [False, False, False, True, True, False, False, False, False]\n",
            "draw  1471  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "################################################################################################\n",
            "game loss:  0.11369517147541046 q value 0.32135933041572573  reward : 0\n",
            "game #num:  14995\n",
            "action not avaliable action<0,8> 1 , satae [0, -1, -1, 1, 0, 0, 0, 0, 1], mask [True, False, False, False, True, True, True, True, False]\n",
            "action not avaliable action<0,8> 3 , satae [0, -1, -1, 1, 0, 0, 0, 0, 1], mask [True, False, False, False, True, True, True, True, False]\n",
            "action not avaliable action<0,8> 3 , satae [0, -1, -1, 1, 0, 0, 0, 0, 1], mask [True, False, False, False, True, True, True, True, False]\n",
            "action not avaliable action<0,8> 3 , satae [0, -1, -1, 1, 0, 0, 0, 0, 1], mask [True, False, False, False, True, True, True, True, False]\n",
            "action not avaliable action<0,8> 6 , satae [0, -1, -1, 1, 0, -1, 1, 0, 1], mask [True, False, False, False, True, False, False, True, False]\n",
            "action not avaliable action<0,8> 1 , satae [0, -1, -1, 1, 0, -1, 1, 0, 1], mask [True, False, False, False, True, False, False, True, False]\n",
            "action not avaliable action<0,8> 6 , satae [0, -1, -1, 1, 0, -1, 1, 0, 1], mask [True, False, False, False, True, False, False, True, False]\n",
            "action not avaliable action<0,8> 1 , satae [0, -1, -1, 1, 0, -1, 1, 0, 1], mask [True, False, False, False, True, False, False, True, False]\n",
            "action not avaliable action<0,8> 6 , satae [0, -1, -1, 1, 0, -1, 1, 0, 1], mask [True, False, False, False, True, False, False, True, False]\n",
            "agent won  8157  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.10505007723203072 q value 0.3208817564524137  reward : 1\n",
            "game #num:  14996\n",
            "action not avaliable action<0,8> 5 , satae [0, 0, 1, -1, 0, -1, 0, -1, 1], mask [True, True, False, False, True, False, True, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [0, 0, 1, -1, 0, -1, 0, -1, 1], mask [True, True, False, False, True, False, True, False, False]\n",
            "agent won  8158  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.10709162652492524 q value 0.32049180269241334  reward : 1\n",
            "game #num:  14997\n",
            "agent won  8159  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.12198447249829769 q value 0.32028239220380783  reward : 1\n",
            "game #num:  14998\n",
            "action not avaliable action<0,8> 6 , satae [0, 0, 0, 0, 0, 0, -1, 0, 1], mask [True, True, True, True, True, True, False, True, False]\n",
            "action not avaliable action<0,8> 3 , satae [1, 1, -1, -1, 0, 0, -1, 0, 1], mask [False, False, False, False, True, True, False, True, False]\n",
            "action not avaliable action<0,8> 0 , satae [1, 1, -1, -1, 0, 0, -1, 0, 1], mask [False, False, False, False, True, True, False, True, False]\n",
            "action not avaliable action<0,8> 0 , satae [1, 1, -1, -1, 0, 0, -1, 0, 1], mask [False, False, False, False, True, True, False, True, False]\n",
            "action not avaliable action<0,8> 2 , satae [1, 1, -1, -1, 0, -1, -1, 1, 1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 2 , satae [1, 1, -1, -1, 0, -1, -1, 1, 1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [1, 1, -1, -1, 0, -1, -1, 1, 1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 0 , satae [1, 1, -1, -1, 0, -1, -1, 1, 1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 0 , satae [1, 1, -1, -1, 0, -1, -1, 1, 1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 2 , satae [1, 1, -1, -1, 0, -1, -1, 1, 1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 2 , satae [1, 1, -1, -1, 0, -1, -1, 1, 1], mask [False, False, False, False, True, False, False, False, False]\n",
            "agent won  8160  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.1190653177909553 q value 0.3178775515407324  reward : 1\n",
            "game #num:  14999\n",
            "action not avaliable action<0,8> 0 , satae [1, 0, 0, 0, 0, 0, -1, 0, 0], mask [False, True, True, True, True, True, False, True, True]\n",
            "action not avaliable action<0,8> 0 , satae [1, 0, 0, 0, 0, 0, -1, 0, 0], mask [False, True, True, True, True, True, False, True, True]\n",
            "action not avaliable action<0,8> 0 , satae [1, 1, -1, 0, 0, 0, -1, 0, 0], mask [False, False, False, True, True, True, False, True, True]\n",
            "action not avaliable action<0,8> 3 , satae [1, 1, -1, -1, 0, 0, -1, 0, 1], mask [False, False, False, False, True, True, False, True, False]\n",
            "action not avaliable action<0,8> 6 , satae [1, 1, -1, -1, 0, -1, -1, 1, 1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [1, 1, -1, -1, 0, -1, -1, 1, 1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 1 , satae [1, 1, -1, -1, 0, -1, -1, 1, 1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 2 , satae [1, 1, -1, -1, 0, -1, -1, 1, 1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 2 , satae [1, 1, -1, -1, 0, -1, -1, 1, 1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 2 , satae [1, 1, -1, -1, 0, -1, -1, 1, 1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [1, 1, -1, -1, 0, -1, -1, 1, 1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 0 , satae [1, 1, -1, -1, 0, -1, -1, 1, 1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 7 , satae [1, 1, -1, -1, 0, -1, -1, 1, 1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 5 , satae [1, 1, -1, -1, 0, -1, -1, 1, 1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 1 , satae [1, 1, -1, -1, 0, -1, -1, 1, 1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 5 , satae [1, 1, -1, -1, 0, -1, -1, 1, 1], mask [False, False, False, False, True, False, False, False, False]\n",
            "action not avaliable action<0,8> 3 , satae [1, 1, -1, -1, 0, -1, -1, 1, 1], mask [False, False, False, False, True, False, False, False, False]\n",
            "agent won  8161  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.10861200873147357 q value 0.31679675253954803  reward : 1\n",
            "game #num:  15000\n",
            "action not avaliable action<0,8> 4 , satae [0, 0, 0, 0, 1, 0, -1, 0, -1], mask [True, True, True, True, False, True, False, True, False]\n",
            "action not avaliable action<0,8> 6 , satae [0, 0, -1, 0, 1, 0, -1, 1, -1], mask [True, True, False, True, False, True, False, False, False]\n",
            "action not avaliable action<0,8> 8 , satae [-1, 0, -1, 1, 1, 0, -1, 1, -1], mask [False, True, False, False, False, True, False, False, False]\n",
            "action not avaliable action<0,8> 4 , satae [-1, 0, -1, 1, 1, 0, -1, 1, -1], mask [False, True, False, False, False, True, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [-1, 0, -1, 1, 1, 0, -1, 1, -1], mask [False, True, False, False, False, True, False, False, False]\n",
            "action not avaliable action<0,8> 6 , satae [-1, 0, -1, 1, 1, 0, -1, 1, -1], mask [False, True, False, False, False, True, False, False, False]\n",
            "agent won  8162  eps  0.9\n",
            "################################################################################################\n",
            "episode_reward :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "################################################################################################\n",
            "game loss:  0.10439709275960922 q value 0.32173396050930025  reward : 1\n",
            "Complete\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oJhpsKFgZwz8"
      },
      "source": [
        "# Training without Mask (Negative Reward for non-available action):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SfPxTQ-HeXPM"
      },
      "source": [
        "#env.step(action) -> s, reward, done, s'\n",
        "#optimize_model\n",
        "env = XO_Board()\n",
        "mcts = MCTS()\n",
        "env.init_board()\n",
        "memory = ReplayMemory(MEMORY_SIZE)\n",
        "\n",
        "losses_list = []\n",
        "num_episodes = 6000\n",
        "reward_list=[]\n",
        "q_list=[]\n",
        "\n",
        "for i_episode in range(num_episodes):\n",
        "    episode_loss=[]\n",
        "    episode_q = []\n",
        "    episode_reward=[]\n",
        "    print('game #num: ',i_episode+1)\n",
        "    # Initialize the environment and state\n",
        "    env.init_board(empty=False)\n",
        "    # last_screen = get_screen()\n",
        "    # current_screen = get_screen()\n",
        "    state = env.position_list()#current_screen - last_screen\n",
        "    for t in count():\n",
        "        # Select and perform an action\n",
        "        mask=[]\n",
        "        for i in env.position_list():\n",
        "          mask.append(not (i==-1 or i==1))\n",
        "        action = select_action(torch.tensor(state).to(device), policy_net, mask=np.array([1,1,1,1,1,1,1,1,1])) #0->8np.array(mask)\n",
        "        action = action.cpu()\n",
        "        _, reward, done, new_s = env.step(action.item()+1,mask) #<1,9>\n",
        "        # print('new s', new_s)\n",
        "        episode_reward.append(reward)\n",
        "        \n",
        "        reward = torch.tensor([reward], device=device)\n",
        "        # Observe new state\n",
        "        # last_screen = current_screen\n",
        "        # current_screen = get_screen()\n",
        "        # if not done:\n",
        "        #     next_state = new_s #current_screen - last_screen\n",
        "        # else:\n",
        "        #     next_state = None\n",
        "\n",
        "        # Store the transition in memory\n",
        "        # print('push')###\n",
        "        if new_s:\n",
        "          new_s = torch.tensor(new_s)\n",
        "          # print(torch.tensor(state), action, reward, new_s))###\n",
        "        # else: ###\n",
        "          # print('new state is None')###\n",
        "          # print(torch.tensor(state), action, reward)###\n",
        "        \n",
        "        # if not np.all(np.array(torch.tensor(state))== np.array(new_s)):\n",
        "        memory.push(torch.tensor(state), action, new_s, reward)\n",
        "        # else:\n",
        "        #   print('eorrrrrrrrrr in adding the data sample')\n",
        "\n",
        "        # Move to the next state\n",
        "        state = new_s\n",
        "\n",
        "        # Perform one step of the optimization (on the policy network)\n",
        "        # print('memoooory ',len(memory))\n",
        "        if len(memory) > BATCH_SIZE:\n",
        "          loss, q = optimize_model() #BSGD\n",
        "          episode_q.append(q)\n",
        "          episode_loss.append(loss)\n",
        "          \n",
        "          # print('lossssssss ',loss)\n",
        "\n",
        "        if done:\n",
        "            episode_durations.append(t + 1)\n",
        "            # episode_reward = reward\n",
        "            break\n",
        "\n",
        "        tr_eps.append(eps_threshold)\n",
        "    print('################################################################################################')\n",
        "    print('episode_reward : ' , episode_reward)\n",
        "    print('################################################################################################')\n",
        "          \n",
        "\n",
        "    reward_list.append(np.sum(episode_reward))\n",
        "    q_list(np.mean(episode_q))\n",
        "    losses_list.append(np.mean(episode_loss))\n",
        "    # Update the target network, copying all weights and biases in DQN\n",
        "    if i_episode % TARGET_UPDATE == 0:\n",
        "        target_net.load_state_dict(policy_net.state_dict())\n",
        "    print('game loss: ',np.mean(episode_loss), 'q value',np.mean(episode_q), ' reward :',np.sum(episode_reward)))\n",
        "\n",
        "\n",
        "\n",
        "print('Complete')\n",
        "# env.render()\n",
        "# env.close()\n",
        "plt.ioff()\n",
        "plt.plot(losses_list)\n",
        "plt.show()\n",
        "# plot_durations(episode_durations)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QyJsQSdhSRVL"
      },
      "source": [
        "# Plot :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWtgrjJMST17"
      },
      "source": [
        "import numpy as np\n",
        "import torch"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "OWELOQxaSaME",
        "outputId": "6137cc87-ada2-45c7-e1da-557300d7b9dc"
      },
      "source": [
        "plt.plot(q_list)\n",
        "plt.show()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KytlamQSSf-d"
      },
      "source": [
        "**Loss:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18SpimkRSfW1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "cb6a238c-70d6-48a3-d324-65742585a7e9"
      },
      "source": [
        "plt.plot(losses_list)\n",
        "plt.show()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BbZkyYoESl-X"
      },
      "source": [
        "**Reward:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "6kmJzO_9SpPZ",
        "outputId": "e45d4db5-104e-46fb-a0d5-8a7ba42b9e62"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "reward_sum=[]\n",
        "for i in range(0,len(reward_list),1000):\n",
        "  if i+100 < len(reward_list):\n",
        "    reward_sum.append(np.sum(reward_list[i:i+100]))\n",
        "  else:\n",
        "    reward_sum.append(np.sum(reward_list[i:]))\n",
        "\n",
        "\n",
        "plt.plot(reward_sum)\n",
        "plt.show()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z0q4KHX-S3Nh"
      },
      "source": [
        "# Save the model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQAMEvOwS2pI"
      },
      "source": [
        "torch.save(policy_net.state_dict(),'ploicy_net.ckpt')"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GonB0bqhTFzB"
      },
      "source": [
        "# Try to play against agent (Human Vs Agent):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-Sck1uvTM6x"
      },
      "source": [
        "# main game loop \n",
        "\n",
        "def game_select_action(state, policy_net,mask=None): #eps-greedy \n",
        "    '''\n",
        "    0-greddy\n",
        "    return action <0,8>\n",
        "    '''\n",
        "    global steps_done\n",
        "    sample = random.random()\n",
        "    eps_threshold = 0.9# EPS_END + (EPS_START - EPS_END) * \\\n",
        "    #     math.exp(-1. * steps_done / EPS_DECAY)\n",
        "    steps_done += 1\n",
        "    if sample < eps_threshold:\n",
        "        with torch.no_grad():\n",
        "            if mask is not None:\n",
        "              ids = torch.tensor(np.where(mask)).squeeze()\n",
        "              p = policy_net(state).squeeze().cpu()\n",
        "              max_value = p[ids].max(0)[0].view(1)\n",
        "              max_index = (p == max_value).nonzero(as_tuple=True)[0]\n",
        "              print('action =  ' , max_index)\n",
        "              return max_index\n",
        "            else:\n",
        "              return policy_net(state).max(1)[1].view(1)\n",
        "    else:\n",
        "        print('select action, random',eps_threshold)\n",
        "        while True:\n",
        "          action=random.randrange(n_actions)\n",
        "          if mask[action]:\n",
        "            break\n",
        "        return torch.tensor([action], device=device, dtype=torch.long)\n",
        "\n",
        "def game():\n",
        "  print('   \\nWelcome to X-O Game:')\n",
        "  print('===================================')\n",
        "  print('enter your move for example : [x,y] = 1,2 where 1 is row and 2 is col,  or type \"exit\" to quit the game')\n",
        "\n",
        "  env.init_board() \n",
        "  # game loop\n",
        "  while True :\n",
        "\n",
        "\n",
        "      # make AI Agent move ....\n",
        "      while True:\n",
        "        #mask to select only the available actions\n",
        "        mask=[]\n",
        "        for i in env.position_list():\n",
        "          mask.append(not (i==-1 or i==1))\n",
        "        mask = np.array(mask)\n",
        "        action = game_select_action(torch.tensor(env.position_list()).cuda(), policy_net, mask) #0->8\n",
        "        row, col = env.action_to_ids(action+1)\n",
        "        if env.position[row,col] == env.empty_place:\n",
        "          env.position[(row,col)] = 'x'\n",
        "          break\n",
        "\n",
        "      print('------------------------Agent Turn----------------------- :)\\n')\n",
        "      env.get_state()\n",
        "\n",
        "      # user input\n",
        "      user_input = input('> ')\n",
        "\n",
        "      if user_input == 'exit':\n",
        "        break\n",
        "\n",
        "      # skipp empty input\n",
        "      if user_input == '':\n",
        "        continue\n",
        "      try:\n",
        "        # parse user input ===> ex : format for move [col,row] = (1,3)\n",
        "        row = int(user_input.split(',')[0]) - 1\n",
        "        col = int(user_input.split(',')[1]) - 1\n",
        "\n",
        "        # check if the move is legal or not\n",
        "        if env.position[row,col] != env.empty_place:\n",
        "          print('Illegal move !!!')\n",
        "          continue\n",
        "\n",
        "        # make move on board\n",
        "        env.position[(row,col)] = 'o'\n",
        "        print('-------------------------Your Turn------------------------ :)\\n')\n",
        "        env.get_state()\n",
        "\n",
        "    #   # check the game state\n",
        "    #   if self.is_win():\n",
        "    #     print(' Player \"%s\" has won the game \\n' % self.second_player )\n",
        "    #     break\n",
        "\n",
        "    #   elif self.is_draw():\n",
        "    #     print('Oooh We have a draw \\n')\n",
        "    #     break   \n",
        "\n",
        "\n",
        "      except Exception as e:\n",
        "        print('Error: ' , e)\n",
        "        print('Illegal command !!!')\n",
        "        print('enter your move for example : [x,y] = 1,2 where 1 is row and 2 is column,  or type \"exit\" to quit the game')"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9ud8AOFTvwg"
      },
      "source": [
        "# Play :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rN48E7KWTvNM"
      },
      "source": [
        "game()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QRcHkvI1TWur"
      },
      "source": [
        "**Method to play Agent Vs Random (Multiple games) with (two modes) ===> agent first or random first:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBNjuP0tTqrW"
      },
      "source": [
        "def agent_against_random(env,num_games,agent_first = True):\n",
        "\n",
        "  n_actions = 9\n",
        "  if agent_first:\n",
        "      print('First \"%s\" games agent will play first: \\n\\n'  %num_games)\n",
        "      env.init_board()\n",
        "      agent_winner = 0\n",
        "      random_winner = 0\n",
        "      draw = 0\n",
        "      game = 0 \n",
        "      \n",
        "      # Agent will play first\n",
        "      while game != num_games:\n",
        "\n",
        "            print('#####################################################################################################') \n",
        "            print('START GAME NUMBER: ' ,game+1 , ' |AGENT : ' , agent_winner , ' |RANDOM: ' , random_winner , ' |DRAW: ', draw)\n",
        "            print('#####################################################################################################')\n",
        "            print('\\n')\n",
        "\n",
        "            env = XO_Board()\n",
        "            env.init_board()\n",
        "\n",
        "            while True:\n",
        "                print('------------------------Agent Turn----------------------- :)\\n')\n",
        "                # make AI Agent move ....\n",
        "                while True:\n",
        "                  # mask to select only the available actions\n",
        "                  mask=[]\n",
        "                  for i in env.position_list():\n",
        "                    mask.append(i==0)\n",
        "                  mask = np.array(mask)\n",
        "\n",
        "                  action = game_select_action(torch.tensor(env.position_list()).cuda(), policy_net, mask) #0->8\n",
        "                  row, col = env.action_to_ids(action+1)\n",
        "                  if env.position[row,col] == env.empty_place:\n",
        "                    env.__dict__ = deepcopy(env.make_move(row, col).__dict__)\n",
        "                    break\n",
        "\n",
        "                env.get_state()\n",
        "\n",
        "                if env.is_win():\n",
        "                  game += 1\n",
        "                  print('Game Number ', game)\n",
        "\n",
        "                  if env.second_player == 'x':\n",
        "                    agent_winner+=1\n",
        "                    print('agent won ', agent_winner)\n",
        "                  else:\n",
        "                    random_winner+=1\n",
        "                    print('random won ', random_winner) \n",
        "\n",
        "                  \n",
        "                  env.get_state()\n",
        "\n",
        "                  if game == num_games:\n",
        "                      print('#####################################################################################################') \n",
        "                      print('GAME NUMBER: ' ,num_games , ' |AGENT : ' , agent_winner , ' |RANDOM: ' , random_winner , ' |DRAW: ', draw)\n",
        "                      print('#####################################################################################################')\n",
        "                \n",
        "                  break\n",
        "\n",
        "                elif env.is_draw():\n",
        "                  draw+=1\n",
        "                  game += 1\n",
        "                  print('draw ', draw)\n",
        "                  env.get_state()\n",
        "\n",
        "                  if game == num_games:\n",
        "                      print('#####################################################################################################') \n",
        "                      print('GAME NUMBER: ' ,num_games , ' |AGENT : ' , agent_winner , ' |RANDOM: ' , random_winner , ' |DRAW: ', draw)\n",
        "                      print('#####################################################################################################')\n",
        "                  break\n",
        "\n",
        "                print('------------------------Random Turn----------------------- :)\\n')\n",
        "                mask[action] = False #action played by the agent\n",
        "                while True:\n",
        "                  r_action=random.randrange(n_actions)\n",
        "                  if mask[r_action]: #available action\n",
        "                    row, col = env.action_to_ids(r_action+1)\n",
        "                    # print('random')\n",
        "                    if env.position[row,col] == env.empty_place:\n",
        "                      env.__dict__ = deepcopy(env.make_move(row, col).__dict__)\n",
        "                      break\n",
        "\n",
        "                env.get_state()\n",
        "\n",
        "                if env.is_win():\n",
        "                  game += 1\n",
        "                  if env.second_player == 'x':\n",
        "                    agent_winner+=1\n",
        "                    print('agent won ', agent_winner)\n",
        "                  else:\n",
        "                    random_winner+=1\n",
        "                    print('random won ', random_winner) \n",
        "\n",
        "                  \n",
        "                  env.get_state()\n",
        "\n",
        "                  if game == num_games:\n",
        "                      print('#####################################################################################################') \n",
        "                      print('GAME NUMBER: ' ,num_games , ' |AGENT : ' , agent_winner , ' |RANDOM: ' , random_winner , ' |DRAW: ', draw)\n",
        "                      print('#####################################################################################################')\n",
        "                  break\n",
        "\n",
        "                elif env.is_draw():\n",
        "                  game += 1\n",
        "                  draw+=1\n",
        "                  print('draw ', draw)\n",
        "                  env.get_state()\n",
        "\n",
        "                  if game == num_games:\n",
        "                      print('#####################################################################################################') \n",
        "                      print('GAME NUMBER: ' ,num_games , ' |AGENT : ' , agent_winner , ' |RANDOM: ' , random_winner , ' |DRAW: ', draw)\n",
        "                      print('#####################################################################################################')\n",
        "\n",
        "                  break\n",
        "  else :\n",
        "      print('\"%s\" games agent will play second: \\n\\n'  %num_games)\n",
        "      env.init_board()\n",
        "      agent_winner = 0\n",
        "      random_winner = 0\n",
        "      draw = 0\n",
        "      game = 0\n",
        "\n",
        "      # Agent will play second\n",
        "      while game != num_games:\n",
        "            print('#####################################################################################################') \n",
        "            print('START GAME NUMBER: ' ,game+1 , ' |AGENT : ' , agent_winner , ' |RANDOM: ' , random_winner , ' |DRAW: ', draw)\n",
        "            print('#####################################################################################################')\n",
        "            print('\\n')\n",
        "\n",
        "            env = XO_Board()\n",
        "            env.init_board()\n",
        "\n",
        "            while True:\n",
        "\n",
        "                print('------------------------Random Turn----------------------- :)\\n')\n",
        "                while True:\n",
        "                  # mask to select only the available actions\n",
        "                  mask=[]\n",
        "                  for i in env.position_list():\n",
        "                    mask.append(i==0)\n",
        "                  mask = np.array(mask)\n",
        "                  r_action=random.randrange(n_actions)\n",
        "                  if mask[r_action]: \n",
        "                    row, col = env.action_to_ids(r_action+1)\n",
        "                    if env.position[row,col] == env.empty_place:\n",
        "                      env.__dict__ = deepcopy(env.make_move(row, col).__dict__)\n",
        "                      break\n",
        "\n",
        "                env.get_state()\n",
        "\n",
        "                if env.is_win():\n",
        "                  game += 1\n",
        "                  print('Game Number ', game)\n",
        "\n",
        "                  if env.second_player == 'x':\n",
        "                    random_winner+=1\n",
        "                    print('random won ', random_winner)\n",
        "                  else:\n",
        "                    agent_winner+=1\n",
        "                    print('agent won ', agent_winner) \n",
        "\n",
        "                  \n",
        "                  env.get_state()\n",
        "\n",
        "                  if game == num_games:\n",
        "                      print('#####################################################################################################') \n",
        "                      print('GAME NUMBER: ' ,num_games , ' |AGENT : ' , agent_winner , ' |RANDOM: ' , random_winner , ' |DRAW: ', draw)\n",
        "                      print('#####################################################################################################')\n",
        "                \n",
        "                  break\n",
        "\n",
        "                elif env.is_draw():\n",
        "                  draw+=1\n",
        "                  game += 1\n",
        "                  print('draw ', draw)\n",
        "                  env.get_state()\n",
        "\n",
        "                  if game == num_games:\n",
        "                      print('#####################################################################################################') \n",
        "                      print('GAME NUMBER: ' ,num_games , ' |AGENT : ' , agent_winner , ' |RANDOM: ' , random_winner , ' |DRAW: ', draw)\n",
        "                      print('#####################################################################################################')\n",
        "                  break\n",
        "\n",
        "            \n",
        "                mask[r_action] = False #action played by the Random Player\n",
        "                print('------------------------Agent Turn----------------------- :)\\n')\n",
        "                # make AI Agent move ....\n",
        "                while True:\n",
        "                  action = game_select_action(torch.tensor(env.position_list()).cuda(), policy_net, mask) #0->8\n",
        "                  row, col = env.action_to_ids(action+1)\n",
        "                  if env.position[row,col] == env.empty_place:\n",
        "                    env.__dict__ = deepcopy(env.make_move(row, col).__dict__)\n",
        "                    break  \n",
        "\n",
        "                env.get_state()\n",
        "\n",
        "                if env.is_win():\n",
        "                  game += 1\n",
        "                  print('Game Number ', game)\n",
        "\n",
        "                  if env.second_player == 'x':\n",
        "                    random_winner+=1\n",
        "                    print('random won ', random_winner)\n",
        "                  else:\n",
        "                    agent_winner+=1\n",
        "                    print('agent won ', agent_winner) \n",
        "\n",
        "                      \n",
        "                  env.get_state()\n",
        "\n",
        "                  if game == num_games:\n",
        "                      print('#####################################################################################################') \n",
        "                      print('GAME NUMBER: ' ,num_games , ' |AGENT : ' , agent_winner , ' |RANDOM: ' , random_winner , ' |DRAW: ', draw)\n",
        "                      print('#####################################################################################################')\n",
        "                \n",
        "                  break\n",
        "\n",
        "                elif env.is_draw():\n",
        "                  draw+=1\n",
        "                  game += 1\n",
        "                  print('draw ', draw)\n",
        "                  env.get_state()\n",
        "\n",
        "                  if game == num_games:\n",
        "                      print('#####################################################################################################') \n",
        "                      print('GAME NUMBER: ' ,num_games , ' |AGENT : ' , agent_winner , ' |RANDOM: ' , random_winner , ' |DRAW: ', draw)\n",
        "                      print('#####################################################################################################')\n",
        "                  break\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uKZXi8AET6yX"
      },
      "source": [
        "env = XO_Board()"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Zix26uST7Rs",
        "outputId": "0778bcf1-739a-430f-8841-0cb68cbd7c0f"
      },
      "source": [
        "agent_against_random(env,num_games=1500,agent_first=True)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " o - x\n",
            " - - -\n",
            " x o -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([4])\n",
            " o - x\n",
            " - x -\n",
            " x o -\n",
            "\n",
            "Game Number  1412\n",
            "agent won  1148\n",
            " o - x\n",
            " - x -\n",
            " x o -\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1413  |AGENT :  1148  |RANDOM:  174  |DRAW:  90\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([6])\n",
            " - - -\n",
            " - - -\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " - - -\n",
            " x o -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([2])\n",
            " - - x\n",
            " - - -\n",
            " x o -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - x\n",
            " - o -\n",
            " x o -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([1])\n",
            " - x x\n",
            " - o -\n",
            " x o -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - x x\n",
            " - o o\n",
            " x o -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "select action, random 0.9\n",
            " - x x\n",
            " x o o\n",
            " x o -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - x x\n",
            " x o o\n",
            " x o o\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([0])\n",
            " x x x\n",
            " x o o\n",
            " x o o\n",
            "\n",
            "Game Number  1413\n",
            "agent won  1149\n",
            " x x x\n",
            " x o o\n",
            " x o o\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1414  |AGENT :  1149  |RANDOM:  174  |DRAW:  90\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([6])\n",
            " - - -\n",
            " - - -\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " - o -\n",
            " x - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([5])\n",
            " - - -\n",
            " - o x\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " o - -\n",
            " - o x\n",
            " x - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([2])\n",
            " o - x\n",
            " - o x\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " o - x\n",
            " - o x\n",
            " x o -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([8])\n",
            " o - x\n",
            " - o x\n",
            " x o x\n",
            "\n",
            "Game Number  1414\n",
            "agent won  1150\n",
            " o - x\n",
            " - o x\n",
            " x o x\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1415  |AGENT :  1150  |RANDOM:  174  |DRAW:  90\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([6])\n",
            " - - -\n",
            " - - -\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " - o -\n",
            " x - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([5])\n",
            " - - -\n",
            " - o x\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - o -\n",
            " - o x\n",
            " x - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([0])\n",
            " x o -\n",
            " - o x\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " x o o\n",
            " - o x\n",
            " x - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "select action, random 0.9\n",
            " x o o\n",
            " - o x\n",
            " x x -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " x o o\n",
            " - o x\n",
            " x x o\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([3])\n",
            " x o o\n",
            " x o x\n",
            " x x o\n",
            "\n",
            "Game Number  1415\n",
            "agent won  1151\n",
            " x o o\n",
            " x o x\n",
            " x x o\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1416  |AGENT :  1151  |RANDOM:  174  |DRAW:  90\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([6])\n",
            " - - -\n",
            " - - -\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " - o -\n",
            " x - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([5])\n",
            " - - -\n",
            " - o x\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - o -\n",
            " - o x\n",
            " x - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([0])\n",
            " x o -\n",
            " - o x\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " x o -\n",
            " - o x\n",
            " x o -\n",
            "\n",
            "random won  175\n",
            " x o -\n",
            " - o x\n",
            " x o -\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1417  |AGENT :  1151  |RANDOM:  175  |DRAW:  90\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "select action, random 0.9\n",
            " - - -\n",
            " - x -\n",
            " - - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " - x o\n",
            " - - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([6])\n",
            " - - -\n",
            " - x o\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " o - -\n",
            " - x o\n",
            " x - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([2])\n",
            " o - x\n",
            " - x o\n",
            " x - -\n",
            "\n",
            "Game Number  1417\n",
            "agent won  1152\n",
            " o - x\n",
            " - x o\n",
            " x - -\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1418  |AGENT :  1152  |RANDOM:  175  |DRAW:  90\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([6])\n",
            " - - -\n",
            " - - -\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " o - -\n",
            " x - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([4])\n",
            " - - -\n",
            " o x -\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " o x o\n",
            " x - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([2])\n",
            " - - x\n",
            " o x o\n",
            " x - -\n",
            "\n",
            "Game Number  1418\n",
            "agent won  1153\n",
            " - - x\n",
            " o x o\n",
            " x - -\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1419  |AGENT :  1153  |RANDOM:  175  |DRAW:  90\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([6])\n",
            " - - -\n",
            " - - -\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - o -\n",
            " - - -\n",
            " x - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([2])\n",
            " - o x\n",
            " - - -\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - o x\n",
            " - - -\n",
            " x o -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([4])\n",
            " - o x\n",
            " - x -\n",
            " x o -\n",
            "\n",
            "Game Number  1419\n",
            "agent won  1154\n",
            " - o x\n",
            " - x -\n",
            " x o -\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1420  |AGENT :  1154  |RANDOM:  175  |DRAW:  90\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([6])\n",
            " - - -\n",
            " - - -\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " - - o\n",
            " x - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([3])\n",
            " - - -\n",
            " x - o\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " x o o\n",
            " x - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([8])\n",
            " - - -\n",
            " x o o\n",
            " x - x\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " o - -\n",
            " x o o\n",
            " x - x\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([2])\n",
            " o - x\n",
            " x o o\n",
            " x - x\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " o - x\n",
            " x o o\n",
            " x o x\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([1])\n",
            " o x x\n",
            " x o o\n",
            " x o x\n",
            "\n",
            "draw  91\n",
            " o x x\n",
            " x o o\n",
            " x o x\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1421  |AGENT :  1154  |RANDOM:  175  |DRAW:  91\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([6])\n",
            " - - -\n",
            " - - -\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - o -\n",
            " - - -\n",
            " x - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([2])\n",
            " - o x\n",
            " - - -\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " o o x\n",
            " - - -\n",
            " x - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([5])\n",
            " o o x\n",
            " - - x\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " o o x\n",
            " o - x\n",
            " x - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([8])\n",
            " o o x\n",
            " o - x\n",
            " x - x\n",
            "\n",
            "Game Number  1421\n",
            "agent won  1155\n",
            " o o x\n",
            " o - x\n",
            " x - x\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1422  |AGENT :  1155  |RANDOM:  175  |DRAW:  91\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([6])\n",
            " - - -\n",
            " - - -\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " - o -\n",
            " x - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([5])\n",
            " - - -\n",
            " - o x\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " o - -\n",
            " - o x\n",
            " x - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([2])\n",
            " o - x\n",
            " - o x\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " o o x\n",
            " - o x\n",
            " x - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([8])\n",
            " o o x\n",
            " - o x\n",
            " x - x\n",
            "\n",
            "Game Number  1422\n",
            "agent won  1156\n",
            " o o x\n",
            " - o x\n",
            " x - x\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1423  |AGENT :  1156  |RANDOM:  175  |DRAW:  91\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "select action, random 0.9\n",
            " - - -\n",
            " - x -\n",
            " - - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " - x o\n",
            " - - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([6])\n",
            " - - -\n",
            " - x o\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - o\n",
            " - x o\n",
            " x - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([0])\n",
            " x - o\n",
            " - x o\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " x - o\n",
            " - x o\n",
            " x o -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([8])\n",
            " x - o\n",
            " - x o\n",
            " x o x\n",
            "\n",
            "Game Number  1423\n",
            "agent won  1157\n",
            " x - o\n",
            " - x o\n",
            " x o x\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1424  |AGENT :  1157  |RANDOM:  175  |DRAW:  91\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([6])\n",
            " - - -\n",
            " - - -\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " - o -\n",
            " x - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([5])\n",
            " - - -\n",
            " - o x\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " o o x\n",
            " x - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([7])\n",
            " - - -\n",
            " o o x\n",
            " x x -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - o -\n",
            " o o x\n",
            " x x -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([8])\n",
            " - o -\n",
            " o o x\n",
            " x x x\n",
            "\n",
            "Game Number  1424\n",
            "agent won  1158\n",
            " - o -\n",
            " o o x\n",
            " x x x\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1425  |AGENT :  1158  |RANDOM:  175  |DRAW:  91\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "select action, random 0.9\n",
            " x - -\n",
            " - - -\n",
            " - - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " x - -\n",
            " - - o\n",
            " - - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([2])\n",
            " x - x\n",
            " - - o\n",
            " - - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " x - x\n",
            " - - o\n",
            " o - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([8])\n",
            " x - x\n",
            " - - o\n",
            " o - x\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " x - x\n",
            " - o o\n",
            " o - x\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([1])\n",
            " x x x\n",
            " - o o\n",
            " o - x\n",
            "\n",
            "Game Number  1425\n",
            "agent won  1159\n",
            " x x x\n",
            " - o o\n",
            " o - x\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1426  |AGENT :  1159  |RANDOM:  175  |DRAW:  91\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([6])\n",
            " - - -\n",
            " - - -\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - o -\n",
            " - - -\n",
            " x - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([2])\n",
            " - o x\n",
            " - - -\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - o x\n",
            " - - o\n",
            " x - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([4])\n",
            " - o x\n",
            " - x o\n",
            " x - -\n",
            "\n",
            "Game Number  1426\n",
            "agent won  1160\n",
            " - o x\n",
            " - x o\n",
            " x - -\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1427  |AGENT :  1160  |RANDOM:  175  |DRAW:  91\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([6])\n",
            " - - -\n",
            " - - -\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " - - -\n",
            " x - o\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([3])\n",
            " - - -\n",
            " x - -\n",
            " x - o\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " o - -\n",
            " x - -\n",
            " x - o\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([2])\n",
            " o - x\n",
            " x - -\n",
            " x - o\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " o - x\n",
            " x o -\n",
            " x - o\n",
            "\n",
            "random won  176\n",
            " o - x\n",
            " x o -\n",
            " x - o\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1428  |AGENT :  1160  |RANDOM:  176  |DRAW:  91\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "select action, random 0.9\n",
            " - - -\n",
            " - - -\n",
            " - x -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " - - -\n",
            " o x -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([3])\n",
            " - - -\n",
            " x - -\n",
            " o x -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " x - -\n",
            " o x o\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([2])\n",
            " - - x\n",
            " x - -\n",
            " o x o\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - x\n",
            " x - o\n",
            " o x o\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "select action, random 0.9\n",
            " - x x\n",
            " x - o\n",
            " o x o\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " o x x\n",
            " x - o\n",
            " o x o\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([4])\n",
            " o x x\n",
            " x x o\n",
            " o x o\n",
            "\n",
            "Game Number  1428\n",
            "agent won  1161\n",
            " o x x\n",
            " x x o\n",
            " o x o\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1429  |AGENT :  1161  |RANDOM:  176  |DRAW:  91\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([6])\n",
            " - - -\n",
            " - - -\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - o -\n",
            " - - -\n",
            " x - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([2])\n",
            " - o x\n",
            " - - -\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - o x\n",
            " o - -\n",
            " x - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([4])\n",
            " - o x\n",
            " o x -\n",
            " x - -\n",
            "\n",
            "Game Number  1429\n",
            "agent won  1162\n",
            " - o x\n",
            " o x -\n",
            " x - -\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1430  |AGENT :  1162  |RANDOM:  176  |DRAW:  91\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([6])\n",
            " - - -\n",
            " - - -\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " o - -\n",
            " - - -\n",
            " x - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([2])\n",
            " o - x\n",
            " - - -\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " o - x\n",
            " o - -\n",
            " x - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([8])\n",
            " o - x\n",
            " o - -\n",
            " x - x\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " o - x\n",
            " o - o\n",
            " x - x\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "select action, random 0.9\n",
            " o - x\n",
            " o x o\n",
            " x - x\n",
            "\n",
            "Game Number  1430\n",
            "agent won  1163\n",
            " o - x\n",
            " o x o\n",
            " x - x\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1431  |AGENT :  1163  |RANDOM:  176  |DRAW:  91\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([6])\n",
            " - - -\n",
            " - - -\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " - - -\n",
            " x o -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "select action, random 0.9\n",
            " - - -\n",
            " - x -\n",
            " x o -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " o x -\n",
            " x o -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "select action, random 0.9\n",
            " - - -\n",
            " o x x\n",
            " x o -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " o - -\n",
            " o x x\n",
            " x o -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([2])\n",
            " o - x\n",
            " o x x\n",
            " x o -\n",
            "\n",
            "Game Number  1431\n",
            "agent won  1164\n",
            " o - x\n",
            " o x x\n",
            " x o -\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1432  |AGENT :  1164  |RANDOM:  176  |DRAW:  91\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([6])\n",
            " - - -\n",
            " - - -\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " - o -\n",
            " x - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([5])\n",
            " - - -\n",
            " - o x\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - o\n",
            " - o x\n",
            " x - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "select action, random 0.9\n",
            " - - o\n",
            " - o x\n",
            " x - x\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - o o\n",
            " - o x\n",
            " x - x\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([0])\n",
            " x o o\n",
            " - o x\n",
            " x - x\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " x o o\n",
            " - o x\n",
            " x o x\n",
            "\n",
            "random won  177\n",
            " x o o\n",
            " - o x\n",
            " x o x\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1433  |AGENT :  1164  |RANDOM:  177  |DRAW:  91\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([6])\n",
            " - - -\n",
            " - - -\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - o -\n",
            " - - -\n",
            " x - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([2])\n",
            " - o x\n",
            " - - -\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - o x\n",
            " - - o\n",
            " x - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([4])\n",
            " - o x\n",
            " - x o\n",
            " x - -\n",
            "\n",
            "Game Number  1433\n",
            "agent won  1165\n",
            " - o x\n",
            " - x o\n",
            " x - -\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1434  |AGENT :  1165  |RANDOM:  177  |DRAW:  91\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([6])\n",
            " - - -\n",
            " - - -\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " - o -\n",
            " x - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([5])\n",
            " - - -\n",
            " - o x\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " - o x\n",
            " x o -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([0])\n",
            " x - -\n",
            " - o x\n",
            " x o -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " x - -\n",
            " o o x\n",
            " x o -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([2])\n",
            " x - x\n",
            " o o x\n",
            " x o -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " x - x\n",
            " o o x\n",
            " x o o\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "select action, random 0.9\n",
            " x x x\n",
            " o o x\n",
            " x o o\n",
            "\n",
            "Game Number  1434\n",
            "agent won  1166\n",
            " x x x\n",
            " o o x\n",
            " x o o\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1435  |AGENT :  1166  |RANDOM:  177  |DRAW:  91\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([6])\n",
            " - - -\n",
            " - - -\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - o -\n",
            " - - -\n",
            " x - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([2])\n",
            " - o x\n",
            " - - -\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - o x\n",
            " - o -\n",
            " x - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([5])\n",
            " - o x\n",
            " - o x\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - o x\n",
            " - o x\n",
            " x o -\n",
            "\n",
            "random won  178\n",
            " - o x\n",
            " - o x\n",
            " x o -\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1436  |AGENT :  1166  |RANDOM:  178  |DRAW:  91\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([6])\n",
            " - - -\n",
            " - - -\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " - - -\n",
            " x - o\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([3])\n",
            " - - -\n",
            " x - -\n",
            " x - o\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - o\n",
            " x - -\n",
            " x - o\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([4])\n",
            " - - o\n",
            " x x -\n",
            " x - o\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - o o\n",
            " x x -\n",
            " x - o\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "select action, random 0.9\n",
            " x o o\n",
            " x x -\n",
            " x - o\n",
            "\n",
            "Game Number  1436\n",
            "agent won  1167\n",
            " x o o\n",
            " x x -\n",
            " x - o\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1437  |AGENT :  1167  |RANDOM:  178  |DRAW:  91\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([6])\n",
            " - - -\n",
            " - - -\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " - - -\n",
            " x o -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([2])\n",
            " - - x\n",
            " - - -\n",
            " x o -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - x\n",
            " - o -\n",
            " x o -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([1])\n",
            " - x x\n",
            " - o -\n",
            " x o -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " o x x\n",
            " - o -\n",
            " x o -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([5])\n",
            " o x x\n",
            " - o x\n",
            " x o -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " o x x\n",
            " - o x\n",
            " x o o\n",
            "\n",
            "random won  179\n",
            " o x x\n",
            " - o x\n",
            " x o o\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1438  |AGENT :  1167  |RANDOM:  179  |DRAW:  91\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([6])\n",
            " - - -\n",
            " - - -\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " - o -\n",
            " x - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([5])\n",
            " - - -\n",
            " - o x\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - o\n",
            " - o x\n",
            " x - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([0])\n",
            " x - o\n",
            " - o x\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " x - o\n",
            " o o x\n",
            " x - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([1])\n",
            " x x o\n",
            " o o x\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " x x o\n",
            " o o x\n",
            " x o -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([8])\n",
            " x x o\n",
            " o o x\n",
            " x o x\n",
            "\n",
            "draw  92\n",
            " x x o\n",
            " o o x\n",
            " x o x\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1439  |AGENT :  1167  |RANDOM:  179  |DRAW:  92\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([6])\n",
            " - - -\n",
            " - - -\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " - - o\n",
            " x - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([3])\n",
            " - - -\n",
            " x - o\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " x o o\n",
            " x - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([8])\n",
            " - - -\n",
            " x o o\n",
            " x - x\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " x o o\n",
            " x o x\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([1])\n",
            " - x -\n",
            " x o o\n",
            " x o x\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " o x -\n",
            " x o o\n",
            " x o x\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([2])\n",
            " o x x\n",
            " x o o\n",
            " x o x\n",
            "\n",
            "draw  93\n",
            " o x x\n",
            " x o o\n",
            " x o x\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1440  |AGENT :  1167  |RANDOM:  179  |DRAW:  93\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "select action, random 0.9\n",
            " - - -\n",
            " - - -\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " - - -\n",
            " x - o\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([3])\n",
            " - - -\n",
            " x - -\n",
            " x - o\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " x - -\n",
            " x o o\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([4])\n",
            " - - -\n",
            " x x -\n",
            " x o o\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - o -\n",
            " x x -\n",
            " x o o\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([2])\n",
            " - o x\n",
            " x x -\n",
            " x o o\n",
            "\n",
            "Game Number  1440\n",
            "agent won  1168\n",
            " - o x\n",
            " x x -\n",
            " x o o\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1441  |AGENT :  1168  |RANDOM:  179  |DRAW:  93\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([6])\n",
            " - - -\n",
            " - - -\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " - o -\n",
            " x - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([5])\n",
            " - - -\n",
            " - o x\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " - o x\n",
            " x - o\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([2])\n",
            " - - x\n",
            " - o x\n",
            " x - o\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - x\n",
            " o o x\n",
            " x - o\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([7])\n",
            " - - x\n",
            " o o x\n",
            " x x o\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - o x\n",
            " o o x\n",
            " x x o\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([0])\n",
            " x o x\n",
            " o o x\n",
            " x x o\n",
            "\n",
            "draw  94\n",
            " x o x\n",
            " o o x\n",
            " x x o\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1442  |AGENT :  1168  |RANDOM:  179  |DRAW:  94\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([6])\n",
            " - - -\n",
            " - - -\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " - - -\n",
            " x o -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "select action, random 0.9\n",
            " - - -\n",
            " - - -\n",
            " x o x\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " o - -\n",
            " x o x\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([0])\n",
            " x - -\n",
            " o - -\n",
            " x o x\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " x - -\n",
            " o o -\n",
            " x o x\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([2])\n",
            " x - x\n",
            " o o -\n",
            " x o x\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " x - x\n",
            " o o o\n",
            " x o x\n",
            "\n",
            "random won  180\n",
            " x - x\n",
            " o o o\n",
            " x o x\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1443  |AGENT :  1168  |RANDOM:  180  |DRAW:  94\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([6])\n",
            " - - -\n",
            " - - -\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " o - -\n",
            " - - -\n",
            " x - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([2])\n",
            " o - x\n",
            " - - -\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " o - x\n",
            " o - -\n",
            " x - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([8])\n",
            " o - x\n",
            " o - -\n",
            " x - x\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " o - x\n",
            " o o -\n",
            " x - x\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([5])\n",
            " o - x\n",
            " o o x\n",
            " x - x\n",
            "\n",
            "Game Number  1443\n",
            "agent won  1169\n",
            " o - x\n",
            " o o x\n",
            " x - x\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1444  |AGENT :  1169  |RANDOM:  180  |DRAW:  94\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([6])\n",
            " - - -\n",
            " - - -\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " - - -\n",
            " x o -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([2])\n",
            " - - x\n",
            " - - -\n",
            " x o -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - x\n",
            " o - -\n",
            " x o -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([4])\n",
            " - - x\n",
            " o x -\n",
            " x o -\n",
            "\n",
            "Game Number  1444\n",
            "agent won  1170\n",
            " - - x\n",
            " o x -\n",
            " x o -\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1445  |AGENT :  1170  |RANDOM:  180  |DRAW:  94\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([6])\n",
            " - - -\n",
            " - - -\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - o\n",
            " - - -\n",
            " x - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([4])\n",
            " - - o\n",
            " - x -\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - o\n",
            " o x -\n",
            " x - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([1])\n",
            " - x o\n",
            " o x -\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " o x o\n",
            " o x -\n",
            " x - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([8])\n",
            " o x o\n",
            " o x -\n",
            " x - x\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " o x o\n",
            " o x -\n",
            " x o x\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([5])\n",
            " o x o\n",
            " o x x\n",
            " x o x\n",
            "\n",
            "draw  95\n",
            " o x o\n",
            " o x x\n",
            " x o x\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1446  |AGENT :  1170  |RANDOM:  180  |DRAW:  95\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([6])\n",
            " - - -\n",
            " - - -\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " o - -\n",
            " - - -\n",
            " x - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([2])\n",
            " o - x\n",
            " - - -\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " o - x\n",
            " - - -\n",
            " x - o\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([4])\n",
            " o - x\n",
            " - x -\n",
            " x - o\n",
            "\n",
            "Game Number  1446\n",
            "agent won  1171\n",
            " o - x\n",
            " - x -\n",
            " x - o\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1447  |AGENT :  1171  |RANDOM:  180  |DRAW:  95\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([6])\n",
            " - - -\n",
            " - - -\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " - - o\n",
            " x - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([3])\n",
            " - - -\n",
            " x - o\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - o -\n",
            " x - o\n",
            " x - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([2])\n",
            " - o x\n",
            " x - o\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - o x\n",
            " x - o\n",
            " x o -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([0])\n",
            " x o x\n",
            " x - o\n",
            " x o -\n",
            "\n",
            "Game Number  1447\n",
            "agent won  1172\n",
            " x o x\n",
            " x - o\n",
            " x o -\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1448  |AGENT :  1172  |RANDOM:  180  |DRAW:  95\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([6])\n",
            " - - -\n",
            " - - -\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " - - o\n",
            " x - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "select action, random 0.9\n",
            " - - x\n",
            " - - o\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - x\n",
            " - o o\n",
            " x - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([1])\n",
            " - x x\n",
            " - o o\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " o x x\n",
            " - o o\n",
            " x - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([8])\n",
            " o x x\n",
            " - o o\n",
            " x - x\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " o x x\n",
            " o o o\n",
            " x - x\n",
            "\n",
            "random won  181\n",
            " o x x\n",
            " o o o\n",
            " x - x\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1449  |AGENT :  1172  |RANDOM:  181  |DRAW:  95\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([6])\n",
            " - - -\n",
            " - - -\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " o - -\n",
            " - - -\n",
            " x - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([2])\n",
            " o - x\n",
            " - - -\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " o - x\n",
            " - - -\n",
            " x - o\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "select action, random 0.9\n",
            " o - x\n",
            " - - x\n",
            " x - o\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " o o x\n",
            " - - x\n",
            " x - o\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([4])\n",
            " o o x\n",
            " - x x\n",
            " x - o\n",
            "\n",
            "Game Number  1449\n",
            "agent won  1173\n",
            " o o x\n",
            " - x x\n",
            " x - o\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1450  |AGENT :  1173  |RANDOM:  181  |DRAW:  95\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "select action, random 0.9\n",
            " - - x\n",
            " - - -\n",
            " - - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - x\n",
            " - - -\n",
            " o - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([8])\n",
            " - - x\n",
            " - - -\n",
            " o - x\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - o x\n",
            " - - -\n",
            " o - x\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([4])\n",
            " - o x\n",
            " - x -\n",
            " o - x\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " o o x\n",
            " - x -\n",
            " o - x\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([3])\n",
            " o o x\n",
            " x x -\n",
            " o - x\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " o o x\n",
            " x x o\n",
            " o - x\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([7])\n",
            " o o x\n",
            " x x o\n",
            " o x x\n",
            "\n",
            "draw  96\n",
            " o o x\n",
            " x x o\n",
            " o x x\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1451  |AGENT :  1173  |RANDOM:  181  |DRAW:  96\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([6])\n",
            " - - -\n",
            " - - -\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " - o -\n",
            " x - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([5])\n",
            " - - -\n",
            " - o x\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - o\n",
            " - o x\n",
            " x - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([0])\n",
            " x - o\n",
            " - o x\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " x - o\n",
            " - o x\n",
            " x o -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([3])\n",
            " x - o\n",
            " x o x\n",
            " x o -\n",
            "\n",
            "Game Number  1451\n",
            "agent won  1174\n",
            " x - o\n",
            " x o x\n",
            " x o -\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1452  |AGENT :  1174  |RANDOM:  181  |DRAW:  96\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([6])\n",
            " - - -\n",
            " - - -\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " o - -\n",
            " - - -\n",
            " x - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([2])\n",
            " o - x\n",
            " - - -\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " o o x\n",
            " - - -\n",
            " x - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([5])\n",
            " o o x\n",
            " - - x\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " o o x\n",
            " - o x\n",
            " x - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([8])\n",
            " o o x\n",
            " - o x\n",
            " x - x\n",
            "\n",
            "Game Number  1452\n",
            "agent won  1175\n",
            " o o x\n",
            " - o x\n",
            " x - x\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1453  |AGENT :  1175  |RANDOM:  181  |DRAW:  96\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([6])\n",
            " - - -\n",
            " - - -\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " - - -\n",
            " x - o\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "select action, random 0.9\n",
            " - - -\n",
            " - - -\n",
            " x x o\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " o - -\n",
            " - - -\n",
            " x x o\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "select action, random 0.9\n",
            " o x -\n",
            " - - -\n",
            " x x o\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " o x o\n",
            " - - -\n",
            " x x o\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([4])\n",
            " o x o\n",
            " - x -\n",
            " x x o\n",
            "\n",
            "Game Number  1453\n",
            "agent won  1176\n",
            " o x o\n",
            " - x -\n",
            " x x o\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1454  |AGENT :  1176  |RANDOM:  181  |DRAW:  96\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([6])\n",
            " - - -\n",
            " - - -\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " o - -\n",
            " x - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([4])\n",
            " - - -\n",
            " o x -\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - o -\n",
            " o x -\n",
            " x - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([2])\n",
            " - o x\n",
            " o x -\n",
            " x - -\n",
            "\n",
            "Game Number  1454\n",
            "agent won  1177\n",
            " - o x\n",
            " o x -\n",
            " x - -\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1455  |AGENT :  1177  |RANDOM:  181  |DRAW:  96\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([6])\n",
            " - - -\n",
            " - - -\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " - - -\n",
            " x o -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([2])\n",
            " - - x\n",
            " - - -\n",
            " x o -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " o - x\n",
            " - - -\n",
            " x o -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([4])\n",
            " o - x\n",
            " - x -\n",
            " x o -\n",
            "\n",
            "Game Number  1455\n",
            "agent won  1178\n",
            " o - x\n",
            " - x -\n",
            " x o -\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1456  |AGENT :  1178  |RANDOM:  181  |DRAW:  96\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([6])\n",
            " - - -\n",
            " - - -\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " - o -\n",
            " x - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([5])\n",
            " - - -\n",
            " - o x\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - o -\n",
            " - o x\n",
            " x - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([0])\n",
            " x o -\n",
            " - o x\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " x o -\n",
            " - o x\n",
            " x - o\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([2])\n",
            " x o x\n",
            " - o x\n",
            " x - o\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " x o x\n",
            " - o x\n",
            " x o o\n",
            "\n",
            "random won  182\n",
            " x o x\n",
            " - o x\n",
            " x o o\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1457  |AGENT :  1178  |RANDOM:  182  |DRAW:  96\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([6])\n",
            " - - -\n",
            " - - -\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " o - -\n",
            " - - -\n",
            " x - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([2])\n",
            " o - x\n",
            " - - -\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " o - x\n",
            " - - o\n",
            " x - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([3])\n",
            " o - x\n",
            " x - o\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " o o x\n",
            " x - o\n",
            " x - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([4])\n",
            " o o x\n",
            " x x o\n",
            " x - -\n",
            "\n",
            "Game Number  1457\n",
            "agent won  1179\n",
            " o o x\n",
            " x x o\n",
            " x - -\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1458  |AGENT :  1179  |RANDOM:  182  |DRAW:  96\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([6])\n",
            " - - -\n",
            " - - -\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " - - -\n",
            " x o -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([2])\n",
            " - - x\n",
            " - - -\n",
            " x o -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - x\n",
            " - o -\n",
            " x o -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([1])\n",
            " - x x\n",
            " - o -\n",
            " x o -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - x x\n",
            " - o -\n",
            " x o o\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([0])\n",
            " x x x\n",
            " - o -\n",
            " x o o\n",
            "\n",
            "Game Number  1458\n",
            "agent won  1180\n",
            " x x x\n",
            " - o -\n",
            " x o o\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1459  |AGENT :  1180  |RANDOM:  182  |DRAW:  96\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([6])\n",
            " - - -\n",
            " - - -\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " o - -\n",
            " - - -\n",
            " x - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([2])\n",
            " o - x\n",
            " - - -\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " o - x\n",
            " o - -\n",
            " x - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([8])\n",
            " o - x\n",
            " o - -\n",
            " x - x\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " o - x\n",
            " o - -\n",
            " x o x\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([4])\n",
            " o - x\n",
            " o x -\n",
            " x o x\n",
            "\n",
            "Game Number  1459\n",
            "agent won  1181\n",
            " o - x\n",
            " o x -\n",
            " x o x\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1460  |AGENT :  1181  |RANDOM:  182  |DRAW:  96\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([6])\n",
            " - - -\n",
            " - - -\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - o\n",
            " - - -\n",
            " x - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([4])\n",
            " - - o\n",
            " - x -\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - o\n",
            " o x -\n",
            " x - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([1])\n",
            " - x o\n",
            " o x -\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - x o\n",
            " o x o\n",
            " x - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([0])\n",
            " x x o\n",
            " o x o\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " x x o\n",
            " o x o\n",
            " x - o\n",
            "\n",
            "random won  183\n",
            " x x o\n",
            " o x o\n",
            " x - o\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1461  |AGENT :  1181  |RANDOM:  183  |DRAW:  96\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([6])\n",
            " - - -\n",
            " - - -\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " o - -\n",
            " x - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([4])\n",
            " - - -\n",
            " o x -\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - o\n",
            " o x -\n",
            " x - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([1])\n",
            " - x o\n",
            " o x -\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - x o\n",
            " o x -\n",
            " x o -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([0])\n",
            " x x o\n",
            " o x -\n",
            " x o -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " x x o\n",
            " o x -\n",
            " x o o\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([5])\n",
            " x x o\n",
            " o x x\n",
            " x o o\n",
            "\n",
            "draw  97\n",
            " x x o\n",
            " o x x\n",
            " x o o\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1462  |AGENT :  1181  |RANDOM:  183  |DRAW:  97\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([6])\n",
            " - - -\n",
            " - - -\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " o - -\n",
            " - - -\n",
            " x - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([2])\n",
            " o - x\n",
            " - - -\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " o - x\n",
            " - - -\n",
            " x o -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([4])\n",
            " o - x\n",
            " - x -\n",
            " x o -\n",
            "\n",
            "Game Number  1462\n",
            "agent won  1182\n",
            " o - x\n",
            " - x -\n",
            " x o -\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1463  |AGENT :  1182  |RANDOM:  183  |DRAW:  97\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([6])\n",
            " - - -\n",
            " - - -\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " o - -\n",
            " x - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "select action, random 0.9\n",
            " - - x\n",
            " o - -\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - x\n",
            " o o -\n",
            " x - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([5])\n",
            " - - x\n",
            " o o x\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - x\n",
            " o o x\n",
            " x o -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([1])\n",
            " - x x\n",
            " o o x\n",
            " x o -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " o x x\n",
            " o o x\n",
            " x o -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([8])\n",
            " o x x\n",
            " o o x\n",
            " x o x\n",
            "\n",
            "Game Number  1463\n",
            "agent won  1183\n",
            " o x x\n",
            " o o x\n",
            " x o x\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1464  |AGENT :  1183  |RANDOM:  183  |DRAW:  97\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([6])\n",
            " - - -\n",
            " - - -\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - o -\n",
            " - - -\n",
            " x - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([2])\n",
            " - o x\n",
            " - - -\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - o x\n",
            " - - o\n",
            " x - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([4])\n",
            " - o x\n",
            " - x o\n",
            " x - -\n",
            "\n",
            "Game Number  1464\n",
            "agent won  1184\n",
            " - o x\n",
            " - x o\n",
            " x - -\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1465  |AGENT :  1184  |RANDOM:  183  |DRAW:  97\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([6])\n",
            " - - -\n",
            " - - -\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " - - o\n",
            " x - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([3])\n",
            " - - -\n",
            " x - o\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - o -\n",
            " x - o\n",
            " x - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([2])\n",
            " - o x\n",
            " x - o\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - o x\n",
            " x - o\n",
            " x o -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([0])\n",
            " x o x\n",
            " x - o\n",
            " x o -\n",
            "\n",
            "Game Number  1465\n",
            "agent won  1185\n",
            " x o x\n",
            " x - o\n",
            " x o -\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1466  |AGENT :  1185  |RANDOM:  183  |DRAW:  97\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "select action, random 0.9\n",
            " - - -\n",
            " - - -\n",
            " - x -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - o -\n",
            " - - -\n",
            " - x -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([6])\n",
            " - o -\n",
            " - - -\n",
            " x x -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - o -\n",
            " - - o\n",
            " x x -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([2])\n",
            " - o x\n",
            " - - o\n",
            " x x -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - o x\n",
            " o - o\n",
            " x x -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([4])\n",
            " - o x\n",
            " o x o\n",
            " x x -\n",
            "\n",
            "Game Number  1466\n",
            "agent won  1186\n",
            " - o x\n",
            " o x o\n",
            " x x -\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1467  |AGENT :  1186  |RANDOM:  183  |DRAW:  97\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([6])\n",
            " - - -\n",
            " - - -\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - o -\n",
            " - - -\n",
            " x - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([2])\n",
            " - o x\n",
            " - - -\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - o x\n",
            " - - o\n",
            " x - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([4])\n",
            " - o x\n",
            " - x o\n",
            " x - -\n",
            "\n",
            "Game Number  1467\n",
            "agent won  1187\n",
            " - o x\n",
            " - x o\n",
            " x - -\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1468  |AGENT :  1187  |RANDOM:  183  |DRAW:  97\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([6])\n",
            " - - -\n",
            " - - -\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " - - o\n",
            " x - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([3])\n",
            " - - -\n",
            " x - o\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - o\n",
            " x - o\n",
            " x - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "select action, random 0.9\n",
            " - - o\n",
            " x - o\n",
            " x x -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - o o\n",
            " x - o\n",
            " x x -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "select action, random 0.9\n",
            " - o o\n",
            " x - o\n",
            " x x x\n",
            "\n",
            "Game Number  1468\n",
            "agent won  1188\n",
            " - o o\n",
            " x - o\n",
            " x x x\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1469  |AGENT :  1188  |RANDOM:  183  |DRAW:  97\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([6])\n",
            " - - -\n",
            " - - -\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - o -\n",
            " - - -\n",
            " x - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([2])\n",
            " - o x\n",
            " - - -\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - o x\n",
            " - - o\n",
            " x - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([4])\n",
            " - o x\n",
            " - x o\n",
            " x - -\n",
            "\n",
            "Game Number  1469\n",
            "agent won  1189\n",
            " - o x\n",
            " - x o\n",
            " x - -\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1470  |AGENT :  1189  |RANDOM:  183  |DRAW:  97\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([6])\n",
            " - - -\n",
            " - - -\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " - - -\n",
            " x - o\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "select action, random 0.9\n",
            " - - -\n",
            " - - x\n",
            " x - o\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " - o x\n",
            " x - o\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([2])\n",
            " - - x\n",
            " - o x\n",
            " x - o\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - x\n",
            " - o x\n",
            " x o o\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([0])\n",
            " x - x\n",
            " - o x\n",
            " x o o\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " x - x\n",
            " o o x\n",
            " x o o\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([1])\n",
            " x x x\n",
            " o o x\n",
            " x o o\n",
            "\n",
            "Game Number  1470\n",
            "agent won  1190\n",
            " x x x\n",
            " o o x\n",
            " x o o\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1471  |AGENT :  1190  |RANDOM:  183  |DRAW:  97\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([6])\n",
            " - - -\n",
            " - - -\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " - o -\n",
            " x - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([5])\n",
            " - - -\n",
            " - o x\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " - o x\n",
            " x - o\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([2])\n",
            " - - x\n",
            " - o x\n",
            " x - o\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - o x\n",
            " - o x\n",
            " x - o\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([3])\n",
            " - o x\n",
            " x o x\n",
            " x - o\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " o o x\n",
            " x o x\n",
            " x - o\n",
            "\n",
            "random won  184\n",
            " o o x\n",
            " x o x\n",
            " x - o\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1472  |AGENT :  1190  |RANDOM:  184  |DRAW:  97\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([6])\n",
            " - - -\n",
            " - - -\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " o - -\n",
            " - - -\n",
            " x - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([2])\n",
            " o - x\n",
            " - - -\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " o o x\n",
            " - - -\n",
            " x - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([5])\n",
            " o o x\n",
            " - - x\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " o o x\n",
            " - - x\n",
            " x - o\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([4])\n",
            " o o x\n",
            " - x x\n",
            " x - o\n",
            "\n",
            "Game Number  1472\n",
            "agent won  1191\n",
            " o o x\n",
            " - x x\n",
            " x - o\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1473  |AGENT :  1191  |RANDOM:  184  |DRAW:  97\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([6])\n",
            " - - -\n",
            " - - -\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " - - -\n",
            " x o -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([2])\n",
            " - - x\n",
            " - - -\n",
            " x o -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - x\n",
            " - - -\n",
            " x o o\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([0])\n",
            " x - x\n",
            " - - -\n",
            " x o o\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " x - x\n",
            " - - o\n",
            " x o o\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([4])\n",
            " x - x\n",
            " - x o\n",
            " x o o\n",
            "\n",
            "Game Number  1473\n",
            "agent won  1192\n",
            " x - x\n",
            " - x o\n",
            " x o o\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1474  |AGENT :  1192  |RANDOM:  184  |DRAW:  97\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([6])\n",
            " - - -\n",
            " - - -\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - o\n",
            " - - -\n",
            " x - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([4])\n",
            " - - o\n",
            " - x -\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - o o\n",
            " - x -\n",
            " x - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "select action, random 0.9\n",
            " - o o\n",
            " x x -\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " o o o\n",
            " x x -\n",
            " x - -\n",
            "\n",
            "random won  185\n",
            " o o o\n",
            " x x -\n",
            " x - -\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1475  |AGENT :  1192  |RANDOM:  185  |DRAW:  97\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([6])\n",
            " - - -\n",
            " - - -\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - o -\n",
            " - - -\n",
            " x - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([2])\n",
            " - o x\n",
            " - - -\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - o x\n",
            " - o -\n",
            " x - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([5])\n",
            " - o x\n",
            " - o x\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " o o x\n",
            " - o x\n",
            " x - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([8])\n",
            " o o x\n",
            " - o x\n",
            " x - x\n",
            "\n",
            "Game Number  1475\n",
            "agent won  1193\n",
            " o o x\n",
            " - o x\n",
            " x - x\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1476  |AGENT :  1193  |RANDOM:  185  |DRAW:  97\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([6])\n",
            " - - -\n",
            " - - -\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " - o -\n",
            " x - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([5])\n",
            " - - -\n",
            " - o x\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " o - -\n",
            " - o x\n",
            " x - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([2])\n",
            " o - x\n",
            " - o x\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " o o x\n",
            " - o x\n",
            " x - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "select action, random 0.9\n",
            " o o x\n",
            " - o x\n",
            " x - x\n",
            "\n",
            "Game Number  1476\n",
            "agent won  1194\n",
            " o o x\n",
            " - o x\n",
            " x - x\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1477  |AGENT :  1194  |RANDOM:  185  |DRAW:  97\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([6])\n",
            " - - -\n",
            " - - -\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - o\n",
            " - - -\n",
            " x - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "select action, random 0.9\n",
            " x - o\n",
            " - - -\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " x o o\n",
            " - - -\n",
            " x - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([4])\n",
            " x o o\n",
            " - x -\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " x o o\n",
            " o x -\n",
            " x - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([7])\n",
            " x o o\n",
            " o x -\n",
            " x x -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " x o o\n",
            " o x -\n",
            " x x o\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([5])\n",
            " x o o\n",
            " o x x\n",
            " x x o\n",
            "\n",
            "draw  98\n",
            " x o o\n",
            " o x x\n",
            " x x o\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1478  |AGENT :  1194  |RANDOM:  185  |DRAW:  98\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([6])\n",
            " - - -\n",
            " - - -\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " - - o\n",
            " x - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([3])\n",
            " - - -\n",
            " x - o\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - o -\n",
            " x - o\n",
            " x - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([2])\n",
            " - o x\n",
            " x - o\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - o x\n",
            " x - o\n",
            " x - o\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([4])\n",
            " - o x\n",
            " x x o\n",
            " x - o\n",
            "\n",
            "Game Number  1478\n",
            "agent won  1195\n",
            " - o x\n",
            " x x o\n",
            " x - o\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1479  |AGENT :  1195  |RANDOM:  185  |DRAW:  98\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "select action, random 0.9\n",
            " x - -\n",
            " - - -\n",
            " - - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " x - -\n",
            " - - -\n",
            " - - o\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([2])\n",
            " x - x\n",
            " - - -\n",
            " - - o\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " x - x\n",
            " o - -\n",
            " - - o\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([6])\n",
            " x - x\n",
            " o - -\n",
            " x - o\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " x - x\n",
            " o - -\n",
            " x o o\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "select action, random 0.9\n",
            " x - x\n",
            " o x -\n",
            " x o o\n",
            "\n",
            "Game Number  1479\n",
            "agent won  1196\n",
            " x - x\n",
            " o x -\n",
            " x o o\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1480  |AGENT :  1196  |RANDOM:  185  |DRAW:  98\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([6])\n",
            " - - -\n",
            " - - -\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - o\n",
            " - - -\n",
            " x - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([4])\n",
            " - - o\n",
            " - x -\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - o\n",
            " - x -\n",
            " x - o\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([3])\n",
            " - - o\n",
            " x x -\n",
            " x - o\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - o\n",
            " x x o\n",
            " x - o\n",
            "\n",
            "random won  186\n",
            " - - o\n",
            " x x o\n",
            " x - o\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1481  |AGENT :  1196  |RANDOM:  186  |DRAW:  98\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([6])\n",
            " - - -\n",
            " - - -\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - o\n",
            " - - -\n",
            " x - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([4])\n",
            " - - o\n",
            " - x -\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " o - o\n",
            " - x -\n",
            " x - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "select action, random 0.9\n",
            " o - o\n",
            " - x x\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " o o o\n",
            " - x x\n",
            " x - -\n",
            "\n",
            "random won  187\n",
            " o o o\n",
            " - x x\n",
            " x - -\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1482  |AGENT :  1196  |RANDOM:  187  |DRAW:  98\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([6])\n",
            " - - -\n",
            " - - -\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " - - -\n",
            " x - o\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([3])\n",
            " - - -\n",
            " x - -\n",
            " x - o\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - o\n",
            " x - -\n",
            " x - o\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([4])\n",
            " - - o\n",
            " x x -\n",
            " x - o\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - o\n",
            " x x o\n",
            " x - o\n",
            "\n",
            "random won  188\n",
            " - - o\n",
            " x x o\n",
            " x - o\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1483  |AGENT :  1196  |RANDOM:  188  |DRAW:  98\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([6])\n",
            " - - -\n",
            " - - -\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " - o -\n",
            " x - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "select action, random 0.9\n",
            " - - -\n",
            " - o -\n",
            " x x -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " o o -\n",
            " x x -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([8])\n",
            " - - -\n",
            " o o -\n",
            " x x x\n",
            "\n",
            "Game Number  1483\n",
            "agent won  1197\n",
            " - - -\n",
            " o o -\n",
            " x x x\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1484  |AGENT :  1197  |RANDOM:  188  |DRAW:  98\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([6])\n",
            " - - -\n",
            " - - -\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " - - o\n",
            " x - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([3])\n",
            " - - -\n",
            " x - o\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " x o o\n",
            " x - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([8])\n",
            " - - -\n",
            " x o o\n",
            " x - x\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - o\n",
            " x o o\n",
            " x - x\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([7])\n",
            " - - o\n",
            " x o o\n",
            " x x x\n",
            "\n",
            "Game Number  1484\n",
            "agent won  1198\n",
            " - - o\n",
            " x o o\n",
            " x x x\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1485  |AGENT :  1198  |RANDOM:  188  |DRAW:  98\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "select action, random 0.9\n",
            " - - -\n",
            " - x -\n",
            " - - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - o\n",
            " - x -\n",
            " - - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([1])\n",
            " - x o\n",
            " - x -\n",
            " - - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - x o\n",
            " o x -\n",
            " - - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([6])\n",
            " - x o\n",
            " o x -\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - x o\n",
            " o x o\n",
            " x - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([0])\n",
            " x x o\n",
            " o x o\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " x x o\n",
            " o x o\n",
            " x - o\n",
            "\n",
            "random won  189\n",
            " x x o\n",
            " o x o\n",
            " x - o\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1486  |AGENT :  1198  |RANDOM:  189  |DRAW:  98\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "select action, random 0.9\n",
            " - - -\n",
            " x - -\n",
            " - - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " x - -\n",
            " - - o\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "select action, random 0.9\n",
            " - - x\n",
            " x - -\n",
            " - - o\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - x\n",
            " x - -\n",
            " o - o\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([4])\n",
            " - - x\n",
            " x x -\n",
            " o - o\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " o - x\n",
            " x x -\n",
            " o - o\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([7])\n",
            " o - x\n",
            " x x -\n",
            " o x o\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " o - x\n",
            " x x o\n",
            " o x o\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([1])\n",
            " o x x\n",
            " x x o\n",
            " o x o\n",
            "\n",
            "Game Number  1486\n",
            "agent won  1199\n",
            " o x x\n",
            " x x o\n",
            " o x o\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1487  |AGENT :  1199  |RANDOM:  189  |DRAW:  98\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([6])\n",
            " - - -\n",
            " - - -\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " o - -\n",
            " x - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([4])\n",
            " - - -\n",
            " o x -\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - o\n",
            " o x -\n",
            " x - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([1])\n",
            " - x o\n",
            " o x -\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - x o\n",
            " o x -\n",
            " x - o\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([5])\n",
            " - x o\n",
            " o x x\n",
            " x - o\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - x o\n",
            " o x x\n",
            " x o o\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([0])\n",
            " x x o\n",
            " o x x\n",
            " x o o\n",
            "\n",
            "draw  99\n",
            " x x o\n",
            " o x x\n",
            " x o o\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1488  |AGENT :  1199  |RANDOM:  189  |DRAW:  99\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([6])\n",
            " - - -\n",
            " - - -\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " - - -\n",
            " x - o\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([3])\n",
            " - - -\n",
            " x - -\n",
            " x - o\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " x - o\n",
            " x - o\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([2])\n",
            " - - x\n",
            " x - o\n",
            " x - o\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - x\n",
            " x - o\n",
            " x o o\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([4])\n",
            " - - x\n",
            " x x o\n",
            " x o o\n",
            "\n",
            "Game Number  1488\n",
            "agent won  1200\n",
            " - - x\n",
            " x x o\n",
            " x o o\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1489  |AGENT :  1200  |RANDOM:  189  |DRAW:  99\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([6])\n",
            " - - -\n",
            " - - -\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " - - -\n",
            " x o -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([2])\n",
            " - - x\n",
            " - - -\n",
            " x o -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - x\n",
            " o - -\n",
            " x o -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([4])\n",
            " - - x\n",
            " o x -\n",
            " x o -\n",
            "\n",
            "Game Number  1489\n",
            "agent won  1201\n",
            " - - x\n",
            " o x -\n",
            " x o -\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1490  |AGENT :  1201  |RANDOM:  189  |DRAW:  99\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "select action, random 0.9\n",
            " - - -\n",
            " - - x\n",
            " - - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " - o x\n",
            " - - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([6])\n",
            " - - -\n",
            " - o x\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " o - -\n",
            " - o x\n",
            " x - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([2])\n",
            " o - x\n",
            " - o x\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " o - x\n",
            " - o x\n",
            " x - o\n",
            "\n",
            "random won  190\n",
            " o - x\n",
            " - o x\n",
            " x - o\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1491  |AGENT :  1201  |RANDOM:  190  |DRAW:  99\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([6])\n",
            " - - -\n",
            " - - -\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - o -\n",
            " - - -\n",
            " x - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([2])\n",
            " - o x\n",
            " - - -\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - o x\n",
            " - - -\n",
            " x - o\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "select action, random 0.9\n",
            " - o x\n",
            " x - -\n",
            " x - o\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - o x\n",
            " x - o\n",
            " x - o\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([4])\n",
            " - o x\n",
            " x x o\n",
            " x - o\n",
            "\n",
            "Game Number  1491\n",
            "agent won  1202\n",
            " - o x\n",
            " x x o\n",
            " x - o\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1492  |AGENT :  1202  |RANDOM:  190  |DRAW:  99\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([6])\n",
            " - - -\n",
            " - - -\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " - - o\n",
            " x - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([3])\n",
            " - - -\n",
            " x - o\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " x - o\n",
            " x o -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([0])\n",
            " x - -\n",
            " x - o\n",
            " x o -\n",
            "\n",
            "Game Number  1492\n",
            "agent won  1203\n",
            " x - -\n",
            " x - o\n",
            " x o -\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1493  |AGENT :  1203  |RANDOM:  190  |DRAW:  99\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([6])\n",
            " - - -\n",
            " - - -\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " - - -\n",
            " x o -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([2])\n",
            " - - x\n",
            " - - -\n",
            " x o -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - x\n",
            " - o -\n",
            " x o -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([1])\n",
            " - x x\n",
            " - o -\n",
            " x o -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " o x x\n",
            " - o -\n",
            " x o -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([5])\n",
            " o x x\n",
            " - o x\n",
            " x o -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " o x x\n",
            " - o x\n",
            " x o o\n",
            "\n",
            "random won  191\n",
            " o x x\n",
            " - o x\n",
            " x o o\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1494  |AGENT :  1203  |RANDOM:  191  |DRAW:  99\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([6])\n",
            " - - -\n",
            " - - -\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " - - -\n",
            " x - o\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([3])\n",
            " - - -\n",
            " x - -\n",
            " x - o\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " o - -\n",
            " x - -\n",
            " x - o\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([2])\n",
            " o - x\n",
            " x - -\n",
            " x - o\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " o - x\n",
            " x o -\n",
            " x - o\n",
            "\n",
            "random won  192\n",
            " o - x\n",
            " x o -\n",
            " x - o\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1495  |AGENT :  1203  |RANDOM:  192  |DRAW:  99\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([6])\n",
            " - - -\n",
            " - - -\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " - - o\n",
            " x - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([3])\n",
            " - - -\n",
            " x - o\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " o - -\n",
            " x - o\n",
            " x - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([4])\n",
            " o - -\n",
            " x x o\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " o - o\n",
            " x x o\n",
            " x - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([1])\n",
            " o x o\n",
            " x x o\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " o x o\n",
            " x x o\n",
            " x o -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([8])\n",
            " o x o\n",
            " x x o\n",
            " x o x\n",
            "\n",
            "draw  100\n",
            " o x o\n",
            " x x o\n",
            " x o x\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1496  |AGENT :  1203  |RANDOM:  192  |DRAW:  100\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([6])\n",
            " - - -\n",
            " - - -\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " - o -\n",
            " x - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([5])\n",
            " - - -\n",
            " - o x\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - o -\n",
            " - o x\n",
            " x - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "select action, random 0.9\n",
            " - o -\n",
            " - o x\n",
            " x x -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - o -\n",
            " - o x\n",
            " x x o\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([3])\n",
            " - o -\n",
            " x o x\n",
            " x x o\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " o o -\n",
            " x o x\n",
            " x x o\n",
            "\n",
            "random won  193\n",
            " o o -\n",
            " x o x\n",
            " x x o\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1497  |AGENT :  1203  |RANDOM:  193  |DRAW:  100\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([6])\n",
            " - - -\n",
            " - - -\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " - o -\n",
            " x - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([5])\n",
            " - - -\n",
            " - o x\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " - o x\n",
            " x o -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([0])\n",
            " x - -\n",
            " - o x\n",
            " x o -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " x - -\n",
            " - o x\n",
            " x o o\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([3])\n",
            " x - -\n",
            " x o x\n",
            " x o o\n",
            "\n",
            "Game Number  1497\n",
            "agent won  1204\n",
            " x - -\n",
            " x o x\n",
            " x o o\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1498  |AGENT :  1204  |RANDOM:  193  |DRAW:  100\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([6])\n",
            " - - -\n",
            " - - -\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - o\n",
            " - - -\n",
            " x - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([4])\n",
            " - - o\n",
            " - x -\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - o\n",
            " o x -\n",
            " x - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "select action, random 0.9\n",
            " - - o\n",
            " o x -\n",
            " x x -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - o o\n",
            " o x -\n",
            " x x -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([8])\n",
            " - o o\n",
            " o x -\n",
            " x x x\n",
            "\n",
            "Game Number  1498\n",
            "agent won  1205\n",
            " - o o\n",
            " o x -\n",
            " x x x\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1499  |AGENT :  1205  |RANDOM:  193  |DRAW:  100\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([6])\n",
            " - - -\n",
            " - - -\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " o - -\n",
            " x - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([4])\n",
            " - - -\n",
            " o x -\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " o x -\n",
            " x o -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([2])\n",
            " - - x\n",
            " o x -\n",
            " x o -\n",
            "\n",
            "Game Number  1499\n",
            "agent won  1206\n",
            " - - x\n",
            " o x -\n",
            " x o -\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1500  |AGENT :  1206  |RANDOM:  193  |DRAW:  100\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "select action, random 0.9\n",
            " - - -\n",
            " - - -\n",
            " - x -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - o\n",
            " - - -\n",
            " - x -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([3])\n",
            " - - o\n",
            " x - -\n",
            " - x -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - o\n",
            " x - -\n",
            " - x o\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "select action, random 0.9\n",
            " - - o\n",
            " x - -\n",
            " x x o\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " o - o\n",
            " x - -\n",
            " x x o\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([1])\n",
            " o x o\n",
            " x - -\n",
            " x x o\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " o x o\n",
            " x - o\n",
            " x x o\n",
            "\n",
            "random won  194\n",
            " o x o\n",
            " x - o\n",
            " x x o\n",
            "\n",
            "#####################################################################################################\n",
            "GAME NUMBER:  1500  |AGENT :  1206  |RANDOM:  194  |DRAW:  100\n",
            "#####################################################################################################\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fI34qnhJc7UT"
      },
      "source": [
        "env = XO_Board()"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EvmygNxlcZi5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60cfddcf-8d12-433c-925c-5c25b3638527"
      },
      "source": [
        "agent_against_random(env,num_games=1500,agent_first=False)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            " o - x\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1416  |AGENT :  649  |RANDOM:  523  |DRAW:  243\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " - - -\n",
            " x - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([3])\n",
            " - - -\n",
            " o - -\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - x -\n",
            " o - -\n",
            " x - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([4])\n",
            " - x -\n",
            " o o -\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " x x -\n",
            " o o -\n",
            " x - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([2])\n",
            " x x o\n",
            " o o -\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " x x o\n",
            " o o -\n",
            " x - x\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([5])\n",
            " x x o\n",
            " o o o\n",
            " x - x\n",
            "\n",
            "Game Number  1416\n",
            "agent won  650\n",
            " x x o\n",
            " o o o\n",
            " x - x\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1417  |AGENT :  650  |RANDOM:  523  |DRAW:  243\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " x - -\n",
            " - - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([2])\n",
            " - - o\n",
            " x - -\n",
            " - - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - o\n",
            " x x -\n",
            " - - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([6])\n",
            " - - o\n",
            " x x -\n",
            " o - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - o\n",
            " x x x\n",
            " o - -\n",
            "\n",
            "Game Number  1417\n",
            "random won  524\n",
            " - - o\n",
            " x x x\n",
            " o - -\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1418  |AGENT :  650  |RANDOM:  524  |DRAW:  243\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - x -\n",
            " - - -\n",
            " - - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "select action, random 0.9\n",
            " - x -\n",
            " - - o\n",
            " - - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - x -\n",
            " - x o\n",
            " - - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([6])\n",
            " - x -\n",
            " - x o\n",
            " o - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - x x\n",
            " - x o\n",
            " o - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([3])\n",
            " - x x\n",
            " o x o\n",
            " o - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - x x\n",
            " o x o\n",
            " o x -\n",
            "\n",
            "Game Number  1418\n",
            "random won  525\n",
            " - x x\n",
            " o x o\n",
            " o x -\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1419  |AGENT :  650  |RANDOM:  525  |DRAW:  243\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - x -\n",
            " - - -\n",
            " - - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([6])\n",
            " - x -\n",
            " - - -\n",
            " o - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " x x -\n",
            " - - -\n",
            " o - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([2])\n",
            " x x o\n",
            " - - -\n",
            " o - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " x x o\n",
            " - x -\n",
            " o - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([3])\n",
            " x x o\n",
            " o x -\n",
            " o - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " x x o\n",
            " o x x\n",
            " o - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([7])\n",
            " x x o\n",
            " o x x\n",
            " o o -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " x x o\n",
            " o x x\n",
            " o o x\n",
            "\n",
            "Game Number  1419\n",
            "random won  526\n",
            " x x o\n",
            " o x x\n",
            " o o x\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1420  |AGENT :  650  |RANDOM:  526  |DRAW:  243\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " x - -\n",
            " - - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([2])\n",
            " - - o\n",
            " x - -\n",
            " - - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " x - o\n",
            " x - -\n",
            " - - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([6])\n",
            " x - o\n",
            " x - -\n",
            " o - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " x - o\n",
            " x x -\n",
            " o - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([8])\n",
            " x - o\n",
            " x x -\n",
            " o - o\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " x x o\n",
            " x x -\n",
            " o - o\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([7])\n",
            " x x o\n",
            " x x -\n",
            " o o o\n",
            "\n",
            "Game Number  1420\n",
            "agent won  651\n",
            " x x o\n",
            " x x -\n",
            " o o o\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1421  |AGENT :  651  |RANDOM:  526  |DRAW:  243\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " - - -\n",
            " - x -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([3])\n",
            " - - -\n",
            " o - -\n",
            " - x -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " o - x\n",
            " - x -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([8])\n",
            " - - -\n",
            " o - x\n",
            " - x o\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - x\n",
            " o - x\n",
            " - x o\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([6])\n",
            " - - x\n",
            " o - x\n",
            " o x o\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - x x\n",
            " o - x\n",
            " o x o\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([4])\n",
            " - x x\n",
            " o o x\n",
            " o x o\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " x x x\n",
            " o o x\n",
            " o x o\n",
            "\n",
            "Game Number  1421\n",
            "random won  527\n",
            " x x x\n",
            " o o x\n",
            " o x o\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1422  |AGENT :  651  |RANDOM:  527  |DRAW:  243\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " - - x\n",
            " - - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([4])\n",
            " - - -\n",
            " - o x\n",
            " - - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - x -\n",
            " - o x\n",
            " - - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([2])\n",
            " - x o\n",
            " - o x\n",
            " - - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - x o\n",
            " - o x\n",
            " x - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([3])\n",
            " - x o\n",
            " o o x\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - x o\n",
            " o o x\n",
            " x x -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([8])\n",
            " - x o\n",
            " o o x\n",
            " x x o\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " x x o\n",
            " o o x\n",
            " x x o\n",
            "\n",
            "draw  244\n",
            " x x o\n",
            " o o x\n",
            " x x o\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1423  |AGENT :  651  |RANDOM:  527  |DRAW:  244\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " - x -\n",
            " - - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([8])\n",
            " - - -\n",
            " - x -\n",
            " - - o\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " x x -\n",
            " - - o\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([6])\n",
            " - - -\n",
            " x x -\n",
            " o - o\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - x\n",
            " x x -\n",
            " o - o\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([7])\n",
            " - - x\n",
            " x x -\n",
            " o o o\n",
            "\n",
            "Game Number  1423\n",
            "agent won  652\n",
            " - - x\n",
            " x x -\n",
            " o o o\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1424  |AGENT :  652  |RANDOM:  527  |DRAW:  244\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " - - x\n",
            " - - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([4])\n",
            " - - -\n",
            " - o x\n",
            " - - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - x\n",
            " - o x\n",
            " - - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([6])\n",
            " - - x\n",
            " - o x\n",
            " o - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - x\n",
            " - o x\n",
            " o x -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([3])\n",
            " - - x\n",
            " o o x\n",
            " o x -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " x - x\n",
            " o o x\n",
            " o x -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([8])\n",
            " x - x\n",
            " o o x\n",
            " o x o\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " x x x\n",
            " o o x\n",
            " o x o\n",
            "\n",
            "Game Number  1424\n",
            "random won  528\n",
            " x x x\n",
            " o o x\n",
            " o x o\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1425  |AGENT :  652  |RANDOM:  528  |DRAW:  244\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " x - -\n",
            " - - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([2])\n",
            " - - o\n",
            " x - -\n",
            " - - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - x o\n",
            " x - -\n",
            " - - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([4])\n",
            " - x o\n",
            " x o -\n",
            " - - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - x o\n",
            " x o -\n",
            " x - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([5])\n",
            " - x o\n",
            " x o o\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " x x o\n",
            " x o o\n",
            " x - -\n",
            "\n",
            "Game Number  1425\n",
            "random won  529\n",
            " x x o\n",
            " x o o\n",
            " x - -\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1426  |AGENT :  652  |RANDOM:  529  |DRAW:  244\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " - - x\n",
            " - - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([4])\n",
            " - - -\n",
            " - o x\n",
            " - - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " x - -\n",
            " - o x\n",
            " - - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([2])\n",
            " x - o\n",
            " - o x\n",
            " - - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " x x o\n",
            " - o x\n",
            " - - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([6])\n",
            " x x o\n",
            " - o x\n",
            " o - -\n",
            "\n",
            "Game Number  1426\n",
            "agent won  653\n",
            " x x o\n",
            " - o x\n",
            " o - -\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1427  |AGENT :  653  |RANDOM:  529  |DRAW:  244\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " - - -\n",
            " - - x\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([3])\n",
            " - - -\n",
            " o - -\n",
            " - - x\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " o - -\n",
            " - x x\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([6])\n",
            " - - -\n",
            " o - -\n",
            " o x x\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " o x -\n",
            " o x x\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([1])\n",
            " - o -\n",
            " o x -\n",
            " o x x\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - o -\n",
            " o x x\n",
            " o x x\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([2])\n",
            " - o o\n",
            " o x x\n",
            " o x x\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " x o o\n",
            " o x x\n",
            " o x x\n",
            "\n",
            "Game Number  1427\n",
            "random won  530\n",
            " x o o\n",
            " o x x\n",
            " o x x\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1428  |AGENT :  653  |RANDOM:  530  |DRAW:  244\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " - - -\n",
            " - x -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "select action, random 0.9\n",
            " - - o\n",
            " - - -\n",
            " - x -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - o\n",
            " - - -\n",
            " - x x\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([6])\n",
            " - - o\n",
            " - - -\n",
            " o x x\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - o\n",
            " - x -\n",
            " o x x\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([3])\n",
            " - - o\n",
            " o x -\n",
            " o x x\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - o\n",
            " o x x\n",
            " o x x\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([1])\n",
            " - o o\n",
            " o x x\n",
            " o x x\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " x o o\n",
            " o x x\n",
            " o x x\n",
            "\n",
            "Game Number  1428\n",
            "random won  531\n",
            " x o o\n",
            " o x x\n",
            " o x x\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1429  |AGENT :  653  |RANDOM:  531  |DRAW:  244\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " x - -\n",
            " - - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([2])\n",
            " - - o\n",
            " x - -\n",
            " - - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - o\n",
            " x x -\n",
            " - - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([6])\n",
            " - - o\n",
            " x x -\n",
            " o - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - o\n",
            " x x -\n",
            " o x -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([1])\n",
            " - o o\n",
            " x x -\n",
            " o x -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - o o\n",
            " x x x\n",
            " o x -\n",
            "\n",
            "Game Number  1429\n",
            "random won  532\n",
            " - o o\n",
            " x x x\n",
            " o x -\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1430  |AGENT :  653  |RANDOM:  532  |DRAW:  244\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " x - -\n",
            " - - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([2])\n",
            " - - o\n",
            " x - -\n",
            " - - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - o\n",
            " x - -\n",
            " x - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([1])\n",
            " - o o\n",
            " x - -\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - o o\n",
            " x x -\n",
            " x - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([0])\n",
            " o o o\n",
            " x x -\n",
            " x - -\n",
            "\n",
            "Game Number  1430\n",
            "agent won  654\n",
            " o o o\n",
            " x x -\n",
            " x - -\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1431  |AGENT :  654  |RANDOM:  532  |DRAW:  244\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " x - -\n",
            " - - -\n",
            " - - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([6])\n",
            " x - -\n",
            " - - -\n",
            " o - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " x - -\n",
            " x - -\n",
            " o - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([1])\n",
            " x o -\n",
            " x - -\n",
            " o - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " x o -\n",
            " x x -\n",
            " o - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([8])\n",
            " x o -\n",
            " x x -\n",
            " o - o\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " x o -\n",
            " x x -\n",
            " o x o\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([5])\n",
            " x o -\n",
            " x x o\n",
            " o x o\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " x o x\n",
            " x x o\n",
            " o x o\n",
            "\n",
            "draw  245\n",
            " x o x\n",
            " x x o\n",
            " o x o\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1432  |AGENT :  654  |RANDOM:  532  |DRAW:  245\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - x -\n",
            " - - -\n",
            " - - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([6])\n",
            " - x -\n",
            " - - -\n",
            " o - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " x x -\n",
            " - - -\n",
            " o - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "select action, random 0.9\n",
            " x x -\n",
            " - o -\n",
            " o - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " x x -\n",
            " - o -\n",
            " o x -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([5])\n",
            " x x -\n",
            " - o o\n",
            " o x -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " x x x\n",
            " - o o\n",
            " o x -\n",
            "\n",
            "Game Number  1432\n",
            "random won  533\n",
            " x x x\n",
            " - o o\n",
            " o x -\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1433  |AGENT :  654  |RANDOM:  533  |DRAW:  245\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " - - -\n",
            " - x -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([3])\n",
            " - - -\n",
            " o - -\n",
            " - x -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " o - -\n",
            " x x -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "select action, random 0.9\n",
            " o - -\n",
            " o - -\n",
            " x x -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " o - -\n",
            " o x -\n",
            " x x -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([8])\n",
            " o - -\n",
            " o x -\n",
            " x x o\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " o x -\n",
            " o x -\n",
            " x x o\n",
            "\n",
            "Game Number  1433\n",
            "random won  534\n",
            " o x -\n",
            " o x -\n",
            " x x o\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1434  |AGENT :  654  |RANDOM:  534  |DRAW:  245\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " - - -\n",
            " - x -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "select action, random 0.9\n",
            " - - -\n",
            " - - -\n",
            " - x o\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " x - -\n",
            " - - -\n",
            " - x o\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([4])\n",
            " x - -\n",
            " - o -\n",
            " - x o\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " x - -\n",
            " - o -\n",
            " x x o\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([3])\n",
            " x - -\n",
            " o o -\n",
            " x x o\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " x - -\n",
            " o o x\n",
            " x x o\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([2])\n",
            " x - o\n",
            " o o x\n",
            " x x o\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " x x o\n",
            " o o x\n",
            " x x o\n",
            "\n",
            "draw  246\n",
            " x x o\n",
            " o o x\n",
            " x x o\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1435  |AGENT :  654  |RANDOM:  534  |DRAW:  246\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - x\n",
            " - - -\n",
            " - - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([4])\n",
            " - - x\n",
            " - o -\n",
            " - - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - x\n",
            " - o -\n",
            " - - x\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([5])\n",
            " - - x\n",
            " - o o\n",
            " - - x\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - x\n",
            " - o o\n",
            " x - x\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "select action, random 0.9\n",
            " - - x\n",
            " o o o\n",
            " x - x\n",
            "\n",
            "Game Number  1435\n",
            "agent won  655\n",
            " - - x\n",
            " o o o\n",
            " x - x\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1436  |AGENT :  655  |RANDOM:  534  |DRAW:  246\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " - - -\n",
            " - x -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([3])\n",
            " - - -\n",
            " o - -\n",
            " - x -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - x\n",
            " o - -\n",
            " - x -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([8])\n",
            " - - x\n",
            " o - -\n",
            " - x o\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " x - x\n",
            " o - -\n",
            " - x o\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([6])\n",
            " x - x\n",
            " o - -\n",
            " o x o\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " x x x\n",
            " o - -\n",
            " o x o\n",
            "\n",
            "Game Number  1436\n",
            "random won  535\n",
            " x x x\n",
            " o - -\n",
            " o x o\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1437  |AGENT :  655  |RANDOM:  535  |DRAW:  246\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " x - -\n",
            " - - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([2])\n",
            " - - o\n",
            " x - -\n",
            " - - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " x - o\n",
            " x - -\n",
            " - - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([6])\n",
            " x - o\n",
            " x - -\n",
            " o - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " x - o\n",
            " x - -\n",
            " o x -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "select action, random 0.9\n",
            " x - o\n",
            " x o -\n",
            " o x -\n",
            "\n",
            "Game Number  1437\n",
            "agent won  656\n",
            " x - o\n",
            " x o -\n",
            " o x -\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1438  |AGENT :  656  |RANDOM:  535  |DRAW:  246\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " - - -\n",
            " x - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([3])\n",
            " - - -\n",
            " o - -\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " o - -\n",
            " x - x\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([4])\n",
            " - - -\n",
            " o o -\n",
            " x - x\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - x -\n",
            " o o -\n",
            " x - x\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([5])\n",
            " - x -\n",
            " o o o\n",
            " x - x\n",
            "\n",
            "Game Number  1438\n",
            "agent won  657\n",
            " - x -\n",
            " o o o\n",
            " x - x\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1439  |AGENT :  657  |RANDOM:  535  |DRAW:  246\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - x -\n",
            " - - -\n",
            " - - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([6])\n",
            " - x -\n",
            " - - -\n",
            " o - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - x x\n",
            " - - -\n",
            " o - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([8])\n",
            " - x x\n",
            " - - -\n",
            " o - o\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - x x\n",
            " - - -\n",
            " o x o\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([3])\n",
            " - x x\n",
            " o - -\n",
            " o x o\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - x x\n",
            " o - x\n",
            " o x o\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "select action, random 0.9\n",
            " - x x\n",
            " o o x\n",
            " o x o\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " x x x\n",
            " o o x\n",
            " o x o\n",
            "\n",
            "Game Number  1439\n",
            "random won  536\n",
            " x x x\n",
            " o o x\n",
            " o x o\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1440  |AGENT :  657  |RANDOM:  536  |DRAW:  246\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " - - -\n",
            " - - x\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([3])\n",
            " - - -\n",
            " o - -\n",
            " - - x\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - x -\n",
            " o - -\n",
            " - - x\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([6])\n",
            " - x -\n",
            " o - -\n",
            " o - x\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " x x -\n",
            " o - -\n",
            " o - x\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([4])\n",
            " x x -\n",
            " o o -\n",
            " o - x\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " x x -\n",
            " o o -\n",
            " o x x\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([5])\n",
            " x x -\n",
            " o o o\n",
            " o x x\n",
            "\n",
            "Game Number  1440\n",
            "agent won  658\n",
            " x x -\n",
            " o o o\n",
            " o x x\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1441  |AGENT :  658  |RANDOM:  536  |DRAW:  246\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - x -\n",
            " - - -\n",
            " - - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([6])\n",
            " - x -\n",
            " - - -\n",
            " o - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - x -\n",
            " - - x\n",
            " o - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([2])\n",
            " - x o\n",
            " - - x\n",
            " o - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - x o\n",
            " x - x\n",
            " o - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([4])\n",
            " - x o\n",
            " x o x\n",
            " o - -\n",
            "\n",
            "Game Number  1441\n",
            "agent won  659\n",
            " - x o\n",
            " x o x\n",
            " o - -\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1442  |AGENT :  659  |RANDOM:  536  |DRAW:  246\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " - - -\n",
            " x - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([3])\n",
            " - - -\n",
            " o - -\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " o - -\n",
            " x x -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([4])\n",
            " - - -\n",
            " o o -\n",
            " x x -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " o o -\n",
            " x x x\n",
            "\n",
            "Game Number  1442\n",
            "random won  537\n",
            " - - -\n",
            " o o -\n",
            " x x x\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1443  |AGENT :  659  |RANDOM:  537  |DRAW:  246\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " - - -\n",
            " - x -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([3])\n",
            " - - -\n",
            " o - -\n",
            " - x -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - x\n",
            " o - -\n",
            " - x -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "select action, random 0.9\n",
            " - - x\n",
            " o - -\n",
            " - x o\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - x\n",
            " o - x\n",
            " - x o\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([6])\n",
            " - - x\n",
            " o - x\n",
            " o x o\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - x x\n",
            " o - x\n",
            " o x o\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([4])\n",
            " - x x\n",
            " o o x\n",
            " o x o\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " x x x\n",
            " o o x\n",
            " o x o\n",
            "\n",
            "Game Number  1443\n",
            "random won  538\n",
            " x x x\n",
            " o o x\n",
            " o x o\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1444  |AGENT :  659  |RANDOM:  538  |DRAW:  246\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " - - x\n",
            " - - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([4])\n",
            " - - -\n",
            " - o x\n",
            " - - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " - o x\n",
            " - x -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([8])\n",
            " - - -\n",
            " - o x\n",
            " - x o\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " x o x\n",
            " - x o\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([6])\n",
            " - - -\n",
            " x o x\n",
            " o x o\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " x - -\n",
            " x o x\n",
            " o x o\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([1])\n",
            " x o -\n",
            " x o x\n",
            " o x o\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " x o x\n",
            " x o x\n",
            " o x o\n",
            "\n",
            "draw  247\n",
            " x o x\n",
            " x o x\n",
            " o x o\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1445  |AGENT :  659  |RANDOM:  538  |DRAW:  247\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " - x -\n",
            " - - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([8])\n",
            " - - -\n",
            " - x -\n",
            " - - o\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " x - -\n",
            " - x -\n",
            " - - o\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([6])\n",
            " x - -\n",
            " - x -\n",
            " o - o\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " x - -\n",
            " - x -\n",
            " o x o\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([1])\n",
            " x o -\n",
            " - x -\n",
            " o x o\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " x o x\n",
            " - x -\n",
            " o x o\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "select action, random 0.9\n",
            " x o x\n",
            " - x o\n",
            " o x o\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " x o x\n",
            " x x o\n",
            " o x o\n",
            "\n",
            "draw  248\n",
            " x o x\n",
            " x x o\n",
            " o x o\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1446  |AGENT :  659  |RANDOM:  538  |DRAW:  248\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " x - -\n",
            " - - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([2])\n",
            " - - o\n",
            " x - -\n",
            " - - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - o\n",
            " x - -\n",
            " x - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([1])\n",
            " - o o\n",
            " x - -\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " x o o\n",
            " x - -\n",
            " x - -\n",
            "\n",
            "Game Number  1446\n",
            "random won  539\n",
            " x o o\n",
            " x - -\n",
            " x - -\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1447  |AGENT :  659  |RANDOM:  539  |DRAW:  248\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " - - -\n",
            " - - x\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([3])\n",
            " - - -\n",
            " o - -\n",
            " - - x\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " o - x\n",
            " - - x\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([6])\n",
            " - - -\n",
            " o - x\n",
            " o - x\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - x -\n",
            " o - x\n",
            " o - x\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([2])\n",
            " - x o\n",
            " o - x\n",
            " o - x\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - x o\n",
            " o - x\n",
            " o x x\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([0])\n",
            " o x o\n",
            " o - x\n",
            " o x x\n",
            "\n",
            "Game Number  1447\n",
            "agent won  660\n",
            " o x o\n",
            " o - x\n",
            " o x x\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1448  |AGENT :  660  |RANDOM:  539  |DRAW:  248\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " - - -\n",
            " - - x\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "select action, random 0.9\n",
            " - - -\n",
            " - - -\n",
            " - o x\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - x -\n",
            " - - -\n",
            " - o x\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([0])\n",
            " o x -\n",
            " - - -\n",
            " - o x\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " o x -\n",
            " - - -\n",
            " x o x\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "select action, random 0.9\n",
            " o x o\n",
            " - - -\n",
            " x o x\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " o x o\n",
            " - - x\n",
            " x o x\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([4])\n",
            " o x o\n",
            " - o x\n",
            " x o x\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " o x o\n",
            " x o x\n",
            " x o x\n",
            "\n",
            "draw  249\n",
            " o x o\n",
            " x o x\n",
            " x o x\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1449  |AGENT :  660  |RANDOM:  539  |DRAW:  249\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " - - -\n",
            " x - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([3])\n",
            " - - -\n",
            " o - -\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - x\n",
            " o - -\n",
            " x - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([4])\n",
            " - - x\n",
            " o o -\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - x\n",
            " o o -\n",
            " x - x\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([5])\n",
            " - - x\n",
            " o o o\n",
            " x - x\n",
            "\n",
            "Game Number  1449\n",
            "agent won  661\n",
            " - - x\n",
            " o o o\n",
            " x - x\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1450  |AGENT :  661  |RANDOM:  539  |DRAW:  249\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " - - -\n",
            " - - x\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([3])\n",
            " - - -\n",
            " o - -\n",
            " - - x\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " o x -\n",
            " - - x\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([6])\n",
            " - - -\n",
            " o x -\n",
            " o - x\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " o x -\n",
            " o x x\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([1])\n",
            " - o -\n",
            " o x -\n",
            " o x x\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - o -\n",
            " o x x\n",
            " o x x\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([2])\n",
            " - o o\n",
            " o x x\n",
            " o x x\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " x o o\n",
            " o x x\n",
            " o x x\n",
            "\n",
            "Game Number  1450\n",
            "random won  540\n",
            " x o o\n",
            " o x x\n",
            " o x x\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1451  |AGENT :  661  |RANDOM:  540  |DRAW:  249\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " - x -\n",
            " - - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([8])\n",
            " - - -\n",
            " - x -\n",
            " - - o\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " - x -\n",
            " - x o\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([6])\n",
            " - - -\n",
            " - x -\n",
            " o x o\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " - x x\n",
            " o x o\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([3])\n",
            " - - -\n",
            " o x x\n",
            " o x o\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " x - -\n",
            " o x x\n",
            " o x o\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "select action, random 0.9\n",
            " x o -\n",
            " o x x\n",
            " o x o\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " x o x\n",
            " o x x\n",
            " o x o\n",
            "\n",
            "draw  250\n",
            " x o x\n",
            " o x x\n",
            " o x o\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1452  |AGENT :  661  |RANDOM:  540  |DRAW:  250\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " x - -\n",
            " - - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([2])\n",
            " - - o\n",
            " x - -\n",
            " - - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - o\n",
            " x - x\n",
            " - - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([6])\n",
            " - - o\n",
            " x - x\n",
            " o - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - o\n",
            " x x x\n",
            " o - -\n",
            "\n",
            "Game Number  1452\n",
            "random won  541\n",
            " - - o\n",
            " x x x\n",
            " o - -\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1453  |AGENT :  661  |RANDOM:  541  |DRAW:  250\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - x\n",
            " - - -\n",
            " - - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([4])\n",
            " - - x\n",
            " - o -\n",
            " - - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - x\n",
            " - o -\n",
            " - - x\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([5])\n",
            " - - x\n",
            " - o o\n",
            " - - x\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - x\n",
            " - o o\n",
            " x - x\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([3])\n",
            " - - x\n",
            " o o o\n",
            " x - x\n",
            "\n",
            "Game Number  1453\n",
            "agent won  662\n",
            " - - x\n",
            " o o o\n",
            " x - x\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1454  |AGENT :  662  |RANDOM:  541  |DRAW:  250\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - x -\n",
            " - - -\n",
            " - - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([6])\n",
            " - x -\n",
            " - - -\n",
            " o - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - x -\n",
            " - - -\n",
            " o x -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "select action, random 0.9\n",
            " - x -\n",
            " - - -\n",
            " o x o\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - x x\n",
            " - - -\n",
            " o x o\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([3])\n",
            " - x x\n",
            " o - -\n",
            " o x o\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - x x\n",
            " o x -\n",
            " o x o\n",
            "\n",
            "Game Number  1454\n",
            "random won  542\n",
            " - x x\n",
            " o x -\n",
            " o x o\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1455  |AGENT :  662  |RANDOM:  542  |DRAW:  250\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " - - -\n",
            " - - x\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([3])\n",
            " - - -\n",
            " o - -\n",
            " - - x\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " o - x\n",
            " - - x\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([6])\n",
            " - - -\n",
            " o - x\n",
            " o - x\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - x -\n",
            " o - x\n",
            " o - x\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([2])\n",
            " - x o\n",
            " o - x\n",
            " o - x\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " x x o\n",
            " o - x\n",
            " o - x\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([4])\n",
            " x x o\n",
            " o o x\n",
            " o - x\n",
            "\n",
            "Game Number  1455\n",
            "agent won  663\n",
            " x x o\n",
            " o o x\n",
            " o - x\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1456  |AGENT :  663  |RANDOM:  542  |DRAW:  250\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " x - -\n",
            " - - -\n",
            " - - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([6])\n",
            " x - -\n",
            " - - -\n",
            " o - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " x - x\n",
            " - - -\n",
            " o - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([1])\n",
            " x o x\n",
            " - - -\n",
            " o - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " x o x\n",
            " - - x\n",
            " o - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([7])\n",
            " x o x\n",
            " - - x\n",
            " o o -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " x o x\n",
            " x - x\n",
            " o o -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([4])\n",
            " x o x\n",
            " x o x\n",
            " o o -\n",
            "\n",
            "Game Number  1456\n",
            "agent won  664\n",
            " x o x\n",
            " x o x\n",
            " o o -\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1457  |AGENT :  664  |RANDOM:  542  |DRAW:  250\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " x - -\n",
            " - - -\n",
            " - - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([6])\n",
            " x - -\n",
            " - - -\n",
            " o - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " x - -\n",
            " - x -\n",
            " o - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([1])\n",
            " x o -\n",
            " - x -\n",
            " o - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " x o -\n",
            " - x x\n",
            " o - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([8])\n",
            " x o -\n",
            " - x x\n",
            " o - o\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " x o x\n",
            " - x x\n",
            " o - o\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([7])\n",
            " x o x\n",
            " - x x\n",
            " o o o\n",
            "\n",
            "Game Number  1457\n",
            "agent won  665\n",
            " x o x\n",
            " - x x\n",
            " o o o\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1458  |AGENT :  665  |RANDOM:  542  |DRAW:  250\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " - - x\n",
            " - - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([4])\n",
            " - - -\n",
            " - o x\n",
            " - - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - x\n",
            " - o x\n",
            " - - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([6])\n",
            " - - x\n",
            " - o x\n",
            " o - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - x\n",
            " - o x\n",
            " o x -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([3])\n",
            " - - x\n",
            " o o x\n",
            " o x -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - x x\n",
            " o o x\n",
            " o x -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([8])\n",
            " - x x\n",
            " o o x\n",
            " o x o\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " x x x\n",
            " o o x\n",
            " o x o\n",
            "\n",
            "Game Number  1458\n",
            "random won  543\n",
            " x x x\n",
            " o o x\n",
            " o x o\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1459  |AGENT :  665  |RANDOM:  543  |DRAW:  250\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " - - -\n",
            " x - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([3])\n",
            " - - -\n",
            " o - -\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - x -\n",
            " o - -\n",
            " x - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([4])\n",
            " - x -\n",
            " o o -\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - x x\n",
            " o o -\n",
            " x - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([5])\n",
            " - x x\n",
            " o o o\n",
            " x - -\n",
            "\n",
            "Game Number  1459\n",
            "agent won  666\n",
            " - x x\n",
            " o o o\n",
            " x - -\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1460  |AGENT :  666  |RANDOM:  543  |DRAW:  250\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " x - -\n",
            " - - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([2])\n",
            " - - o\n",
            " x - -\n",
            " - - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - o\n",
            " x - -\n",
            " - x -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "select action, random 0.9\n",
            " - - o\n",
            " x - -\n",
            " - x o\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - o\n",
            " x - -\n",
            " x x o\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([4])\n",
            " - - o\n",
            " x o -\n",
            " x x o\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - o\n",
            " x o x\n",
            " x x o\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([1])\n",
            " - o o\n",
            " x o x\n",
            " x x o\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " x o o\n",
            " x o x\n",
            " x x o\n",
            "\n",
            "Game Number  1460\n",
            "random won  544\n",
            " x o o\n",
            " x o x\n",
            " x x o\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1461  |AGENT :  666  |RANDOM:  544  |DRAW:  250\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " x - -\n",
            " - - -\n",
            " - - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([6])\n",
            " x - -\n",
            " - - -\n",
            " o - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " x - -\n",
            " x - -\n",
            " o - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([1])\n",
            " x o -\n",
            " x - -\n",
            " o - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " x o -\n",
            " x - x\n",
            " o - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([2])\n",
            " x o o\n",
            " x - x\n",
            " o - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " x o o\n",
            " x - x\n",
            " o - x\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([4])\n",
            " x o o\n",
            " x o x\n",
            " o - x\n",
            "\n",
            "Game Number  1461\n",
            "agent won  667\n",
            " x o o\n",
            " x o x\n",
            " o - x\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1462  |AGENT :  667  |RANDOM:  544  |DRAW:  250\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " - - x\n",
            " - - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([4])\n",
            " - - -\n",
            " - o x\n",
            " - - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " - o x\n",
            " x - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([3])\n",
            " - - -\n",
            " o o x\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - x -\n",
            " o o x\n",
            " x - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([2])\n",
            " - x o\n",
            " o o x\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - x o\n",
            " o o x\n",
            " x - x\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([7])\n",
            " - x o\n",
            " o o x\n",
            " x o x\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " x x o\n",
            " o o x\n",
            " x o x\n",
            "\n",
            "draw  251\n",
            " x x o\n",
            " o o x\n",
            " x o x\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1463  |AGENT :  667  |RANDOM:  544  |DRAW:  251\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " - - -\n",
            " - x -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([3])\n",
            " - - -\n",
            " o - -\n",
            " - x -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " o - -\n",
            " - x x\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([6])\n",
            " - - -\n",
            " o - -\n",
            " o x x\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " o - x\n",
            " o x x\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([2])\n",
            " - - o\n",
            " o - x\n",
            " o x x\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - x o\n",
            " o - x\n",
            " o x x\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([0])\n",
            " o x o\n",
            " o - x\n",
            " o x x\n",
            "\n",
            "Game Number  1463\n",
            "agent won  668\n",
            " o x o\n",
            " o - x\n",
            " o x x\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1464  |AGENT :  668  |RANDOM:  544  |DRAW:  251\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " - x -\n",
            " - - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([8])\n",
            " - - -\n",
            " - x -\n",
            " - - o\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " - x -\n",
            " x - o\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([5])\n",
            " - - -\n",
            " - x o\n",
            " x - o\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - x\n",
            " - x o\n",
            " x - o\n",
            "\n",
            "Game Number  1464\n",
            "random won  545\n",
            " - - x\n",
            " - x o\n",
            " x - o\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1465  |AGENT :  668  |RANDOM:  545  |DRAW:  251\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " - x -\n",
            " - - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([8])\n",
            " - - -\n",
            " - x -\n",
            " - - o\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " - x x\n",
            " - - o\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([6])\n",
            " - - -\n",
            " - x x\n",
            " o - o\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " - x x\n",
            " o x o\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([3])\n",
            " - - -\n",
            " o x x\n",
            " o x o\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - x\n",
            " o x x\n",
            " o x o\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "select action, random 0.9\n",
            " o - x\n",
            " o x x\n",
            " o x o\n",
            "\n",
            "Game Number  1465\n",
            "agent won  669\n",
            " o - x\n",
            " o x x\n",
            " o x o\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1466  |AGENT :  669  |RANDOM:  545  |DRAW:  251\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " - - -\n",
            " x - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "select action, random 0.9\n",
            " - - -\n",
            " - - -\n",
            " x o -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " x - -\n",
            " x o -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([0])\n",
            " o - -\n",
            " x - -\n",
            " x o -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " o - -\n",
            " x - x\n",
            " x o -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([2])\n",
            " o - o\n",
            " x - x\n",
            " x o -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " o x o\n",
            " x - x\n",
            " x o -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([4])\n",
            " o x o\n",
            " x o x\n",
            " x o -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " o x o\n",
            " x o x\n",
            " x o x\n",
            "\n",
            "draw  252\n",
            " o x o\n",
            " x o x\n",
            " x o x\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1467  |AGENT :  669  |RANDOM:  545  |DRAW:  252\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " - - -\n",
            " - x -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([3])\n",
            " - - -\n",
            " o - -\n",
            " - x -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " o x -\n",
            " - x -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([8])\n",
            " - - -\n",
            " o x -\n",
            " - x o\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " o x -\n",
            " x x o\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "select action, random 0.9\n",
            " - - -\n",
            " o x o\n",
            " x x o\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - x\n",
            " o x o\n",
            " x x o\n",
            "\n",
            "Game Number  1467\n",
            "random won  546\n",
            " - - x\n",
            " o x o\n",
            " x x o\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1468  |AGENT :  669  |RANDOM:  546  |DRAW:  252\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " - - -\n",
            " - x -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([3])\n",
            " - - -\n",
            " o - -\n",
            " - x -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " o x -\n",
            " - x -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([8])\n",
            " - - -\n",
            " o x -\n",
            " - x o\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - x\n",
            " o x -\n",
            " - x o\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([6])\n",
            " - - x\n",
            " o x -\n",
            " o x o\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - x x\n",
            " o x -\n",
            " o x o\n",
            "\n",
            "Game Number  1468\n",
            "random won  547\n",
            " - x x\n",
            " o x -\n",
            " o x o\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1469  |AGENT :  669  |RANDOM:  547  |DRAW:  252\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " - - -\n",
            " - - x\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "select action, random 0.9\n",
            " o - -\n",
            " - - -\n",
            " - - x\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " o - -\n",
            " - x -\n",
            " - - x\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([6])\n",
            " o - -\n",
            " - x -\n",
            " o - x\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " o - -\n",
            " - x x\n",
            " o - x\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "select action, random 0.9\n",
            " o o -\n",
            " - x x\n",
            " o - x\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " o o -\n",
            " - x x\n",
            " o x x\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "select action, random 0.9\n",
            " o o -\n",
            " o x x\n",
            " o x x\n",
            "\n",
            "Game Number  1469\n",
            "agent won  670\n",
            " o o -\n",
            " o x x\n",
            " o x x\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1470  |AGENT :  670  |RANDOM:  547  |DRAW:  252\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " - - -\n",
            " - x -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "select action, random 0.9\n",
            " - - -\n",
            " - - -\n",
            " o x -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " - - x\n",
            " o x -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([3])\n",
            " - - -\n",
            " o - x\n",
            " o x -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " o - x\n",
            " o x x\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([2])\n",
            " - - o\n",
            " o - x\n",
            " o x x\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " x - o\n",
            " o - x\n",
            " o x x\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([4])\n",
            " x - o\n",
            " o o x\n",
            " o x x\n",
            "\n",
            "Game Number  1470\n",
            "agent won  671\n",
            " x - o\n",
            " o o x\n",
            " o x x\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1471  |AGENT :  671  |RANDOM:  547  |DRAW:  252\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - x -\n",
            " - - -\n",
            " - - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([6])\n",
            " - x -\n",
            " - - -\n",
            " o - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " x x -\n",
            " - - -\n",
            " o - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([2])\n",
            " x x o\n",
            " - - -\n",
            " o - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " x x o\n",
            " - - -\n",
            " o x -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([5])\n",
            " x x o\n",
            " - - o\n",
            " o x -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " x x o\n",
            " - x o\n",
            " o x -\n",
            "\n",
            "Game Number  1471\n",
            "random won  548\n",
            " x x o\n",
            " - x o\n",
            " o x -\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1472  |AGENT :  671  |RANDOM:  548  |DRAW:  252\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " - - -\n",
            " - - x\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([3])\n",
            " - - -\n",
            " o - -\n",
            " - - x\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - x\n",
            " o - -\n",
            " - - x\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([6])\n",
            " - - x\n",
            " o - -\n",
            " o - x\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - x x\n",
            " o - -\n",
            " o - x\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([5])\n",
            " - x x\n",
            " o - o\n",
            " o - x\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " x x x\n",
            " o - o\n",
            " o - x\n",
            "\n",
            "Game Number  1472\n",
            "random won  549\n",
            " x x x\n",
            " o - o\n",
            " o - x\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1473  |AGENT :  671  |RANDOM:  549  |DRAW:  252\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " x - -\n",
            " - - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([2])\n",
            " - - o\n",
            " x - -\n",
            " - - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - o\n",
            " x - -\n",
            " x - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([1])\n",
            " - o o\n",
            " x - -\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - o o\n",
            " x x -\n",
            " x - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([0])\n",
            " o o o\n",
            " x x -\n",
            " x - -\n",
            "\n",
            "Game Number  1473\n",
            "agent won  672\n",
            " o o o\n",
            " x x -\n",
            " x - -\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1474  |AGENT :  672  |RANDOM:  549  |DRAW:  252\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " x - -\n",
            " - - -\n",
            " - - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([6])\n",
            " x - -\n",
            " - - -\n",
            " o - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " x - -\n",
            " - x -\n",
            " o - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([1])\n",
            " x o -\n",
            " - x -\n",
            " o - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " x o x\n",
            " - x -\n",
            " o - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([3])\n",
            " x o x\n",
            " o x -\n",
            " o - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " x o x\n",
            " o x x\n",
            " o - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([7])\n",
            " x o x\n",
            " o x x\n",
            " o o -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " x o x\n",
            " o x x\n",
            " o o x\n",
            "\n",
            "Game Number  1474\n",
            "random won  550\n",
            " x o x\n",
            " o x x\n",
            " o o x\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1475  |AGENT :  672  |RANDOM:  550  |DRAW:  252\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - x\n",
            " - - -\n",
            " - - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([4])\n",
            " - - x\n",
            " - o -\n",
            " - - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - x\n",
            " - o -\n",
            " - - x\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([5])\n",
            " - - x\n",
            " - o o\n",
            " - - x\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - x\n",
            " - o o\n",
            " x - x\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "select action, random 0.9\n",
            " - o x\n",
            " - o o\n",
            " x - x\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - o x\n",
            " - o o\n",
            " x x x\n",
            "\n",
            "Game Number  1475\n",
            "random won  551\n",
            " - o x\n",
            " - o o\n",
            " x x x\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1476  |AGENT :  672  |RANDOM:  551  |DRAW:  252\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - x -\n",
            " - - -\n",
            " - - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([6])\n",
            " - x -\n",
            " - - -\n",
            " o - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - x -\n",
            " - - x\n",
            " o - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([2])\n",
            " - x o\n",
            " - - x\n",
            " o - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - x o\n",
            " - x x\n",
            " o - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([3])\n",
            " - x o\n",
            " o x x\n",
            " o - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - x o\n",
            " o x x\n",
            " o - x\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([0])\n",
            " o x o\n",
            " o x x\n",
            " o - x\n",
            "\n",
            "Game Number  1476\n",
            "agent won  673\n",
            " o x o\n",
            " o x x\n",
            " o - x\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1477  |AGENT :  673  |RANDOM:  551  |DRAW:  252\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - x -\n",
            " - - -\n",
            " - - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([6])\n",
            " - x -\n",
            " - - -\n",
            " o - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " x x -\n",
            " - - -\n",
            " o - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([2])\n",
            " x x o\n",
            " - - -\n",
            " o - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " x x o\n",
            " - - -\n",
            " o - x\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([4])\n",
            " x x o\n",
            " - o -\n",
            " o - x\n",
            "\n",
            "Game Number  1477\n",
            "agent won  674\n",
            " x x o\n",
            " - o -\n",
            " o - x\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1478  |AGENT :  674  |RANDOM:  551  |DRAW:  252\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " x - -\n",
            " - - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([2])\n",
            " - - o\n",
            " x - -\n",
            " - - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - o\n",
            " x - -\n",
            " - x -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "select action, random 0.9\n",
            " o - o\n",
            " x - -\n",
            " - x -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " o - o\n",
            " x x -\n",
            " - x -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([1])\n",
            " o o o\n",
            " x x -\n",
            " - x -\n",
            "\n",
            "Game Number  1478\n",
            "agent won  675\n",
            " o o o\n",
            " x x -\n",
            " - x -\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1479  |AGENT :  675  |RANDOM:  551  |DRAW:  252\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " x - -\n",
            " - - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([2])\n",
            " - - o\n",
            " x - -\n",
            " - - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - o\n",
            " x - -\n",
            " - - x\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([0])\n",
            " o - o\n",
            " x - -\n",
            " - - x\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " o - o\n",
            " x x -\n",
            " - - x\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([1])\n",
            " o o o\n",
            " x x -\n",
            " - - x\n",
            "\n",
            "Game Number  1479\n",
            "agent won  676\n",
            " o o o\n",
            " x x -\n",
            " - - x\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1480  |AGENT :  676  |RANDOM:  551  |DRAW:  252\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - x\n",
            " - - -\n",
            " - - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([4])\n",
            " - - x\n",
            " - o -\n",
            " - - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - x\n",
            " - o -\n",
            " - x -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([8])\n",
            " - - x\n",
            " - o -\n",
            " - x o\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - x x\n",
            " - o -\n",
            " - x o\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([3])\n",
            " - x x\n",
            " o o -\n",
            " - x o\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - x x\n",
            " o o -\n",
            " x x o\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([5])\n",
            " - x x\n",
            " o o o\n",
            " x x o\n",
            "\n",
            "Game Number  1480\n",
            "agent won  677\n",
            " - x x\n",
            " o o o\n",
            " x x o\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1481  |AGENT :  677  |RANDOM:  551  |DRAW:  252\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " - - x\n",
            " - - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([4])\n",
            " - - -\n",
            " - o x\n",
            " - - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - x\n",
            " - o x\n",
            " - - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([6])\n",
            " - - x\n",
            " - o x\n",
            " o - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - x\n",
            " - o x\n",
            " o - x\n",
            "\n",
            "Game Number  1481\n",
            "random won  552\n",
            " - - x\n",
            " - o x\n",
            " o - x\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1482  |AGENT :  677  |RANDOM:  552  |DRAW:  252\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " - - x\n",
            " - - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([4])\n",
            " - - -\n",
            " - o x\n",
            " - - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " - o x\n",
            " - - x\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([6])\n",
            " - - -\n",
            " - o x\n",
            " o - x\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - x -\n",
            " - o x\n",
            " o - x\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([2])\n",
            " - x o\n",
            " - o x\n",
            " o - x\n",
            "\n",
            "Game Number  1482\n",
            "agent won  678\n",
            " - x o\n",
            " - o x\n",
            " o - x\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1483  |AGENT :  678  |RANDOM:  552  |DRAW:  252\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " - x -\n",
            " - - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([8])\n",
            " - - -\n",
            " - x -\n",
            " - - o\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " x - -\n",
            " - x -\n",
            " - - o\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([6])\n",
            " x - -\n",
            " - x -\n",
            " o - o\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " x - -\n",
            " - x x\n",
            " o - o\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([3])\n",
            " x - -\n",
            " o x x\n",
            " o - o\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " x - x\n",
            " o x x\n",
            " o - o\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([1])\n",
            " x o x\n",
            " o x x\n",
            " o - o\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " x o x\n",
            " o x x\n",
            " o x o\n",
            "\n",
            "draw  253\n",
            " x o x\n",
            " o x x\n",
            " o x o\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1484  |AGENT :  678  |RANDOM:  552  |DRAW:  253\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " - - x\n",
            " - - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([4])\n",
            " - - -\n",
            " - o x\n",
            " - - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " - o x\n",
            " - - x\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([6])\n",
            " - - -\n",
            " - o x\n",
            " o - x\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " x o x\n",
            " o - x\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([2])\n",
            " - - o\n",
            " x o x\n",
            " o - x\n",
            "\n",
            "Game Number  1484\n",
            "agent won  679\n",
            " - - o\n",
            " x o x\n",
            " o - x\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1485  |AGENT :  679  |RANDOM:  552  |DRAW:  253\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " - - -\n",
            " x - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([3])\n",
            " - - -\n",
            " o - -\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " o x -\n",
            " x - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([8])\n",
            " - - -\n",
            " o x -\n",
            " x - o\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " o x -\n",
            " x x o\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([2])\n",
            " - - o\n",
            " o x -\n",
            " x x o\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - x o\n",
            " o x -\n",
            " x x o\n",
            "\n",
            "Game Number  1485\n",
            "random won  553\n",
            " - x o\n",
            " o x -\n",
            " x x o\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1486  |AGENT :  679  |RANDOM:  553  |DRAW:  253\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - x\n",
            " - - -\n",
            " - - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([4])\n",
            " - - x\n",
            " - o -\n",
            " - - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - x x\n",
            " - o -\n",
            " - - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([5])\n",
            " - x x\n",
            " - o o\n",
            " - - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " x x x\n",
            " - o o\n",
            " - - -\n",
            "\n",
            "Game Number  1486\n",
            "random won  554\n",
            " x x x\n",
            " - o o\n",
            " - - -\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1487  |AGENT :  679  |RANDOM:  554  |DRAW:  253\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - x -\n",
            " - - -\n",
            " - - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([6])\n",
            " - x -\n",
            " - - -\n",
            " o - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " x x -\n",
            " - - -\n",
            " o - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([2])\n",
            " x x o\n",
            " - - -\n",
            " o - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " x x o\n",
            " - - -\n",
            " o x -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([5])\n",
            " x x o\n",
            " - - o\n",
            " o x -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " x x o\n",
            " - x o\n",
            " o x -\n",
            "\n",
            "Game Number  1487\n",
            "random won  555\n",
            " x x o\n",
            " - x o\n",
            " o x -\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1488  |AGENT :  679  |RANDOM:  555  |DRAW:  253\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " - - -\n",
            " - - x\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([3])\n",
            " - - -\n",
            " o - -\n",
            " - - x\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " x - -\n",
            " o - -\n",
            " - - x\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "select action, random 0.9\n",
            " x o -\n",
            " o - -\n",
            " - - x\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " x o -\n",
            " o - -\n",
            " - x x\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "select action, random 0.9\n",
            " x o -\n",
            " o o -\n",
            " - x x\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " x o x\n",
            " o o -\n",
            " - x x\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([5])\n",
            " x o x\n",
            " o o o\n",
            " - x x\n",
            "\n",
            "Game Number  1488\n",
            "agent won  680\n",
            " x o x\n",
            " o o o\n",
            " - x x\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1489  |AGENT :  680  |RANDOM:  555  |DRAW:  253\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " - x -\n",
            " - - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([8])\n",
            " - - -\n",
            " - x -\n",
            " - - o\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " - x -\n",
            " x - o\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([5])\n",
            " - - -\n",
            " - x o\n",
            " x - o\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - x -\n",
            " - x o\n",
            " x - o\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([2])\n",
            " - x o\n",
            " - x o\n",
            " x - o\n",
            "\n",
            "Game Number  1489\n",
            "agent won  681\n",
            " - x o\n",
            " - x o\n",
            " x - o\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1490  |AGENT :  681  |RANDOM:  555  |DRAW:  253\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " - - -\n",
            " - - x\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "select action, random 0.9\n",
            " - - -\n",
            " - - -\n",
            " o - x\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " - x -\n",
            " o - x\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([3])\n",
            " - - -\n",
            " o x -\n",
            " o - x\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " o x x\n",
            " o - x\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([2])\n",
            " - - o\n",
            " o x x\n",
            " o - x\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - o\n",
            " o x x\n",
            " o x x\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([1])\n",
            " - o o\n",
            " o x x\n",
            " o x x\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " x o o\n",
            " o x x\n",
            " o x x\n",
            "\n",
            "Game Number  1490\n",
            "random won  556\n",
            " x o o\n",
            " o x x\n",
            " o x x\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1491  |AGENT :  681  |RANDOM:  556  |DRAW:  253\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - x -\n",
            " - - -\n",
            " - - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([6])\n",
            " - x -\n",
            " - - -\n",
            " o - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - x -\n",
            " x - -\n",
            " o - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([2])\n",
            " - x o\n",
            " x - -\n",
            " o - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - x o\n",
            " x x -\n",
            " o - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([8])\n",
            " - x o\n",
            " x x -\n",
            " o - o\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - x o\n",
            " x x x\n",
            " o - o\n",
            "\n",
            "Game Number  1491\n",
            "random won  557\n",
            " - x o\n",
            " x x x\n",
            " o - o\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1492  |AGENT :  681  |RANDOM:  557  |DRAW:  253\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " x - -\n",
            " - - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([2])\n",
            " - - o\n",
            " x - -\n",
            " - - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - o\n",
            " x - -\n",
            " x - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([1])\n",
            " - o o\n",
            " x - -\n",
            " x - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " x o o\n",
            " x - -\n",
            " x - -\n",
            "\n",
            "Game Number  1492\n",
            "random won  558\n",
            " x o o\n",
            " x - -\n",
            " x - -\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1493  |AGENT :  681  |RANDOM:  558  |DRAW:  253\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " - - -\n",
            " - x -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "select action, random 0.9\n",
            " - o -\n",
            " - - -\n",
            " - x -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - o -\n",
            " - - x\n",
            " - x -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([3])\n",
            " - o -\n",
            " o - x\n",
            " - x -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - o -\n",
            " o x x\n",
            " - x -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "select action, random 0.9\n",
            " o o -\n",
            " o x x\n",
            " - x -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " o o x\n",
            " o x x\n",
            " - x -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([6])\n",
            " o o x\n",
            " o x x\n",
            " o x -\n",
            "\n",
            "Game Number  1493\n",
            "agent won  682\n",
            " o o x\n",
            " o x x\n",
            " o x -\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1494  |AGENT :  682  |RANDOM:  558  |DRAW:  253\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - x\n",
            " - - -\n",
            " - - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([4])\n",
            " - - x\n",
            " - o -\n",
            " - - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - x\n",
            " - o -\n",
            " - - x\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([5])\n",
            " - - x\n",
            " - o o\n",
            " - - x\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - x\n",
            " x o o\n",
            " - - x\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([1])\n",
            " - o x\n",
            " x o o\n",
            " - - x\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - o x\n",
            " x o o\n",
            " - x x\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([6])\n",
            " - o x\n",
            " x o o\n",
            " o x x\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " x o x\n",
            " x o o\n",
            " o x x\n",
            "\n",
            "draw  254\n",
            " x o x\n",
            " x o o\n",
            " o x x\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1495  |AGENT :  682  |RANDOM:  558  |DRAW:  254\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " - - -\n",
            " - x -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([3])\n",
            " - - -\n",
            " o - -\n",
            " - x -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " o - -\n",
            " - x x\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([6])\n",
            " - - -\n",
            " o - -\n",
            " o x x\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " x - -\n",
            " o - -\n",
            " o x x\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([5])\n",
            " x - -\n",
            " o - o\n",
            " o x x\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " x x -\n",
            " o - o\n",
            " o x x\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([4])\n",
            " x x -\n",
            " o o o\n",
            " o x x\n",
            "\n",
            "Game Number  1495\n",
            "agent won  683\n",
            " x x -\n",
            " o o o\n",
            " o x x\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1496  |AGENT :  683  |RANDOM:  558  |DRAW:  254\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " x - -\n",
            " - - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([2])\n",
            " - - o\n",
            " x - -\n",
            " - - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - o\n",
            " x - -\n",
            " - - x\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([0])\n",
            " o - o\n",
            " x - -\n",
            " - - x\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " o x o\n",
            " x - -\n",
            " - - x\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([4])\n",
            " o x o\n",
            " x o -\n",
            " - - x\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " o x o\n",
            " x o -\n",
            " x - x\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([5])\n",
            " o x o\n",
            " x o o\n",
            " x - x\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " o x o\n",
            " x o o\n",
            " x x x\n",
            "\n",
            "Game Number  1496\n",
            "random won  559\n",
            " o x o\n",
            " x o o\n",
            " x x x\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1497  |AGENT :  683  |RANDOM:  559  |DRAW:  254\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " - - x\n",
            " - - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([4])\n",
            " - - -\n",
            " - o x\n",
            " - - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - x -\n",
            " - o x\n",
            " - - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([2])\n",
            " - x o\n",
            " - o x\n",
            " - - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - x o\n",
            " - o x\n",
            " - x -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([6])\n",
            " - x o\n",
            " - o x\n",
            " o x -\n",
            "\n",
            "Game Number  1497\n",
            "agent won  684\n",
            " - x o\n",
            " - o x\n",
            " o x -\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1498  |AGENT :  684  |RANDOM:  559  |DRAW:  254\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " - x -\n",
            " - - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([8])\n",
            " - - -\n",
            " - x -\n",
            " - - o\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " - x x\n",
            " - - o\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([6])\n",
            " - - -\n",
            " - x x\n",
            " o - o\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - x -\n",
            " - x x\n",
            " o - o\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([3])\n",
            " - x -\n",
            " o x x\n",
            " o - o\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - x x\n",
            " o x x\n",
            " o - o\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([7])\n",
            " - x x\n",
            " o x x\n",
            " o o o\n",
            "\n",
            "Game Number  1498\n",
            "agent won  685\n",
            " - x x\n",
            " o x x\n",
            " o o o\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1499  |AGENT :  685  |RANDOM:  559  |DRAW:  254\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - - -\n",
            " - - x\n",
            " - - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "select action, random 0.9\n",
            " - o -\n",
            " - - x\n",
            " - - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " - o -\n",
            " x - x\n",
            " - - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([0])\n",
            " o o -\n",
            " x - x\n",
            " - - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " o o x\n",
            " x - x\n",
            " - - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "select action, random 0.9\n",
            " o o x\n",
            " x o x\n",
            " - - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " o o x\n",
            " x o x\n",
            " - x -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([8])\n",
            " o o x\n",
            " x o x\n",
            " - x o\n",
            "\n",
            "Game Number  1499\n",
            "agent won  686\n",
            " o o x\n",
            " x o x\n",
            " - x o\n",
            "\n",
            "#####################################################################################################\n",
            "START GAME NUMBER:  1500  |AGENT :  686  |RANDOM:  559  |DRAW:  254\n",
            "#####################################################################################################\n",
            "\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " x - -\n",
            " - - -\n",
            " - - -\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([6])\n",
            " x - -\n",
            " - - -\n",
            " o - -\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " x - -\n",
            " - - -\n",
            " o - x\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([1])\n",
            " x o -\n",
            " - - -\n",
            " o - x\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " x o x\n",
            " - - -\n",
            " o - x\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([4])\n",
            " x o x\n",
            " - o -\n",
            " o - x\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " x o x\n",
            " - o -\n",
            " o x x\n",
            "\n",
            "------------------------Agent Turn----------------------- :)\n",
            "\n",
            "action =   tensor([3])\n",
            " x o x\n",
            " o o -\n",
            " o x x\n",
            "\n",
            "------------------------Random Turn----------------------- :)\n",
            "\n",
            " x o x\n",
            " o o x\n",
            " o x x\n",
            "\n",
            "Game Number  1500\n",
            "random won  560\n",
            " x o x\n",
            " o o x\n",
            " o x x\n",
            "\n",
            "#####################################################################################################\n",
            "GAME NUMBER:  1500  |AGENT :  686  |RANDOM:  560  |DRAW:  254\n",
            "#####################################################################################################\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_7L8Ftlc8qM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}